{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_tutorial_newVersion.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "skYZyQjd4rmB",
        "phakm7zosRZd",
        "LxCYlntcGOML",
        "dsdmyap1GSZT"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linghduoduo/Deep-Learning/blob/master/3_PyTorch_tutorial_newVersion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gVHm1iS4hjM"
      },
      "source": [
        "# PyTorch 模型建構與訓練基礎介紹 -- PyTorch Training Steps & Tips "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LENbLEdJ8avG",
        "cellView": "form"
      },
      "source": [
        "#@markdown **安裝適當的套件版本 Run me to install libraries!**\n",
        "\n",
        "%%bash\n",
        "pip install torch==1.2.0    \\\n",
        "      torchvision==0.4.0    \\\n",
        "            numpy==1.17.5   \\\n",
        "       matplotlib==3.1.3    \\\n",
        "           pandas==0.25.3   \\\n",
        "            scipy==1.4.1    \\\n",
        "           pillow==6.2.2    \\\n",
        "           gensim==3.6.0    \\\n",
        "    opencv-python==4.1.2.30 \\\n",
        "     scikit-learn==0.22.1 -q\n",
        "\n",
        "pip install  tqdm==4.28.1   \\\n",
        "             lime==0.1.1.37 \\\n",
        "             nltk==3.4.5  -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wivgXSBk5kTi",
        "cellView": "form",
        "outputId": "f3edacd6-4b04-4b97-85e6-80a1062375f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "#@markdown **下載所需的資料 Download the necessary files here!**\n",
        "\n",
        "%%bash\n",
        "COLAB_ICON=\"${COLAB_ICON}https://miro.medium.com/max/200/\"\n",
        "COLAB_ICON=\"${COLAB_ICON}1*i_ncmAcN81MRMNRDcenKiw.png\"\n",
        "wget -q -nc -O Colab_icon.png $COLAB_ICON\n",
        "\n",
        "echo \"Hello! I am the data~. :P\" > filename.txt\n",
        "\n",
        "echo \"Col0,Col1,Col2,Col3\" > data.csv\n",
        "echo \"Row1,data11,data12,data13\" >> data.csv\n",
        "echo \"Row2,data21,data22,data23\" >> data.csv\n",
        "echo \"Row3,data31,data32,data33\" >> data.csv\n",
        "echo \"Row4,data41,data42,data43\" >> data.csv\n",
        "echo \"Row5,data51,data52,data53\" >> data.csv\n",
        "echo \"Row6,data61,data62,data63\" >> data.csv\n",
        "echo \"Row7,data71,data72,data73\" >> data.csv\n",
        "printf \"%s\" \"Row8,data81,data82,data83\" >> data.csv\n",
        "\n",
        "gdown --id '19CzXudqN58R3D-1G8KeFWk8UDQwlb8is' \\\n",
        "    --output food-11.zip # 下載資料集\n",
        "unzip food-11.zip > unziplog # 解壓縮\n",
        "rm -f unziplog\n",
        "\n",
        "wget -q -N https://download.pytorch.org/tutorial/faces.zip\n",
        "if [ ! -d data ]; then mkdir data; fi\n",
        "unzip -q -o faces.zip -d data > unziplog\n",
        "rm -f faces.zip\n",
        "rm -f unziplog"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19CzXudqN58R3D-1G8KeFWk8UDQwlb8is\n",
            "To: /content/food-11.zip\n",
            "\r0.00B [00:00, ?B/s]\r8.91MB [00:00, 72.4MB/s]\r41.9MB [00:00, 94.6MB/s]\r67.1MB [00:00, 116MB/s] \r89.7MB [00:00, 136MB/s]\r107MB [00:00, 139MB/s] \r134MB [00:00, 161MB/s]\r155MB [00:00, 173MB/s]\r179MB [00:00, 190MB/s]\r201MB [00:01, 148MB/s]\r228MB [00:01, 171MB/s]\r252MB [00:01, 185MB/s]\r277MB [00:01, 198MB/s]\r303MB [00:01, 214MB/s]\r327MB [00:01, 189MB/s]\r348MB [00:01, 173MB/s]\r370MB [00:02, 139MB/s]\r395MB [00:02, 147MB/s]\r428MB [00:02, 164MB/s]\r447MB [00:02, 153MB/s]\r472MB [00:02, 174MB/s]\r498MB [00:02, 192MB/s]\r524MB [00:02, 208MB/s]\r546MB [00:02, 175MB/s]\r576MB [00:03, 199MB/s]\r599MB [00:03, 201MB/s]\r621MB [00:03, 192MB/s]\r644MB [00:03, 200MB/s]\r671MB [00:03, 216MB/s]\r695MB [00:03, 224MB/s]\r719MB [00:03, 220MB/s]\r747MB [00:03, 200MB/s]\r778MB [00:03, 223MB/s]\r808MB [00:04, 243MB/s]\r835MB [00:04, 232MB/s]\r859MB [00:04, 191MB/s]\r887MB [00:04, 209MB/s]\r915MB [00:04, 181MB/s]\r936MB [00:04, 189MB/s]\r964MB [00:04, 208MB/s]\r990MB [00:04, 221MB/s]\r1.01GB [00:05, 221MB/s]\r1.04GB [00:05, 184MB/s]\r1.06GB [00:05, 189MB/s]\r1.08GB [00:05, 183MB/s]\r1.10GB [00:05, 116MB/s]\r1.12GB [00:05, 136MB/s]\r1.14GB [00:05, 151MB/s]\r1.16GB [00:06, 191MB/s]\n",
            "replace food-11/testing/0071.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: new name: replace iplog? [y]es, [n]o, [A]ll, [N]one, [r]ename: error:  invalid response [{ENTER}]\n",
            "replace iplog? [y]es, [n]o, [A]ll, [N]one, [r]ename: error:  invalid response [wget -q -]\n",
            "replace iplog? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWRp-c948C8d"
      },
      "source": [
        "### 載入需要的套件和模組 Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y0ZJM-u8Fyw"
      },
      "source": [
        "import os, sys\n",
        "import time, json, csv\n",
        "from glob import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# %% 深度學習套件 deep learning related \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# %% 視覺化/製圖套件 visualization / plotting\n",
        "# MacOSX 比較麻煩⋯⋯\n",
        "from platform import system\n",
        "if system() == \"Darwin\":\n",
        "    import matplotlib\n",
        "    matplotlib.use('TkAgg')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# %% 圖片處理套件 CV related\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# %% 文字處理套件 NLP related\n",
        "from gensim.models import word2vec\n",
        "\n",
        "# %% 音訊處理套件 Speech related\n",
        "# import torchaudio\n",
        "# import librosa\n",
        "\n",
        "# %% 好用的進度條和排版工具\n",
        "##   progress bar and pretty print\n",
        "from tqdm import tqdm\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h1vq2z74pf5"
      },
      "source": [
        "## 1. 資料前處理 - Data Preprocessing\n",
        "首先，我們需要將我們的資料整理成 model 可以處理的形式  \n",
        "First, we need to process our data into forms that can be processed by models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skYZyQjd4rmB"
      },
      "source": [
        "### 1 -- 資料讀取 - Reading files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnsuLEEpm_xf"
      },
      "source": [
        "#### 文字檔案 - Text Files\n",
        "這是最簡單的，直接如一般 Python 讀取就好\n",
        "Simply follows that in other Python programs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8rTKKH6m8dM",
        "outputId": "3729893b-4e08-4768-fb1a-c766f471c730",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with open(\"filename.txt\", 'r') as f:\n",
        "    data = f.read()\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello! I am the data~. :P\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8JkbabDi5Cl"
      },
      "source": [
        "#### CSV 檔案 - CSV Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbyYFdXsi77M",
        "outputId": "ef096ee9-cab4-48e4-bda6-0e2550d6e883",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with open(\"data.csv\") as f: \n",
        "    csv_data = f.read()\n",
        "print(\"Here comes a csv data:\", \n",
        "      '=' * 60, csv_data, '=' * 60, sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here comes a csv data:\n",
            "============================================================\n",
            "Col0,Col1,Col2,Col3\n",
            "Row1,data11,data12,data13\n",
            "Row2,data21,data22,data23\n",
            "Row3,data31,data32,data33\n",
            "Row4,data41,data42,data43\n",
            "Row5,data51,data52,data53\n",
            "Row6,data61,data62,data63\n",
            "Row7,data71,data72,data73\n",
            "Row8,data81,data82,data83\n",
            "============================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFcYiR39hWoU"
      },
      "source": [
        "##### 1) Python 原生 - Pure Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nxl0qUS7vOD",
        "outputId": "ae2c4217-f516-463c-c302-8b9880a0d86c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import csv\n",
        "with open(\"data.csv\", 'r') as f:\n",
        "    csv_reader = csv.reader(f, delimiter=',')\n",
        "    # If you have a \"tsv\", do this:\n",
        "    ##  `csv_reader = csv.reader(f, delimiter='\\t')`\n",
        "    csv_data1 = [row for row in csv_reader]\n",
        "csv_data1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Col0', 'Col1', 'Col2', 'Col3'],\n",
              " ['Row1', 'data11', 'data12', 'data13'],\n",
              " ['Row2', 'data21', 'data22', 'data23'],\n",
              " ['Row3', 'data31', 'data32', 'data33'],\n",
              " ['Row4', 'data41', 'data42', 'data43'],\n",
              " ['Row5', 'data51', 'data52', 'data53'],\n",
              " ['Row6', 'data61', 'data62', 'data63'],\n",
              " ['Row7', 'data71', 'data72', 'data73'],\n",
              " ['Row8', 'data81', 'data82', 'data83']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZFhzPzBlsVw"
      },
      "source": [
        "##### 2) 使用 Pandas 套件（比較快！） --- Pandas Library (Faster!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYq1U1tcjYsj",
        "outputId": "117c4bd5-578c-46de-959e-8a6a141b6df9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "csv_data2 = pd.read_csv(\"data.csv\")\n",
        "\n",
        "# Saved as a Pandas dataframe\n",
        "csv_data2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Col0</th>\n",
              "      <th>Col1</th>\n",
              "      <th>Col2</th>\n",
              "      <th>Col3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Row1</td>\n",
              "      <td>data11</td>\n",
              "      <td>data12</td>\n",
              "      <td>data13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Row2</td>\n",
              "      <td>data21</td>\n",
              "      <td>data22</td>\n",
              "      <td>data23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Row3</td>\n",
              "      <td>data31</td>\n",
              "      <td>data32</td>\n",
              "      <td>data33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Row4</td>\n",
              "      <td>data41</td>\n",
              "      <td>data42</td>\n",
              "      <td>data43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Row5</td>\n",
              "      <td>data51</td>\n",
              "      <td>data52</td>\n",
              "      <td>data53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Row6</td>\n",
              "      <td>data61</td>\n",
              "      <td>data62</td>\n",
              "      <td>data63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Row7</td>\n",
              "      <td>data71</td>\n",
              "      <td>data72</td>\n",
              "      <td>data73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Row8</td>\n",
              "      <td>data81</td>\n",
              "      <td>data82</td>\n",
              "      <td>data83</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Col0    Col1    Col2    Col3\n",
              "0  Row1  data11  data12  data13\n",
              "1  Row2  data21  data22  data23\n",
              "2  Row3  data31  data32  data33\n",
              "3  Row4  data41  data42  data43\n",
              "4  Row5  data51  data52  data53\n",
              "5  Row6  data61  data62  data63\n",
              "6  Row7  data71  data72  data73\n",
              "7  Row8  data81  data82  data83"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGrYRNCsjxLy",
        "outputId": "d8f9e365-acff-454d-d147-25aac9665f03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_columns = csv_data2.columns\n",
        "data_columns.values # `.values` to numpy arrays"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Col0', 'Col1', 'Col2', 'Col3'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUzmkKxljqQc",
        "outputId": "7b3f7b8c-f444-459d-f533-6f650e66e48e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "try:    # after pandas ver.0.24.0\n",
        "    data_content = csv_data2.to_numpy()\n",
        "except: # before pandas ver.0.24.0\n",
        "    data_content = csv_data2.values\n",
        "data_content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Row1', 'data11', 'data12', 'data13'],\n",
              "       ['Row2', 'data21', 'data22', 'data23'],\n",
              "       ['Row3', 'data31', 'data32', 'data33'],\n",
              "       ['Row4', 'data41', 'data42', 'data43'],\n",
              "       ['Row5', 'data51', 'data52', 'data53'],\n",
              "       ['Row6', 'data61', 'data62', 'data63'],\n",
              "       ['Row7', 'data71', 'data72', 'data73'],\n",
              "       ['Row8', 'data81', 'data82', 'data83']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EUMFj63m4e0"
      },
      "source": [
        "#### 圖片檔案 --- Image Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jes6-txCG1G-",
        "cellView": "form",
        "outputId": "b7220ba0-1466-433a-d360-eb5b667fd14f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title **看看圖片！ Run me to view image!**\n",
        "from IPython.display import Image as ImageColab\n",
        "image = cv2.imread(\"Colab_icon.png\")\n",
        "im = Image.fromarray(image[..., ::-1])\n",
        "im.save(\"Colab_icon.png\")\n",
        "ImageColab('Colab_icon.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAAhFklEQVR4nO2daYwkx3WgvxdZWVXd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\nHo/H4/F4PB6PxzPH/weKQxTHmGEKHwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lECLMERMs4vm",
        "outputId": "38f86725-2af1-4f25-f101-020c35400860",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# image = cv2.imread(\"image1.png\")\n",
        "image = cv2.imread(\"Colab_icon.png\")\n",
        "image.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 200, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phakm7zosRZd"
      },
      "source": [
        "### 2 -- 資料處理操作 -- Data Manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjWxLwp2snSR"
      },
      "source": [
        "#### 文字資料 --- Text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1qdd5o5vp1E"
      },
      "source": [
        "text = \"Hello, world!\\nI want to try tabs.\\tLike this!\"\n",
        "text_splitted = text.split('\\n')\n",
        "text_splitted = text.splitlines()\n",
        "\n",
        "# List comprehension\n",
        "text_splitted = [line.split('\\t') \n",
        "     for line in text.split('\\n')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRS5MgBnylg2"
      },
      "source": [
        "#### Numpy 陣列 --- Numpy Array data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPYFn6jTwhvU",
        "outputId": "c5ff60dd-dc74-4fb0-ae2e-e58230043eeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "arr1 = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "arr2 = np.array([[9, 8], [7, 6], [5, 4]])\n",
        "arr6 = np.random.randint(0, 100, (3, 5, 4))\n",
        "print(\">>> arr1 is ...\"); print(arr1)\n",
        "print(\">>> arr2 is ...\"); print(arr2)\n",
        "\n",
        "arr3 = np.concatenate((arr1, arr2), axis=0)\n",
        "arr4 = np.concatenate((arr1, arr2), axis=1)\n",
        "\n",
        "arr5 = np.transpose(arr1)\n",
        "arr7 = np.transpose(arr6, axes=(0, 2, 1))\n",
        "\n",
        "lst = [3, 76, 4, -45, 0, 6]\n",
        "arr8 = np.array(lst)\n",
        "print(f\">>> The shape of arr8 is {arr8.shape}.\")\n",
        "\n",
        "arr9 = arr8.astype(np.float)\n",
        "print(\">>> arr9 is ...\"); print(arr9)\n",
        "\n",
        "lst = [[9, 8], [7, 6], [5, 4]]\n",
        "arr10 = np.array(lst, dtype=\"uint8\")\n",
        "arr11 = arr10.astype(np.float32)\n",
        "\n",
        "print(f\">>> The type of `lst` is {type(lst)},\")\n",
        "print(f\"    but the type of `arr10` is {type(arr10)}.\")\n",
        "\n",
        "new_shape = (1, -1, 3)\n",
        "arr10_reshaped = arr10.reshape(new_shape)\n",
        "print(\">>> arr10_reshaped is ...\")\n",
        "print(arr10_reshaped)\n",
        "\n",
        "arr10_transposed = arr10.T\n",
        "print(\">>> arr10_transposed is ...\")\n",
        "print(arr10_transposed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> arr1 is ...\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n",
            ">>> arr2 is ...\n",
            "[[9 8]\n",
            " [7 6]\n",
            " [5 4]]\n",
            ">>> The shape of arr8 is (6,).\n",
            ">>> arr9 is ...\n",
            "[  3.  76.   4. -45.   0.   6.]\n",
            ">>> The type of `lst` is <class 'list'>,\n",
            "    but the type of `arr10` is <class 'numpy.ndarray'>.\n",
            ">>> arr10_reshaped is ...\n",
            "[[[9 8 7]\n",
            "  [6 5 4]]]\n",
            ">>> arr10_transposed is ...\n",
            "[[9 7 5]\n",
            " [8 6 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pClcg-oHyjdB"
      },
      "source": [
        "#### 圖片資料 --- Image data\n",
        "把原來的圖片做伸縮"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYg38hAEIUL2",
        "outputId": "bac59b7c-c427-42f0-d123-56bbd879842f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "img_shape = (100, 100)\n",
        "images = [cv2.resize(image, img_shape)]\n",
        "zeros_reserved = \\\n",
        "    np.zeros((len(images), *img_shape),\n",
        "                            dtype=np.uint8)\n",
        "print(images[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 100, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dzg-gG5Mq-7",
        "cellView": "form",
        "outputId": "4766e9ee-64a8-4a6b-d644-28323cde3d6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@markdown 看轉換的圖片！ View resized image!\n",
        "im = Image.fromarray(images[0][..., ::-1])\n",
        "im.save(\"your_file.png\")\n",
        "ImageColab(\"your_file.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAIAAAD/gAIDAAAOqElEQVR4nO2ce3Qc1XnAf3dmdrWS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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCu9kfNOxLVW"
      },
      "source": [
        "##### 常用的圖片轉換 Data augmentations\n",
        "\n",
        "```python\n",
        "import torchvision.transforms as transforms\n",
        "# Basic transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(), # np.array  --> PIL_image\n",
        "    transforms.ToTensor()    # PIL_image --> Tensor\n",
        "])\n",
        "```\n",
        "\n",
        "下面有一些重複且被註解掉的部分，是因為版本差異造成。請注意應該只有一個會 work\n",
        "```python\n",
        "# For data augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(), \n",
        "    transforms.RandomRotation(DEGREE), \n",
        "    # transforms.RandomRotation(DEGREE, fill=(0,)),\n",
        "    # transforms.RandomRotation(DEGREE, \n",
        "    #     resample=False, expand=False, center=None),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Feature Scaling, \n",
        "#     `mean` and `std` as np.array provided\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(), \n",
        "    transforms.Normalize(\n",
        "        [mean], [std], inplace=False)\n",
        "    # transforms.Normalize([mean], [std])\n",
        "])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqmhEfk1y1H7"
      },
      "source": [
        "#### 詞向量 --- Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tab3dSNYl72u"
      },
      "source": [
        "# https://en.wikipedia.org/wiki/Machine_learning\n",
        "\n",
        "article = '''Machine learning (ML) is the scientific \n",
        "study of algorithms and statistical models that \n",
        "computer systems use to perform a specific task \n",
        "without using explicit instructions, relying on \n",
        "patterns and inference instead. It is seen as a \n",
        "subset of artificial intelligence. Machine learning \n",
        "algorithms build a mathematical model based on sample \n",
        "data, known as \"training data\", in order to make \n",
        "predictions or decisions without being explicitly \n",
        "programmed to perform the task. Machine learning \n",
        "algorithms are used in a wide variety of applications, \n",
        "such as email filtering and computer vision, where it \n",
        "is difficult or infeasible to develop a conventional \n",
        "algorithm for effectively performing the task.\n",
        "'''[:-1].replace('\\n', '')\n",
        "\n",
        "for punctuation in \",()\\\"\":\n",
        "    article = article.replace(punctuation, '')\n",
        "tokenized_sentences = []\n",
        "for sentence in article.split('.'):\n",
        "    if sentence == '': continue\n",
        "    sentence = sentence.strip()\n",
        "    sentence = sentence[0].lower() + sentence[1:]\n",
        "    tokenized_sentences.append(sentence.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhFBD-vdnOoh"
      },
      "source": [
        "# 這格有時可能要跑一段時間！ This cell may take time! \n",
        "w2vmodel = word2vec.Word2Vec(\n",
        "                    tokenized_sentences, \n",
        "                    size=100, # Word embedding 的維度數\n",
        "                    window=5, min_count=1,\n",
        "                    workers=12, iter=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppbOOpLzsjtT"
      },
      "source": [
        "### 3 -- 資料準備 --- Dataset / Dataloader Preparation\n",
        "在處理訓練資料時，進行資料型態的前處理與分批（batch）等是相當麻煩的事。  \n",
        "PyTorch 提供了一個很好的 dataset 與 dataloader 讓我們進行分裝以利訓練進行，還可以依需求自訂 dataset 的型態  \n",
        "\n",
        "簡言之，`dataset` 是用來做打包與預處理（例如輸入資料路徑自動讀取）；  \n",
        "`Dataloader` 則是可以將整個資料集（dataset）按照 batch 進行迭代分裝或 shuffle（會得到一個 iterator 以利 for 迴圈讀取）\n",
        "\n",
        "其中 `dataset` 必須給予 `__len__`（dataset 大小）與`__getitem__`（取得特定 index 的資料）的定義  \n",
        "（否則會跳出 `NotImplementedError`）\n",
        "\n",
        "另外 `Dataloader` 可以自訂 `collate_fn` 決定 batch 的分裝方式，可以參見[這裡](https://pytorch.org/docs/stable/data.html#dataloader-collate-fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYkq7v-vRwnl"
      },
      "source": [
        "#### 範例１：隨機資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQaa5zgeRzF-"
      },
      "source": [
        "X = np.random.rand(1000, 100, 100, 1)   # 虛構 1000 張 100 x 100 單色圖片\n",
        "Y = np.random.randint(0, 7, [1000, 10]) # 虛構 1000 個 labels\n",
        "\n",
        "class RandomDataset(Dataset):\n",
        "    def __init__(self, data, target):             # 把資料存進 class object\n",
        "        self.data = data\n",
        "        self.target = target\n",
        "    def __len__(self):\n",
        "        assert len(self.data) == len(self.target) # 確定資料有互相對應\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):                     # 定義我們需要取得某筆資料的方式\n",
        "        return self.data[idx], self.target[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY437hkCVWa1",
        "outputId": "2bed6231-d14a-41ce-86db-08774e42c279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "randomdataset = RandomDataset(X.astype(np.float32), Y.astype(np.float32))\n",
        "taken_x, taken_y = randomdataset[0] # 原則上可以取得第一筆資料\n",
        "taken_x.shape, taken_y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 100, 1), (10,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i__4aBYTVklB"
      },
      "source": [
        "# 將 dataset 包裝成 dataloader\n",
        "randomdataloader = DataLoader(\n",
        "    randomdataset, batch_size=4,\n",
        "    shuffle=True, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-_uGi_VVh3G",
        "outputId": "94e7c742-48d4-4611-ac99-0e28ffb366f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "# 跑一個 loop 確認拿到的 batch 是否正確\n",
        "for batch_x, batch_y in randomdataloader:\n",
        "    print((batch_x.shape, batch_y.shape))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(torch.Size([4, 100, 100, 1]), torch.Size([4, 10]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i_HE2Weyzhd"
      },
      "source": [
        "##### 張量資料集 Tensor dataset\n",
        "這是最常見的形式，因此 PyTorch 本身有提供方便的 `TensorDataset` 給我們使用  \n",
        "This is the most common form, so we have `TensorDataset` implemented in PyTorch.\n",
        "\n",
        "```python\n",
        "torch.utils.data.TensorDataset(data_tensor, target_tensor)\n",
        "```\n",
        "\n",
        "如果用 `TensorDataset` 寫，上面就會輕鬆很多"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzz71aV8WNci",
        "outputId": "2d9110fd-94e4-430d-a646-5484aca941df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "# 把資料轉成 Tensor\n",
        "tsrX, tsrY = torch.tensor(X), torch.tensor(Y)\n",
        "# 然後就只要一行了！\n",
        "tsrdataset = TensorDataset(tsrX, tsrY)\n",
        "\n",
        "# dataloader 本來就相對簡單\n",
        "tsrdataloader = DataLoader(\n",
        "    tsrdataset, batch_size=4,\n",
        "    shuffle=True, num_workers=4)\n",
        "\n",
        "# 跑一個 loop 確認拿到的 batch 是否正確\n",
        "for batch_x, batch_y in tsrdataloader:\n",
        "    print((batch_x.shape, batch_y.shape))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(torch.Size([4, 100, 100, 1]), torch.Size([4, 10]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGBM0gDPZd5b"
      },
      "source": [
        "實際上資料處理還可以更加複雜，機器學習中資料的錢處理也是相當的學問！  \n",
        "\n",
        "#### 範例２：MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoKQEiwnX5zu",
        "outputId": "5eb9d3dc-7410-4d79-d254-e3dd048f258a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "train_set = datasets.MNIST('../data', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ]))\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "\n",
        "test_set = datasets.MNIST('../data', train=False, \n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ]))\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=True)\n",
        "\n",
        "for batch_x, batch_y in train_loader:\n",
        "    print((batch_x.shape, batch_y.shape))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(torch.Size([32, 1, 28, 28]), torch.Size([32]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cdULNKC51DU"
      },
      "source": [
        "## 2. Model Construction -- <mark><tt>**torch.nn**</tt></mark>\n",
        "After data processing, it comes to the *main part* of the implementation of deep learning -- **model construction**.\n",
        "Most frequently used modules and functions are wrapped under the <mark><tt>**torch.nn**</tt></mark> module.  \n",
        "\n",
        "Here comes a common syntax --  \n",
        "```python\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etmxw1JM6rUP"
      },
      "source": [
        "### Model -- **`nn.Module`**\n",
        "\n",
        "This is the basic module for PyTorch Neural network models. To build an NN model, inherit from it.\n",
        "\n",
        "```python\n",
        "class MyNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNNModel, self).__init__()\n",
        "        # other layers or else...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSauJhBQewrD"
      },
      "source": [
        "### Wrapper -- **`nn.Sequential`**\n",
        "\n",
        "PyTorch provides a convenient layer wrapper `nn.Sequential` for us.  \n",
        "We can wrap a couple of layers together and use it for many times.\n",
        "\n",
        "```python\n",
        "nn.Sequential(layers)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrpbNZEXFVK7"
      },
      "source": [
        "# Let us have 3 layers\n",
        "layer1 = nn.Linear(100, 20)\n",
        "layer2 = nn.Linear(20, 16)\n",
        "layer3 = nn.Linear(16, 7)\n",
        "\n",
        "# Data format: \n",
        "#    - Input:  100 x 100\n",
        "#    - Output: 100 x 7\n",
        "input_data  = torch.randn(100, 100)\n",
        "output_data = torch.randn(100, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1qJNpZa7awf",
        "outputId": "4e00070e-eaec-49a4-97c0-026e24c45f7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "print(\"Befor using `nn.Sequential`...\")\n",
        "# Originally, we need to write this.\n",
        "print(f\"The input tensor shape: {input_data.shape}\")\n",
        "out = layer1(input_data)\n",
        "out = layer2(out)\n",
        "result = layer3(out)\n",
        "print(f\"The output tensor shape: {result.shape}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Befor using `nn.Sequential`...\n",
            "The input tensor shape: torch.Size([100, 100])\n",
            "The output tensor shape: torch.Size([100, 7])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd9xV8j57dG-",
        "outputId": "5ae40e97-8cfa-4147-ed43-562547de5226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "# If we wrap them together, \n",
        "##  we can just view the layers as a block.\n",
        "print(\"After using `nn.Sequential`...\")\n",
        "print(f\"The input tensor shape: {input_data.shape}\")\n",
        "layer_block = nn.Sequential(\n",
        "    layer1, layer2, layer3\n",
        ")\n",
        "result = layer_block(input_data)\n",
        "print(f\"The output tensor shape: {result.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After using `nn.Sequential`...\n",
            "The input tensor shape: torch.Size([100, 100])\n",
            "The output tensor shape: torch.Size([100, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG2NdMnq7L1n"
      },
      "source": [
        "### 1 -- Model Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fq4mlAu7RMN"
      },
      "source": [
        "#### 1) NN\n",
        "`nn.Linear` -- Often used fully-connected layer\n",
        "```python\n",
        "nn.Linear(in_dim, out_dim)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0X9y-ZR78gm",
        "outputId": "c7f6accf-29ee-49db-f4c1-02e00f4c3b73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        }
      },
      "source": [
        "batch_size = 32\n",
        "\"\"\"nn.Linear(in_dim, out_dim)\"\"\"\n",
        "fake_data = torch.randn(batch_size, 128)\n",
        "print(f\"The input data shape:  {fake_data.shape}\")\n",
        "Linear_layer = nn.Linear(128, 32)\n",
        "print( \"The output data shape: \"\\\n",
        "      f\"{Linear_layer(fake_data).shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The input data shape:  torch.Size([32, 128])\n",
            "The output data shape: torch.Size([32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICAsUgyG7Vsu"
      },
      "source": [
        "#### 2) CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxCYlntcGOML"
      },
      "source": [
        "##### Convolution layers\n",
        "`nn.Conv2d` -- Basic 2D Convolutional Layer\n",
        "```python\n",
        "nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)\n",
        "```\n",
        "Input shape: $(N, C_{in}, H_{in}, W_{in})$  \n",
        "Output shape: $(N, C_{out}, H_{out}, W_{out})$ where\n",
        "$$H_{out}=\\left \\lfloor \\cfrac{H_{in}+ 2 \\times \\text{padding}[0]-\\text{dilation}[0]\\times(\\text{kernel_size}[0]-1)-1}{\\text{stride}[0]} \\right \\rfloor+1$$\n",
        "$$W_{out}=\\left \\lfloor \\cfrac{H_{in}+ 2 \\times \\text{padding}[1]-\\text{dilation}[1]\\times(\\text{kernel_size}[1]-1)-1}{\\text{stride}[1]} \\right \\rfloor+1$$\n",
        "\n",
        "The `[0]`, `[1]` in the formula means the same value if the variable is passed in as an integer. (They can be tuples.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z83eR8bX8jBB",
        "outputId": "ce77d27e-98e5-4ad2-9bfc-b7e46b4b4312",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fake_data = torch.randn(batch_size, 3, 100, 100)\n",
        "print(f\"The input data shape:  {fake_data.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The input data shape:  torch.Size([32, 3, 100, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL9hUZxDE7X4",
        "cellView": "form"
      },
      "source": [
        "#@title Deciding channels\n",
        "input_channels = 3#@param {type:\"integer\"}\n",
        "output_channels = 128#@param {type:\"integer\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFZ3_WiJHhzr",
        "cellView": "form",
        "outputId": "bd45ff2d-3d7f-4030-a389-0ac382761bd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Only `kernel_size`\n",
        "kernel_size =   7#@param {type:\"integer\"}\n",
        "\n",
        "Conv_layer1 = nn.Conv2d(input_channels,\n",
        "                        output_channels, \n",
        "                        kernel_size)\n",
        "output_res1 = Conv_layer1(fake_data)\n",
        "\n",
        "print(\"############### Try the following code... ###############\\n\")\n",
        "print(f\"Conv_layer1 = nn.Conv2d({input_channels}, \"\\\n",
        "      f\"{output_channels}, \"\\\n",
        "      f\"{kernel_size})\")\n",
        "print(\"output_res1 = Conv_layer1(fake_data)\")\n",
        "print(\"print(f\\\"The output data shape: {output_res1.shape}\\\")\")\n",
        "print(\"\\n#########################################################\\n\")\n",
        "print(\"Output `H_out` =\",\n",
        "     f\"((⌊100 + 2 × 0 - 1 × ({kernel_size} - 1) - 1⌋ / 1) + 1 =\",\n",
        "      int((100 + 2 * 0 - 1 * (kernel_size - 1) - 1) / 1) + 1)\n",
        "print(f\"The output data shape: {output_res1.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############### Try the following code... ###############\n",
            "\n",
            "Conv_layer1 = nn.Conv2d(3, 128, 7)\n",
            "output_res1 = Conv_layer1(fake_data)\n",
            "print(f\"The output data shape: {output_res1.shape}\")\n",
            "\n",
            "#########################################################\n",
            "\n",
            "Output `H_out` = ((⌊100 + 2 × 0 - 1 × (7 - 1) - 1⌋ / 1) + 1 = 94\n",
            "The output data shape: torch.Size([32, 128, 94, 94])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuBqUPgPIKVi",
        "outputId": "2189ae66-4b4e-4960-99da-daf15406910c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Conv_layer1 = nn.Conv2d(3, 128, 7)\n",
        "output_res1 = Conv_layer1(fake_data)\n",
        "print(f\"The output data shape: {output_res1.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The output data shape: torch.Size([32, 128, 94, 94])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f2vbOvvIIiy",
        "cellView": "form",
        "outputId": "9894bb34-7d84-448c-bb30-247fecac98cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title `kernel_size` and `stride`\n",
        "kernel_size =   9#@param {type:\"integer\"}\n",
        "stride =   3#@param {type:\"integer\"}\n",
        "\n",
        "Conv_layer2 = nn.Conv2d(input_channels,\n",
        "                        output_channels, \n",
        "                        kernel_size, \n",
        "                        stride)\n",
        "output_res2 = Conv_layer2(fake_data)\n",
        "\n",
        "print(\"############### Try the following code... ###############\\n\")\n",
        "print(f\"Conv_layer2 = nn.Conv2d({input_channels}, \"\\\n",
        "      f\"{output_channels}, \"\\\n",
        "      f\"{kernel_size}, {stride})\")\n",
        "print(\"output_res2 = Conv_layer2(fake_data)\")\n",
        "print(\"print(f\\\"The output data shape: {output_res2.shape}\\\")\")\n",
        "print(\"\\n#########################################################\\n\")\n",
        "print(\"Output `H_out` =\",\n",
        "     f\"((⌊100 + 2 × 0 - 1 × ({kernel_size} - 1) - 1⌋ / {stride}) + 1 =\",\n",
        "      int((100 + 2 * 0 - 1 * (kernel_size - 1) - 1) / stride) + 1)\n",
        "print( \"The output data shape: \"\\\n",
        "      f\"{output_res2.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############### Try the following code... ###############\n",
            "\n",
            "Conv_layer2 = nn.Conv2d(3, 128, 9, 3)\n",
            "output_res2 = Conv_layer2(fake_data)\n",
            "print(f\"The output data shape: {output_res2.shape}\")\n",
            "\n",
            "#########################################################\n",
            "\n",
            "Output `H_out` = ((⌊100 + 2 × 0 - 1 × (9 - 1) - 1⌋ / 3) + 1 = 31\n",
            "The output data shape: torch.Size([32, 128, 31, 31])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq98yD4SIotg",
        "outputId": "e5d693bf-b2ef-464e-c64e-175a4199ef6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Conv_layer2 = nn.Conv2d(3, 128, 9, 3)\n",
        "output_res2 = Conv_layer2(fake_data)\n",
        "print(f\"The output data shape: {output_res2.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The output data shape: torch.Size([32, 128, 31, 31])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DkW5rpEIMuu",
        "cellView": "form",
        "outputId": "6c3b932c-5caa-4720-b0fd-63296baac656",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title `kernel_size` and `padding`\n",
        "kernel_size =   3#@param {type:\"integer\"}\n",
        "padding =   1#@param {type:\"integer\"}\n",
        "\n",
        "Conv_layer3 = nn.Conv2d(input_channels,\n",
        "                        output_channels, \n",
        "                        kernel_size, \n",
        "                        padding=padding)\n",
        "output_res3 = Conv_layer3(fake_data)\n",
        "\n",
        "print(\"############### Try the following code... ###############\\n\")\n",
        "print(f\"Conv_layer3 = nn.Conv2d({input_channels}, \"\\\n",
        "      f\"{output_channels}, \"\\\n",
        "      f\"{kernel_size}, padding={padding})\")\n",
        "print(\"output_res3 = Conv_layer3(fake_data)\")\n",
        "print(\"print(f\\\"The output data shape: {output_res3.shape}\\\")\")\n",
        "print(\"\\n#########################################################\\n\")\n",
        "print(\"Output `H_out` =\",\n",
        "     f\"⌊((100 + 2 × {padding} - 1 × ({kernel_size} - 1) - 1⌋ / 1) + 1 =\",\n",
        "      int((100 + 2 * padding - 1 * (kernel_size - 1) - 1) / 1) + 1)\n",
        "print( \"The output data shape: \"\\\n",
        "      f\"{output_res3.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############### Try the following code... ###############\n",
            "\n",
            "Conv_layer3 = nn.Conv2d(3, 128, 3, padding=1)\n",
            "output_res3 = Conv_layer3(fake_data)\n",
            "print(f\"The output data shape: {output_res3.shape}\")\n",
            "\n",
            "#########################################################\n",
            "\n",
            "Output `H_out` = ⌊((100 + 2 × 1 - 1 × (3 - 1) - 1⌋ / 1) + 1 = 100\n",
            "The output data shape: torch.Size([32, 128, 100, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqLDMa2tJttN",
        "outputId": "9a2464ac-92cf-4d44-8c75-d533fe3d619d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Conv_layer3 = nn.Conv2d(3, 128, 3, padding=1)\n",
        "output_res3 = Conv_layer3(fake_data)\n",
        "print(f\"The output data shape: {output_res3.shape}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The output data shape: torch.Size([32, 128, 100, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnVtzCTXIdZG",
        "cellView": "form",
        "outputId": "f0368612-a6bd-4547-cc6a-2b693bec3da9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title `kernel_size`, `stride` and `padding`\n",
        "kernel_size =   6#@param {type:\"integer\"}\n",
        "stride =   2#@param {type:\"integer\"}\n",
        "padding =   3#@param {type:\"integer\"}\n",
        "\n",
        "Conv_layer4 = nn.Conv2d(input_channels,\n",
        "                        output_channels, \n",
        "                        kernel_size, \n",
        "                        stride, \n",
        "                        padding)\n",
        "output_res4 = Conv_layer4(fake_data)\n",
        "\n",
        "print(\"############### Try the following code... ###############\\n\")\n",
        "print(f\"Conv_layer4 = nn.Conv2d({input_channels}, \"\\\n",
        "      f\"{output_channels}, \"\\\n",
        "      f\"{kernel_size}, {stride}, {padding})\")\n",
        "print(\"output_res4 = Conv_layer4(fake_data)\")\n",
        "print(\"print(f\\\"The output data shape: {output_res4.shape}\\\")\")\n",
        "print(\"\\n#########################################################\\n\")\n",
        "print(\"Output `H_out` =\",\n",
        "     f\"⌊((100 + 2 × {padding} - 1 × ({kernel_size} - 1) - 1⌋ / {stride}) + 1 =\",\n",
        "      int((100 + 2 * padding - 1 * (kernel_size - 1) - 1) / stride) + 1)\n",
        "print( \"The output data shape: \"\\\n",
        "      f\"{output_res4.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############### Try the following code... ###############\n",
            "\n",
            "Conv_layer4 = nn.Conv2d(3, 128, 6, 2, 3)\n",
            "output_res4 = Conv_layer4(fake_data)\n",
            "print(f\"The output data shape: {output_res4.shape}\")\n",
            "\n",
            "#########################################################\n",
            "\n",
            "Output `H_out` = ⌊((100 + 2 × 3 - 1 × (6 - 1) - 1⌋ / 2) + 1 = 51\n",
            "The output data shape: torch.Size([32, 128, 51, 51])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8cD2H3bJ4M3",
        "outputId": "02a99528-6e79-4396-b785-106eb6d7568b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Conv_layer4 = nn.Conv2d(3, 128, 6, 2, 3)\n",
        "output_res4 = Conv_layer4(fake_data)\n",
        "print(f\"The output data shape: {output_res4.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The output data shape: torch.Size([32, 128, 51, 51])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsdmyap1GSZT"
      },
      "source": [
        "##### Pooling layers\n",
        "`nn.MaxPool2d` -- Basic 2D Max Pooling Layer\n",
        "```python\n",
        "nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1)\n",
        "# stride default: kernel_size\n",
        "```\n",
        "Input shape: $(N, C, H_{in}, W_{in})$  \n",
        "Output shape: $(N, C, H_{out}, W_{out})$ where\n",
        "$$H_{out}=\\left \\lfloor \\cfrac{H_{in}+ 2 \\times \\text{padding}[0]-\\text{dilation}[0]\\times(\\text{kernel_size}[0]-1)-1}{\\text{stride}[0]} \\right \\rfloor+1$$\n",
        "$$W_{out}=\\left \\lfloor \\cfrac{H_{in}+ 2 \\times \\text{padding}[1]-\\text{dilation}[1]\\times(\\text{kernel_size}[1]-1)-1}{\\text{stride}[1]} \\right \\rfloor+1$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXOrl_um-3Kw",
        "outputId": "db0ccee6-5a94-46f3-ee2c-4f9c796e50f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fake_data = torch.randn(batch_size, 3, 100, 100)\n",
        "print(f\"The input data shape:  {fake_data.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The input data shape:  torch.Size([32, 3, 100, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzrOgrkjJBzm",
        "outputId": "501e457d-9f19-45bb-d017-2fdcd6014a83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Only `kernel_size` {display-mode:\"form\"}\n",
        "kernel_size =   6#@param {type:\"integer\"}\n",
        "\n",
        "MaxPool_layer1 = nn.MaxPool2d(kernel_size)\n",
        "output_res1 = MaxPool_layer1(fake_data)\n",
        "\n",
        "print(\"############### Try the following code... ###############\\n\")\n",
        "print(f\"MaxPool_layer1 = nn.MaxPool2d({kernel_size})\")\n",
        "print(\"output_res1 = MaxPool_layer1(fake_data)\")\n",
        "print(\"print(f\\\"The output data shape: {output_res1.shape}\\\")\")\n",
        "print(\"\\n#########################################################\\n\")\n",
        "\n",
        "print(\"Output `H_out` =\",\n",
        "     f\"⌊((100 + 2 × 0 - 1 × ({kernel_size} - 1) - 1) / {kernel_size}⌋ + 1 =\",\n",
        "      int((100 + 2 * 0 - 1 * (kernel_size - 1) - 1) / kernel_size) + 1)\n",
        "print(f\"The output data shape: {output_res1.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############### Try the following code... ###############\n",
            "\n",
            "MaxPool_layer1 = nn.MaxPool2d(6)\n",
            "output_res1 = MaxPool_layer1(fake_data)\n",
            "print(f\"The output data shape: {output_res1.shape}\")\n",
            "\n",
            "#########################################################\n",
            "\n",
            "Output `H_out` = ⌊((100 + 2 × 0 - 1 × (6 - 1) - 1) / 6⌋ + 1 = 16\n",
            "The output data shape: torch.Size([32, 3, 16, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZl6hfISMXAl",
        "outputId": "7e86b491-586f-4639-cc07-277b2b7d5e49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "MaxPool_layer1 = nn.MaxPool2d(6)\n",
        "output_res1 = MaxPool_layer1(fake_data)\n",
        "print(f\"The output data shape: {output_res1.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The output data shape: torch.Size([32, 3, 16, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKRzK602JWfi",
        "outputId": "ec425a58-0a4c-409c-fd0c-d5ee975b949a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# @title `kernel_size` ≠ `stride` {display-mode:\"form\"}\n",
        "kernel_size =   7#@param {type:\"integer\"}\n",
        "stride =   9#@param {type:\"integer\"}\n",
        "\n",
        "MaxPool_layer2 = nn.MaxPool2d(kernel_size, stride)\n",
        "output_res2 = MaxPool_layer2(fake_data)\n",
        "\n",
        "print(\"############### Try the following code... ###############\\n\")\n",
        "print(f\"MaxPool_layer2 = nn.MaxPool2d({kernel_size}, {stride})\")\n",
        "print(\"output_res2 = MaxPool_layer2(fake_data)\")\n",
        "print(\"print(f\\\"The output data shape: {output_res2.shape}\\\")\")\n",
        "print(\"\\n#########################################################\\n\")\n",
        "\n",
        "print(\"Output `H_out` =\",\n",
        "     f\"⌊((100 + 2 × 0 - 1 × ({kernel_size} - 1) - 1⌋ / {stride}) + 1 =\",\n",
        "      int((100 + 2 * 0 - 1 * (kernel_size - 1) - 1) / stride) + 1)\n",
        "print(f\"The output data shape: {output_res2.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############### Try the following code... ###############\n",
            "\n",
            "MaxPool_layer2 = nn.MaxPool2d(7, 9)\n",
            "output_res2 = MaxPool_layer2(fake_data)\n",
            "print(f\"The output data shape: {output_res2.shape}\")\n",
            "\n",
            "#########################################################\n",
            "\n",
            "Output `H_out` = ⌊((100 + 2 × 0 - 1 × (7 - 1) - 1⌋ / 9) + 1 = 11\n",
            "The output data shape: torch.Size([32, 3, 11, 11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyVEKMj-MrVy",
        "outputId": "b6ea9de5-5c26-4343-e164-629473efca94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "MaxPool_layer2 = nn.MaxPool2d(7, 9)\n",
        "output_res2 = MaxPool_layer2(fake_data)\n",
        "print(f\"The output data shape: {output_res2.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The output data shape: torch.Size([32, 3, 11, 11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfR1jjRbJW40",
        "cellView": "form",
        "outputId": "e65fe135-127b-4b19-d721-be486f60a84b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title `kernel_size`, `stride` and `padding`\n",
        "kernel_size =   5#@param {type:\"integer\"}\n",
        "stride =   3#@param {type:\"integer\"}\n",
        "padding =   2#@param {type:\"integer\"}\n",
        "\n",
        "MaxPool_layer3 = nn.MaxPool2d(kernel_size, stride, padding)\n",
        "output_res3 = MaxPool_layer3(fake_data)\n",
        "\n",
        "print(\"############### Try the following code... ###############\\n\")\n",
        "print(f\"MaxPool_layer3 = nn.MaxPool2d({kernel_size}, {stride}, {padding})\")\n",
        "print(\"output_res3 = MaxPool_layer3(fake_data)\")\n",
        "print(\"print(f\\\"The output data shape: {output_res3.shape}\\\")\")\n",
        "print(\"\\n#########################################################\\n\")\n",
        "\n",
        "print(\"Output `H_out` =\",\n",
        "     f\"⌊((100 + 2 × {padding} - 1 × ({kernel_size} - 1) - 1⌋ / {stride}) + 1 =\",\n",
        "      int((100 + 2 * padding - 1 * (kernel_size - 1) - 1) / stride) + 1)\n",
        "print( \"The output data shape: \"\\\n",
        "      f\"{output_res3.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############### Try the following code... ###############\n",
            "\n",
            "MaxPool_layer3 = nn.MaxPool2d(5, 3, 2)\n",
            "output_res3 = MaxPool_layer3(fake_data)\n",
            "print(f\"The output data shape: {output_res3.shape}\")\n",
            "\n",
            "#########################################################\n",
            "\n",
            "Output `H_out` = ⌊((100 + 2 × 2 - 1 × (5 - 1) - 1⌋ / 3) + 1 = 34\n",
            "The output data shape: torch.Size([32, 3, 34, 34])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOltRx-Wj7RC",
        "outputId": "8427b876-2b8a-43e2-ca5d-f51e19a0b550",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "MaxPool_layer3 = nn.MaxPool2d(5, 3, 2)\n",
        "output_res3 = MaxPool_layer3(fake_data)\n",
        "print(f\"The output data shape: {output_res3.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The output data shape: torch.Size([32, 3, 34, 34])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMAgHqGo7Yp7"
      },
      "source": [
        "#### 3) RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQDvf5JPNiCK"
      },
      "source": [
        "##### Embedding layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKKVZez-LdzN",
        "outputId": "da914f0f-e9eb-47a8-f38b-d1b9b32c3e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        }
      },
      "source": [
        "Embedding_layer = nn.Embedding(10, 3)\n",
        "fake_data = torch.LongTensor([[1, 2, 4, 5], [4, 3, 2, 9]])\n",
        "print(\"\"\"\n",
        "The input data shape:  {}\n",
        "The output data shape: {}\"\"\".format\n",
        "(fake_data.shape, Embedding_layer(fake_data).shape)[1:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The input data shape:  torch.Size([2, 4])\n",
            "The output data shape: torch.Size([2, 4, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPat3loG4Pzr"
      },
      "source": [
        "###### Loading Word2Vec models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyOwYeo-pztQ",
        "outputId": "85480b70-1b18-460e-8148-6f047024b321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "Embedding_layer = nn.Embedding(*(w2vmodel.wv.vectors.shape))\n",
        "Embedding_layer.weight = nn.Parameter(\n",
        "    torch.FloatTensor(w2vmodel.wv.vectors))\n",
        "fix_embedding = True\n",
        "Embedding_layer.weight.requires_grad = not fix_embedding\n",
        "\n",
        "word2index = {word: ind \\\n",
        "    for ind, word in enumerate(w2vmodel.wv.index2word)}\n",
        "print(\"Our embedding dimesion is {}.\".format(w2vmodel.wv.vector_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our embedding dimesion is 100.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pag-CrWAsccg",
        "outputId": "9a9fd41f-c689-426d-f79e-31ea97d61f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "sent_ori = \"The model is used for training.\"\n",
        "sent = sent_ori.replace('.', '').lower()\n",
        "list_of_indices = [word2index[w] for w in sent.split()]\n",
        "tensor_of_indices = torch.LongTensor(list_of_indices)\n",
        "\n",
        "print(\n",
        "    \"The sentence is:\\n   \\\"\", sent_ori + '\"',\n",
        "\"\"\"\\nWe pass {} tokens into the model,\n",
        "    which is treated as a LongTensor with shape \"{}\".\n",
        "The embedding layer transformed it to shape \"{}\".\n",
        "\"\"\".format(len(list_of_indices), \n",
        "           tensor_of_indices.shape, \n",
        "           Embedding_layer(tensor_of_indices).shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sentence is:\n",
            "   \" The model is used for training.\" \n",
            "We pass 6 tokens into the model,\n",
            "    which is treated as a LongTensor with shape \"torch.Size([6])\".\n",
            "The embedding layer transformed it to shape \"torch.Size([6, 100])\".\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cwZPgMeNhhh"
      },
      "source": [
        "##### RNN layers (LSTM, GRU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coKPYY8xMrsh",
        "outputId": "301612e3-aa2a-45ad-8fe6-a572b5af0aa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        }
      },
      "source": [
        "LSTM_layer = nn.LSTM(100, 80, 2)\n",
        "fake_data = torch.randn(5, 3, 100)\n",
        "h0 = torch.randn(2, 3, 80)\n",
        "c0 = torch.randn(2, 3, 80)\n",
        "output, (hn, cn) = LSTM_layer(fake_data, (h0, c0))\n",
        "print(\"\"\"Input shape: {}\n",
        "Output shape: {}\"\"\".format(\n",
        "fake_data.shape, (output.shape, (hn.shape, cn.shape))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([5, 3, 100])\n",
            "Output shape: (torch.Size([5, 3, 80]), (torch.Size([2, 3, 80]), torch.Size([2, 3, 80])))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCcCGtYMNMak",
        "outputId": "b4729192-9872-4894-b3a1-43706f723547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        }
      },
      "source": [
        "GRU_layer = nn.GRU(100, 80, 2)\n",
        "fake_data = torch.randn(5, 3, 100)\n",
        "h0 = torch.randn(2, 3, 80)\n",
        "output, hn = GRU_layer(fake_data, h0)\n",
        "print(\"\"\"Input shape: {}\n",
        "Output shape: {}\"\"\".format(\n",
        "fake_data.shape, (output.shape, hn.shape)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([5, 3, 100])\n",
            "Output shape: (torch.Size([5, 3, 80]), torch.Size([2, 3, 80]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmtM2cCF7Ylh"
      },
      "source": [
        "### 2 -- Activation functions  \n",
        "You have two choices for your activation functions:\n",
        "\n",
        "1. In `torch.nn`, we have model layer modules.  \n",
        "2. In `torch.nn.functionals`, we have function implementations of activation functions, loss functions, and so on.\n",
        "\n",
        "Just to list a few...  \n",
        "\n",
        "| activation function | `torch.nn as nn`                    | `torch.nn.functional as F` |\n",
        "|:-------------------:| ----------------------------------- | -------------------------- |\n",
        "| Sigmoid             | `nn.Sigmoid()`                      | `F.sigmoid`                |\n",
        "| Softmax             | `nn.Softmax(dim=None)`              | `F.softmax`                |\n",
        "| ReLU                | `nn.ReLU()`                         | `F.relu`                   |\n",
        "| LeakyReLU           | `nn.LeakyReLU(negative_slope=0.01)` | `F.leaky_relu`             |\n",
        "| Tanh                | `nn.Tanh()`                         | `F.tanh`                   |\n",
        "| GELU                | `nn.GELU()`                         | `F.gelu`                   |\n",
        "| ReLU6               | `nn.ReLU6()`                        | `F.relu6`                  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHpBXmxe7L0u"
      },
      "source": [
        "<h2>Python Tips</h2>  \n",
        "<h3>Functions vs. Objects</h3>  \n",
        "\n",
        "What you get from calling `nn.Sigmoid()` (and others...) is an <b><mark>object</mark></b> initialized from the module.  \n",
        "Hence, if you want to pass a tensor to that \"layer object\", you should write this:\n",
        "\n",
        "```python\n",
        "# `x` is a tensor.\n",
        "activation = nn.Sigmoid() # Note that this is a \"constructor\"!\n",
        "out = activation(x)       # i.e. `out = nn.Sigmoid()(x)` is valid,\n",
        "                          # but the object is discarded if you do that.\n",
        "```\n",
        "\n",
        "On the other hand, if you simply want to use functions, do this:\n",
        "```python\n",
        "# `x` is a tensor.\n",
        "out = F.sigmoid(x)        # Since `F.sigmoid` is already a \"function\"!\n",
        "```\n",
        "\n",
        "For most time, <b><mark>both are valid</mark></b>. It's just two coding styles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV9A1pzmccJz"
      },
      "source": [
        "### 3 -- Loss functions\n",
        "Here, you also have two choices for your loss functions:\n",
        "\n",
        "| loss functions              | `torch.nn as nn`     | `torch.nn.functional as F`\n",
        "|:--------------------------- | -------------------- | ----------------------------------------\n",
        "| Mean Square Error           | `MSELoss()`          | `F.mse_loss(input, target)`\n",
        "| Cross Entropy (Multi-label) | `CrossEntropyLoss()` | `F.cross_entropy(input, target)`\n",
        "| Binary Cross Entropy        | `BCELoss()`          | `F.binary_cross_entropy(input, target)`\n",
        "| Negative Log Likelihood     | `NLLLoss()`          | `F.nll_loss(F.log_softmax(input), target)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd2G9CUd7Yhu"
      },
      "source": [
        "### 4 -- 優化器 --- Optimizers\n",
        "用來更新參數的方法（`SGD`、`Adagrad`、`Adam`⋯⋯）  \n",
        "在 PyTorch 中要經過 `backward()` 函數計算 gradient，  \n",
        "而在這之前要先用 `optim.zero_grad()` 將 gradient 清掉，否則 PyTorch 會將 gradient 累加起來\n",
        "\n",
        "（以下請注意 model 參數更新的方向）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OmtknIqNrTx",
        "outputId": "aecc0b71-dcf5-4eec-9f85-74ca7df264f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        }
      },
      "source": [
        "small_model = nn.Linear(3, 7)\n",
        "\n",
        "print(\"Take a look at model params:\")\n",
        "print(small_model.weight)\n",
        "\n",
        "X, Y = torch.rand(3,), torch.rand(7,)\n",
        "print(\"\\nGiven input X:\")\n",
        "print(X)\n",
        "\n",
        "print(\"\\nAnd target Y:\")\n",
        "print(Y)\n",
        "\n",
        "optim = torch.optim.SGD(\n",
        "    small_model.parameters(), lr=1e-2)\n",
        "mse_loss = nn.MSELoss()\n",
        "\n",
        "print(\"\\nThe output Y:\")\n",
        "temp_Y = small_model(X)\n",
        "print(temp_Y)\n",
        "\n",
        "\n",
        "print(\"\\nCalculate their MSE Loss = \", end='')\n",
        "loss = mse_loss(temp_Y, Y)\n",
        "print(loss.item())\n",
        "\n",
        "print(\"\\n##### Update a step! #####\")\n",
        "optim.zero_grad()\n",
        "loss.backward()\n",
        "optim.step()\n",
        "\n",
        "print(\"\\nTake a look at \\\"updated\\\"model params:\")\n",
        "print(small_model.weight)\n",
        "updated_params = small_model.weight.data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Take a look at model params:\n",
            "Parameter containing:\n",
            "tensor([[ 0.2741, -0.0400,  0.3174],\n",
            "        [ 0.4538, -0.2445, -0.1900],\n",
            "        [ 0.0368,  0.3594, -0.2954],\n",
            "        [-0.3002, -0.1828,  0.5202],\n",
            "        [-0.0783, -0.5013, -0.1427],\n",
            "        [ 0.0558,  0.2025,  0.0199],\n",
            "        [-0.1796,  0.2220, -0.0274]], requires_grad=True)\n",
            "\n",
            "Given input X:\n",
            "tensor([0.6425, 0.5494, 0.2037])\n",
            "\n",
            "And target Y:\n",
            "tensor([0.3314, 0.3200, 0.2782, 0.9563, 0.9515, 0.4855, 0.1262])\n",
            "\n",
            "The output Y:\n",
            "tensor([-0.2295,  0.1076,  0.6899,  0.0077, -0.4212,  0.2130,  0.0091],\n",
            "       grad_fn=<AddBackward0>)\n",
            "\n",
            "Calculate their MSE Loss = 0.4859066605567932\n",
            "\n",
            "##### Update a step! #####\n",
            "\n",
            "Take a look at \"updated\"model params:\n",
            "Parameter containing:\n",
            "tensor([[ 0.2751, -0.0392,  0.3177],\n",
            "        [ 0.4542, -0.2441, -0.1899],\n",
            "        [ 0.0361,  0.3588, -0.2956],\n",
            "        [-0.2985, -0.1814,  0.5207],\n",
            "        [-0.0758, -0.4992, -0.1419],\n",
            "        [ 0.0563,  0.2029,  0.0201],\n",
            "        [-0.1794,  0.2222, -0.0273]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EUFDLr47Yew"
      },
      "source": [
        "### 5 -- Normalization\n",
        "PyTorch 提供不少 normalization 的方法，在初期用得到的主要是 CNN 的 batch normalization\n",
        "```python\n",
        "nn.BatchNorm2d(num_features)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7WbSDYi58em"
      },
      "source": [
        "## 3. Training (Validation) / Fine-Tuning\n",
        "先像上面一樣處理隨機資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMUe-7UtjRLZ"
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Training\n",
        "X = np.random.rand(1000, 100, 100, 1)   # 虛構 1000 張 100 x 100 單色圖片\n",
        "Y = np.random.randint(0, 7, [1000, 10]) # 虛構 1000 個 labels\n",
        "\n",
        "X, Y = X.astype(np.float32), Y.astype(np.float32)\n",
        "tsrX, tsrY = torch.tensor(X), torch.tensor(Y)\n",
        "tsrdataset = TensorDataset(tsrX, tsrY)\n",
        "\n",
        "tsrdataloader = DataLoader(\n",
        "    tsrdataset, batch_size=4,\n",
        "    shuffle=True, num_workers=4)\n",
        "\n",
        "# Validation\n",
        "vX = np.random.rand(100, 100, 100, 1)   # 虛構 100 張 100 x 100 單色圖片\n",
        "vY = np.random.randint(0, 7, [100, 10]) # 虛構 100 個 labels\n",
        "\n",
        "vX, vY = vX.astype(np.float32), vY.astype(np.float32)\n",
        "vtsrX, vtsrY = torch.tensor(vX), torch.tensor(vY)\n",
        "vtsrdataset = TensorDataset(tsrX, tsrY)\n",
        "\n",
        "vtsrdataloader = DataLoader(\n",
        "    vtsrdataset, batch_size=4,\n",
        "    shuffle=False, num_workers=4) # Validation 不需要 shuffle\n",
        "\n",
        "# Testing\n",
        "tX = np.random.rand(100, 100, 100, 1)   # 虛構 100 張 100 x 100 單色圖片\n",
        "tY = np.random.randint(0, 7, [100, 10]) # 虛構 100 個 labels\n",
        "\n",
        "tX, tY = tX.astype(np.float32), tY.astype(np.float32)\n",
        "ttsrX, ttsrY = torch.tensor(tX), torch.tensor(tY)\n",
        "ttsrdataset = TensorDataset(tsrX, tsrY)\n",
        "\n",
        "ttsrdataloader = DataLoader(\n",
        "    ttsrdataset, batch_size=4,\n",
        "    shuffle=False, num_workers=4) # Testing 不需要 shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEUcLJDCeV_8"
      },
      "source": [
        "在訓練之前，先根據我們前面全部的東西搭一個簡單的 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bugYSmh-ecff"
      },
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(10000, 500),\n",
        "            nn.Linear(500, 10))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 傳入 model 的函數會經過 forward 做 inference\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "simpleNN = SimpleNN()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jra3IUz1fXKv"
      },
      "source": [
        "接著準備 optimizer 跟 loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpuO56Pzg41-"
      },
      "source": [
        "optim = torch.optim.Adam(simpleNN.parameters(),\n",
        "                         lr=1e-4)\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4fg9Iwrif89"
      },
      "source": [
        "接著進入 training  \n",
        "Training 的本質就是跑一個迴圈，在每一次（叫一個 **epoch**）要做的事有——\n",
        "1. 載入資料\n",
        "1. 經過 model 跑一次\n",
        "1. 比對資料的正確性，算誤差（loss）\n",
        "1. 把梯度清掉，然後根據這次誤差算新的梯度\n",
        "1. 根據 optimizer 更新參數\n",
        "1. 為了方便觀察，將本次 epoch 訓練的變化顯示出來，包括\n",
        "    - 進度條（觀察訓練快慢）\n",
        "    - batch loss （這個有時候會輸出太多東西）\n",
        "    - epoch loss （記得累計並除掉資料數量）\n",
        "    - 記錄到其他變數中（方便作圖）\n",
        "    - 記錄到 Tensorboard 中（SummaryWriter）\n",
        "\n",
        "為了避免 overfit，我們每個 epoch 還會進行一次 validation，事情少一些，變成——\n",
        "1. 載入資料\n",
        "1. 經過 model 跑一次\n",
        "1. 比對資料的正確性，算誤差（loss）\n",
        "1. 為了方便觀察，將本次 epoch validate 的結果顯示出來，包括\n",
        "    - 進度條（觀察訓練快慢）\n",
        "    - batch loss （這個有時候會輸出太多東西）\n",
        "    - epoch loss （記得累計並除掉資料數量）\n",
        "    - 記錄到其他變數中（方便作圖）\n",
        "    - 記錄到 Tensorboard 中（SummaryWriter）\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g0elfvzbVzm",
        "outputId": "877dd0dd-6d6c-40bc-f3b2-e294c341ea9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "    simpleNN.train()\n",
        "    epoch_loss = 0.0\n",
        "    for x, y in tsrdataloader:\n",
        "        y_hat = simpleNN(x)\n",
        "        loss = criterion(y, y_hat)\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        epoch_loss += loss.item()\n",
        "    average_epoch_loss = epoch_loss / len(tsrdataset)\n",
        "    print(f\"Training   Epoch {epoch + 1:2d}: Loss = {average_epoch_loss:.4f}\")\n",
        "\n",
        "    simpleNN.eval()\n",
        "    vepoch_loss = 0.0\n",
        "    for x, y in vtsrdataloader:\n",
        "        y_hat = simpleNN(x)\n",
        "        loss = criterion(y, y_hat)\n",
        "        vepoch_loss += loss.item()\n",
        "    vaverage_epoch_loss = vepoch_loss / len(vtsrdataset)\n",
        "    print(f\"Validation Epoch {epoch + 1:2d}: Loss = {vaverage_epoch_loss:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training   Epoch  1: Loss = 1.1976\n",
            "Validation Epoch  1: Loss = 0.8974\n",
            "Training   Epoch  2: Loss = 0.9631\n",
            "Validation Epoch  2: Loss = 0.8561\n",
            "Training   Epoch  3: Loss = 0.7902\n",
            "Validation Epoch  3: Loss = 0.6162\n",
            "Training   Epoch  4: Loss = 0.6237\n",
            "Validation Epoch  4: Loss = 0.5360\n",
            "Training   Epoch  5: Loss = 0.4898\n",
            "Validation Epoch  5: Loss = 0.3594\n",
            "Training   Epoch  6: Loss = 0.3460\n",
            "Validation Epoch  6: Loss = 0.2413\n",
            "Training   Epoch  7: Loss = 0.2222\n",
            "Validation Epoch  7: Loss = 0.1503\n",
            "Training   Epoch  8: Loss = 0.1479\n",
            "Validation Epoch  8: Loss = 0.1421\n",
            "Training   Epoch  9: Loss = 0.0847\n",
            "Validation Epoch  9: Loss = 0.0547\n",
            "Training   Epoch 10: Loss = 0.0500\n",
            "Validation Epoch 10: Loss = 0.0412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IznmTeyXkvjx"
      },
      "source": [
        "嘛⋯⋯畢竟是隨機生成的，所以發生 overfit 什麼的也不要太意外，不過有時好像會 train 起來？？！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgwtsGu9rSJM"
      },
      "source": [
        "覺得跑很慢嗎？我們有 GPU 為什麼不用呢？？！來看看怎麼用！"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqcXZMZ3pzmZ",
        "outputId": "3f07b555-c3b8-411f-dbd6-f4509237d225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device # Check if GPU available\n",
        "# 其實寫 x.to(device) 之外也可以寫 x.cuda()\n",
        "# 但是前者會自動根據環境決定是否使用 GPU 比較彈性"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LthwGZG1ptSE",
        "outputId": "10cec8cf-c3a6-4aeb-ad85-a7cf20064a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "simpleNN = SimpleNN()\n",
        "simpleNN.to(device)                           # 把 model 移到 GPU 計算\n",
        "optim = torch.optim.Adam(\n",
        "    simpleNN.parameters(), lr=1e-4)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "    simpleNN.train()\n",
        "    epoch_loss = 0.0\n",
        "    for x, y in tsrdataloader:\n",
        "        y_hat = simpleNN(x.to(device))        # 把 x tensor 移到 GPU 計算\n",
        "        loss = criterion(y.to(device), y_hat) # 把 y tensor 移到 GPU 計算，\n",
        "                                              ##  y_hat 因為是從 GPU model input GPU Tensor 出來的\n",
        "                                              ##  所以不用再次 .to(device) 當然要也是沒差啦 =_=|||\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        epoch_loss += loss.item()\n",
        "    average_epoch_loss = epoch_loss / len(tsrdataset)\n",
        "    print(f\"Training   Epoch {epoch + 1:2d}: Loss = {average_epoch_loss:.4f}\")\n",
        "\n",
        "    simpleNN.eval()\n",
        "    vepoch_loss = 0.0\n",
        "    for x, y in vtsrdataloader:\n",
        "        y_hat = simpleNN(x.to(device))\n",
        "        loss = criterion(y.to(device), y_hat)\n",
        "        vepoch_loss += loss.item()\n",
        "    vaverage_epoch_loss = vepoch_loss / len(vtsrdataset)\n",
        "    print(f\"Validation Epoch {epoch + 1:2d}: Loss = {vaverage_epoch_loss:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training   Epoch  1: Loss = 1.1831\n",
            "Validation Epoch  1: Loss = 0.9545\n",
            "Training   Epoch  2: Loss = 0.9413\n",
            "Validation Epoch  2: Loss = 0.8006\n",
            "Training   Epoch  3: Loss = 0.7970\n",
            "Validation Epoch  3: Loss = 0.5749\n",
            "Training   Epoch  4: Loss = 0.6074\n",
            "Validation Epoch  4: Loss = 0.4643\n",
            "Training   Epoch  5: Loss = 0.4606\n",
            "Validation Epoch  5: Loss = 0.3617\n",
            "Training   Epoch  6: Loss = 0.3210\n",
            "Validation Epoch  6: Loss = 0.2529\n",
            "Training   Epoch  7: Loss = 0.2151\n",
            "Validation Epoch  7: Loss = 0.1599\n",
            "Training   Epoch  8: Loss = 0.1299\n",
            "Validation Epoch  8: Loss = 0.0795\n",
            "Training   Epoch  9: Loss = 0.0788\n",
            "Validation Epoch  9: Loss = 0.0532\n",
            "Training   Epoch 10: Loss = 0.0456\n",
            "Validation Epoch 10: Loss = 0.0273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqDZoYUksCUW"
      },
      "source": [
        "<h1><mark><b><large>快多了是吧！</large></b></mark></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze0HjceW6AG3"
      },
      "source": [
        "### -- Model saving / loading (checkpoints)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz1W_II3lBND",
        "outputId": "ace93670-d343-4105-954f-bca28533fd79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "# Save model\n",
        "simpleNN.cpu() # 先移回 CPU\n",
        "torch.save(simpleNN.state_dict(), \"randmodel.model\")\n",
        "\n",
        "# Load model\n",
        "model2 = SimpleNN()\n",
        "model2.load_state_dict(torch.load(\"randmodel.model\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9ABfP3MmKCY",
        "outputId": "b87b6272-6ff8-467d-e4a4-012dcaeef958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "# 確認是同一個 model\n",
        "torch.equal(model2(x), simpleNN(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUK-O-GY6FVy"
      },
      "source": [
        "## 4. Testing / Evaluation\n",
        "這裡當然也可以開 GPU，用法相同"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npxKbf5Ul7Er",
        "outputId": "af9d2c26-3b08-415b-ae67-1fd1c90ed28b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "simpleNN.eval()\n",
        "tepoch_loss = 0.0\n",
        "for x, y in ttsrdataloader:\n",
        "    y_hat = simpleNN(x)\n",
        "    loss = criterion(y, y_hat)\n",
        "    tepoch_loss += loss.item()\n",
        "taverage_epoch_loss = tepoch_loss / len(ttsrdataset)\n",
        "print(f\"Testing Loss = {taverage_epoch_loss:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Loss = 0.0273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q1r0Lg26HNj"
      },
      "source": [
        "## 5. Result Post-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9HBQxKP6Yyt"
      },
      "source": [
        "### 1 -- Saving files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYuxFVTAmkjg"
      },
      "source": [
        "with open(\"loss.txt\", 'w') as f: f.write(str(taverage_epoch_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L-mSYC8muk0"
      },
      "source": [
        "如果已經把答案存成一個 np.array 或 list，叫做 `answer`\n",
        "\n",
        "```python\n",
        "with open(\"result.csv\", 'w') as f:\n",
        "    f.write(\"index,ans\\n\")\n",
        "    for idx, i in enumerate(answer):\n",
        "        f.write(f\"{idx},{i}\\n\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cilhJCF46Zql"
      },
      "source": [
        "### 2 -- Kaggle Upload\n",
        "Kaggle 有提供方便的 API 可以直接在 Colab 或是 terminal 上傳，只要先弄好 token，以下列指令\n",
        "```bash\n",
        "kaggle competitions submit -c <competition_name> -f <filename> -m <message>\n",
        "```\n",
        "就可以上傳，例如作業３\n",
        "```bash\n",
        "kaggle competitions submit -c ml2020spring-hw3 -f result.csv -m \"The first try!\"\n",
        "```\n",
        "\n",
        "另外要看自己的 submissions\n",
        "```bash\n",
        "# kaggle competitions submissions -c <competition_name>\n",
        "  kaggle competitions submissions -c ml2020spring-hw3\n",
        "```\n",
        "或是排行榜\n",
        "```bash\n",
        "# kaggle competitions leaderboard -c <competition_name> --show\n",
        "  kaggle competitions leaderboard -c ml2020spring-hw3 --show\n",
        "```\n",
        "（記得把競賽名對應改掉）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AdyUvvT6boQ"
      },
      "source": [
        "### 3 -- Colaboratory / Kaggle Notebook\n",
        "\n",
        "你現在在用的這個環境本質是 Jupyter Notebook，Kaggle 也有提供一樣的環境可以操作   \n",
        "（不過在比賽中還是不要用的好，大家都想先藏招嘛！ B-) ） \n",
        "\n",
        "![](https://i.imgur.com/YCiTKl9.png)\n",
        "\n",
        "另外 Jupyter Notebook 也是可以開本地端的（如去年和前年有 DeepQ 贊助運算資源即是以此為介面）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrSF0P5B6ekR"
      },
      "source": [
        "## 6. Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYD2Usl46dn8"
      },
      "source": [
        "### TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW_cttzIvrGP"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjNRR0ivvmLY"
      },
      "source": [
        "import os\n",
        "logs_base_dir = \"runs\"\n",
        "os.makedirs(logs_base_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trt16rnNv2bd"
      },
      "source": [
        "%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBEcd4eOv4Ra"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "tb = SummaryWriter()\n",
        "\n",
        "simpleNN = SimpleNN()\n",
        "simpleNN.to(device)                           # 把 model 移到 GPU 計算\n",
        "optim = torch.optim.Adam(\n",
        "    simpleNN.parameters(), lr=1e-4)\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "EPOCHS = 100\n",
        "for epoch in range(EPOCHS):\n",
        "    simpleNN.train()\n",
        "    epoch_loss = 0.0\n",
        "    for x, y in tsrdataloader:\n",
        "        y_hat = simpleNN(x.to(device))        # 把 x tensor 移到 GPU 計算\n",
        "        loss = criterion(y.to(device), y_hat) # 把 y tensor 移到 GPU 計算，\n",
        "                                              ##  y_hat 因為是從 GPU model input GPU Tensor 出來的\n",
        "                                              ##  所以不用再次 .to(device) 當然要也是沒差啦 =_=|||\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        epoch_loss += loss.item()\n",
        "    average_epoch_loss = epoch_loss / len(tsrdataset)\n",
        "    print(f\"Training   Epoch {epoch + 1:2d}: Loss = {average_epoch_loss:.4f}\")\n",
        "    tb.add_scalar(\"Loss/train\", average_epoch_loss, epoch + 1)\n",
        "\n",
        "    simpleNN.eval()\n",
        "    vepoch_loss = 0.0\n",
        "    for x, y in vtsrdataloader:\n",
        "        y_hat = simpleNN(x.to(device))\n",
        "        loss = criterion(y.to(device), y_hat)\n",
        "        vepoch_loss += loss.item()\n",
        "    vaverage_epoch_loss = vepoch_loss / len(vtsrdataset)\n",
        "    print(f\"Validation Epoch {epoch + 1:2d}: Loss = {vaverage_epoch_loss:.4f}\")\n",
        "    tb.add_scalar(\"Loss/val\", vaverage_epoch_loss, epoch + 1)\n",
        "tb.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j2GnfV06VMv"
      },
      "source": [
        "應該會像這樣子（左下角只會有一個顏色才是，此處請忽略）\n",
        "![](https://i.imgur.com/25qVrAH.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5STIsoi6f_U"
      },
      "source": [
        "## 7. GPU Usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy29jcKcYtrJ",
        "outputId": "2f73abf3-9bf9-4942-fd8b-a1c170034418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "%%bash\n",
        "nvidia-smi\n",
        "echo\n",
        "echo \"沒有跑出來請看下面\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Mar 25 22:22:23 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    32W / 250W |    877MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "\n",
            "沒有跑出來請看下面\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ahXAybO6fXV"
      },
      "source": [
        "### 1 -- Colaboratory\n",
        "1. 如果不知道怎麼切 GPU 的，看左上角  \n",
        "   ![](https://i.imgur.com/ZuZSvKe.png)  \n",
        "\n",
        "2. 然後  \n",
        "   ![](https://i.imgur.com/wLmRD3V.png)  \n",
        "   其實還有 TPU 可以用，就自己去研究吧！\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvK9BuKv6dFx"
      },
      "source": [
        "### 2 -- PBS Usage\n",
        "[這裡](https://asciinema.org/a/T10wcvFwIzXgH4ZdERexBjtKa)有我之前錄製的用法，如果有人有機會用到計中或臺灣杉之類的排程工作站可以學一下"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCgdnESxt6tg",
        "outputId": "90b260fb-43ff-49c2-c502-93dffc893028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        }
      },
      "source": [
        "%%html\n",
        "<script id=\"asciicast-T10wcvFwIzXgH4ZdERexBjtKa\" src=\"https://asciinema.org/a/T10wcvFwIzXgH4ZdERexBjtKa.js\" async></script>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<script id=\"asciicast-T10wcvFwIzXgH4ZdERexBjtKa\" src=\"https://asciinema.org/a/T10wcvFwIzXgH4ZdERexBjtKa.js\" async></script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSOcvJvvSKK0"
      },
      "source": [
        "## TODO for next version\n",
        "- [ ] argparse\n",
        "- [ ] Transformer 用法\n",
        "- [ ] Colab 其他進階用法 \n",
        "\n",
        "### Useful tips\n",
        "-  Save at best\n",
        "-  Early Stopping\n",
        "-  Learning rate scheduler\n",
        "\n",
        "### Visualization\n",
        "-  Matplotlib Usage\n",
        "\n",
        "### Jupyter / VSCode （Connect to runtime）\n",
        "\n",
        "### More Examples\n",
        "- [ ] MNIST"
      ]
    }
  ]
}