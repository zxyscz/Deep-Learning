{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorchCookBook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP36+rBMFGklHrctzIX6hs5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linghduoduo/Deep-Learning/blob/master/PyTorchCookBook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvp3_28dNAtZ"
      },
      "source": [
        "import collections\n",
        "import os\n",
        "import shutil\n",
        "import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUbOR6muNKxr"
      },
      "source": [
        "import numpy as np\n",
        "import PIL.Image\n",
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OLGPJXRTNVKw",
        "outputId": "f8e95489-781f-480e-f513-8c615a5733fa"
      },
      "source": [
        "torch.__version__\n",
        "torch.version.cuda\n",
        "torch.backends.cudnn.version()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laFCG4XKN5pO"
      },
      "source": [
        "固定随机种子"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGtkaWXBNg7b"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTFckrh2OFTP"
      },
      "source": [
        "指定程序运行在特定 GPU 卡上 在命令行指定环境变量"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNygdyL7N3h7"
      },
      "source": [
        "CUDA_VISIBLE_DEVICES=0,1 python train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UxNSclvOfnX"
      },
      "source": [
        "指定程序运行在特定  在代码中指定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olefp2WIOXWv"
      },
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiTVWpSJOdO6"
      },
      "source": [
        "判断是否有 CUDA 支持"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW8behUfO3o-",
        "outputId": "757e7b8c-0d98-46f2-c02d-9650be701ed6"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz8N7DxXO9fe"
      },
      "source": [
        "设置为 cuDNN benchmark 模式.  Benchmark 模式会提升计算速度，但是由于计算中有随机性，每次网络前馈结果略有差异。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8X3EU78PEOo"
      },
      "source": [
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgw5AUJDPMtW"
      },
      "source": [
        "如果想要避免这种结果波动，设置"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xa4kvtsPO_w"
      },
      "source": [
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD6H6T0sPI0I"
      },
      "source": [
        "清除 GPU 存储 - 有时 Control-C 中止运行后 GPU 存储没有及时释放，需要手动清空。在 PyTorch 内部可以"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D6SH-kqPkeP"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M685I0McPs5i"
      },
      "source": [
        "或在命令行可以先使用 ps 找到程序的 PID，再使用 kill 结束该进程\n",
        "\n",
        "ps aux | grep pythonkill -9 [pid]\n",
        "\n",
        "或者直接重置没有被清空的 GPU\n",
        "\n",
        "nvidia-smi --gpu-reset -i [gpu_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXtj4So-RXD7"
      },
      "source": [
        "张量基本信息"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Uv-0LIUlPgUd",
        "outputId": "65c3c4d3-5653-4518-f946-974363a8ee8a"
      },
      "source": [
        "a = torch.tensor([1,2,3,4,5])\n",
        "a.type()   # Data type"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'torch.LongTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPtUsqnDRWMv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KKI1MJjQehx",
        "outputId": "c0de26d7-c17c-481a-d06c-9ff4e9f3c83d"
      },
      "source": [
        "a.size()   # Shape of the tensor. It is a subclass of Python tuple"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwzYstS-RL6m",
        "outputId": "5508c5e7-91e8-4cec-c34c-0f97656aed95"
      },
      "source": [
        "a.dim()    # Number of dimensions."
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFUXItuRRddy"
      },
      "source": [
        "数据类型转换"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5stvtMTReI4"
      },
      "source": [
        "# Set default tensor type. Float in PyTorch is much faster than double.\n",
        "torch.set_default_tensor_type(torch.FloatTensor)\n",
        "\n",
        "tensor = torch.rand(10)\n",
        "\n",
        "# Type convertions.\n",
        "tensor = tensor.cuda()\n",
        "tensor = tensor.cpu()\n",
        "tensor = tensor.float()\n",
        "tensor = tensor.long()\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMEq-KSaSrNJ"
      },
      "source": [
        "torch.Tensor 与 np.ndarray 转换"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P2pZt1PRhe6"
      },
      "source": [
        "# torch.Tensor -> np.ndarray.\n",
        "ndarray = tensor.cpu().numpy()\n",
        "\n",
        "# np.ndarray -> torch.Tensor.\n",
        "tensor = torch.from_numpy(ndarray).float()\n",
        "tensor = torch.from_numpy(ndarray.copy()).float()  # If ndarray has negative stride"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Yocgj1yTENl"
      },
      "source": [
        "torch.Tensor 与 PIL.Image 转换"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_EPuwMFTLr7"
      },
      "source": [
        "PyTorch 中的张量默认采用 N×D×H×W 的顺序，并且数据范围在 [0, 1]，需要进行转置和规范化。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAO4gNmESdPL"
      },
      "source": [
        "from torchvision.transforms import ToPILImage \n",
        "\n",
        "# torch.Tensor -> PIL.Image.\n",
        "\n",
        "tensor = torch.randn(3, 256, 256) # 64 images here\n",
        "img = ToPILImage()(tensor)\n",
        "\n",
        "\n",
        "# image = PIL.Image.fromarray(torch.clamp(tensor * 255, min=0, max=255).byte().permute(1, 2, 0).cpu().numpy())\n",
        "# image = torchvision.transforms.functional.to_pil_image(tensor)  # Equivalently way\n",
        "\n",
        "# # PIL.Image -> torch.Tensor.\n",
        "# tensor = torch.from_numpy(np.asarray(PIL.Image.open(path))).permute(2, 0, 1).float() / 255\n",
        "# tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path))  # Equivalently way\n",
        "# img = tensor.fromarray((255*imgs[i].permute(1, 2, 0)).numpy().astype(np.uint8))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_aV07GpVo0S"
      },
      "source": [
        "np.ndarray 与 PIL.Image 转换"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttiABY7uSevX"
      },
      "source": [
        "# np.ndarray -> PIL.Image.\n",
        "image = PIL.Image.fromarray(ndarray.astypde(np.uint8))\n",
        "\n",
        "# PIL.Image -> np.ndarray.\n",
        "ndarray = np.asarray(PIL.Image.open(path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOZxkbaPWvfL",
        "outputId": "52abd898-957c-4d9d-bf79-f154a266d128"
      },
      "source": [
        "torch.mean(torch.mean(tensor, dim=0)).item()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0003451622906140983"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8gl1g0yXhto"
      },
      "source": [
        "张量形变常常需要用于将卷积层特征输入全连接层的情形。相比 torch.view，torch.reshape 可以自动处理输入张量不连续的情况。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZpi18z8XcGc"
      },
      "source": [
        "tensor = torch.reshape(tensor, (1, -1))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jn9z2adXz-R"
      },
      "source": [
        "打乱顺序"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMay4MUOXvCI"
      },
      "source": [
        "tensor = tensor[torch.randperm(tensor.size(0))]  # Shuffle the first dimension"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czvQY99UX5oV"
      },
      "source": [
        "水平翻转 -PyTorch 不支持 tensor[::-1] 这样的负步长操作，水平翻转可以用张量索引实现。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FDUS3s7YZBT"
      },
      "source": [
        "# Assume tensor has shape N*D*H*W.\n",
        "tensor = tensor[:, :, :, torch.arange(tensor.size(3) - 1, -1, -1).long()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDuvEPlhYjY7"
      },
      "source": [
        "复制张量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-n8DeabX_Ny",
        "outputId": "6f0b7b57-32eb-466b-d0cc-ceb0713fc885"
      },
      "source": [
        "# Operation                 |  New/Shared memory | Still in computation graph |\n",
        "tensor.clone()            # |        New         |          Yes               |\n",
        "tensor.detach()           # |      Shared        |          No                |\n",
        "#tensor.detach.clone()()   # |        New         |          No                |"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2622, -0.3164, -0.4101,  ...,  1.1204, -0.7937,  0.4344]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zlBSqN1Y3As"
      },
      "source": [
        "拼接张量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbHyqFegZI2N"
      },
      "source": [
        "tensor = torch.cat(list_of_tensors, dim=0)\n",
        "tensor = torch.stack(list_of_tensors, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TPAzr8bZK4C"
      },
      "source": [
        "将整数标记转换成独热（one-hot）编码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqeVrDAaZfgb"
      },
      "source": [
        "N = tensor.size(0)\n",
        "one_hot = torch.zeros(N, num_classes).long()\n",
        "one_hot.scatter_(dim=1, index=torch.unsqueeze(tensor, dim=1), src=torch.ones(N, num_classes).long())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz3pwcxyZn1g"
      },
      "source": [
        "得到非零/零元素"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3t7Jj4yZhjc",
        "outputId": "74729c31-a541-4d13-e54d-7781915cc4ed"
      },
      "source": [
        "torch.nonzero(tensor)               # Index of non-zero elements\n",
        "torch.nonzero(tensor == 0)          # Index of zero elements\n",
        "torch.nonzero(tensor).size(0)       # Number of non-zero elements\n",
        "torch.nonzero(tensor == 0).size(0)  # Number of zero elements"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5kYxC1UZsbh"
      },
      "source": [
        "张量扩展"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi-_VfSdZuhr"
      },
      "source": [
        "# Expand tensor of shape 64*512 to shape 64*512*7*7.\n",
        "tensor = torch.rand(64, 512)\n",
        "extended_tensor = torch.reshape(tensor, (64, 512, 1, 1)).expand(64, 512, 7, 7)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJcdp2ysadnW"
      },
      "source": [
        "矩阵乘法\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6AKi0C2aB06"
      },
      "source": [
        "# Matrix multiplication: (m*n) * (n*p) -> (m*p).\n",
        "result = torch.mm(tensor1, tensor2)\n",
        "\n",
        "# Batch matrix multiplication: (b*m*n) * (b*n*p) -> (b*m*p).\n",
        "result = torch.bmm(tensor1, tensor2)\n",
        "\n",
        "# Element-wise multiplication.\n",
        "result = tensor1 * tensor2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czulmfiIauV9"
      },
      "source": [
        "计算两组数据之间的两两欧式距离"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVESwbXLaxt3"
      },
      "source": [
        "# X1 is of shape m*d.\n",
        "X1 = torch.unsqueeze(X1, dim=1).expand(m, n, d)\n",
        "# X2 is of shape n*d.\n",
        "X2 = torch.unsqueeze(X2, dim=0).expand(m, n, d)\n",
        "# dist is of shape m*n, where dist[i][j] = sqrt(|X1[i, :] - X[j, :]|^2)\n",
        "dist = torch.sqrt(torch.sum((X1 - X2) ** 2, dim=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p1HGfM_a5_M"
      },
      "source": [
        "最常用的卷积层配置"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V6buWC_bTHc"
      },
      "source": [
        "conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True)conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NcnJn7ob4X5"
      },
      "source": [
        "0GAP（Global average pooling）层"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXPShfSXb7Sd"
      },
      "source": [
        "gap = torch.nn.AdaptiveAvgPool2d(output_size=1)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K7w011PbV5U"
      },
      "source": [
        "双线性汇合（bilinear pooling）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG4JqhKVb-63"
      },
      "source": [
        "X = torch.reshape(N, D, H * W)                        # Assume X has shape N*D*H*W\n",
        "X = torch.bmm(X, torch.transpose(X, 1, 2)) / (H * W)  # Bilinear pooling\n",
        "assert X.size() == (N, D, D)\n",
        "X = torch.reshape(X, (N, D * D))\n",
        "X = torch.sign(X) * torch.sqrt(torch.abs(X) + 1e-5)   # Signed-sqrt normalization\n",
        "X = torch.nn.functional.normalize(X)                  # L2 normalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2Ct1TRPcCKZ"
      },
      "source": [
        "多卡同步 BN（Batch normalization）\n",
        "\n",
        "当使用 torch.nn.DataParallel 将代码运行在多张 GPU 卡上时，PyTorch 的 BN 层默认操作是各卡上数据独立地计算均值和标准差，同步 BN 使用所有卡上的数据一起计算 BN 层的均值和标准差，缓解了当批量大小（batch size）比较小时对均值和标准差估计不准的情况，是在目标检测等任务中一个有效的提升性能的技巧。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu9sIAl4cFV9"
      },
      "source": [
        "类似 BN 滑动平均"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDA58bfZcZbQ"
      },
      "source": [
        "class BN(torch.nn.Module)\n",
        "    def __init__(self):\n",
        "        ...\n",
        "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
        "\n",
        "    def forward(self, X):\n",
        "        ...\n",
        "        self.running_mean += momentum * (current - self.running_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dikraxy9coZg"
      },
      "source": [
        "计算模型整体参数量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCokiYOpc2CE"
      },
      "source": [
        "num_parameters = sum(torch.numel(parameter) for parameter in model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrMeEQGhcvHb"
      },
      "source": [
        "模型权值初始化\n",
        "\n",
        "注意 model.modules() 和 model.children() 的区别：model.modules() 会迭代地遍历模型的所有子层，而 model.children() 只会遍历模型下的一层。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjLNws1xc6St"
      },
      "source": [
        "# Common practise for initialization.\n",
        "for layer in model.modules():\n",
        "    if isinstance(layer, torch.nn.Conv2d):\n",
        "        torch.nn.init.kaiming_normal_(layer.weight, mode='fan_out',\n",
        "                                      nonlinearity='relu')\n",
        "        if layer.bias is not None:\n",
        "            torch.nn.init.constant_(layer.bias, val=0.0)\n",
        "    elif isinstance(layer, torch.nn.BatchNorm2d):\n",
        "        torch.nn.init.constant_(layer.weight, val=1.0)\n",
        "        torch.nn.init.constant_(layer.bias, val=0.0)\n",
        "    elif isinstance(layer, torch.nn.Linear):\n",
        "        torch.nn.init.xavier_normal_(layer.weight)\n",
        "        if layer.bias is not None:\n",
        "            torch.nn.init.constant_(layer.bias, val=0.0)\n",
        "\n",
        "# Initialization with given tensor.\n",
        "layer.weight = torch.nn.Parameter(tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laeKdd-tdCbB"
      },
      "source": [
        "部分层使用预训练模型\n",
        "\n",
        "注意如果保存的模型是 torch.nn.DataParallel，则当前的模型也需要是"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfvMUH9IdIL2"
      },
      "source": [
        "model.load_state_dict(torch.load('model,pth'), strict=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xvf89LedQtR"
      },
      "source": [
        "将在 GPU 保存的模型加载到 CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY7uolbGdNiv"
      },
      "source": [
        "model.load_state_dict(torch.load('model,pth', map_location='cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTyPH-m6dXid"
      },
      "source": [
        "数据准备、特征提取与微调"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_EjyvE_dc0E"
      },
      "source": [
        "得到视频数据基本信息"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvgnjf2ZdYNt"
      },
      "source": [
        "import cv2\n",
        "video = cv2.VideoCapture(mp4_path)\n",
        "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
        "video.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNDRHkJ3df4q"
      },
      "source": [
        "TSN 每段（segment）采样一帧视频"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afs65oJYdjVI"
      },
      "source": [
        "K = self._num_segments\n",
        "if is_train:\n",
        "    if num_frames > K:\n",
        "        # Random index for each segment.\n",
        "        frame_indices = torch.randint(\n",
        "            high=num_frames // K, size=(K,), dtype=torch.long)\n",
        "        frame_indices += num_frames // K * torch.arange(K)\n",
        "    else:\n",
        "        frame_indices = torch.randint(\n",
        "            high=num_frames, size=(K - num_frames,), dtype=torch.long)\n",
        "        frame_indices = torch.sort(torch.cat((\n",
        "            torch.arange(num_frames), frame_indices)))[0]\n",
        "else:\n",
        "    if num_frames > K:\n",
        "        # Middle index for each segment.\n",
        "        frame_indices = num_frames / K // 2\n",
        "        frame_indices += num_frames // K * torch.arange(K)\n",
        "    else:\n",
        "        frame_indices = torch.sort(torch.cat((                              \n",
        "            torch.arange(num_frames), torch.arange(K - num_frames))))[0]\n",
        "assert frame_indices.size() == (K,)\n",
        "return [frame_indices[i] for i in range(K)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tBKNVZ5dpLu"
      },
      "source": [
        "提取 ImageNet 预训练模型某层的卷积特征"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOPOHIcpdsda"
      },
      "source": [
        "# VGG-16 relu5-3 feature.\n",
        "model = torchvision.models.vgg16(pretrained=True).features[:-1]\n",
        "# VGG-16 pool5 feature.\n",
        "model = torchvision.models.vgg16(pretrained=True).features\n",
        "# VGG-16 fc7 feature.\n",
        "model = torchvision.models.vgg16(pretrained=True)\n",
        "model.classifier = torch.nn.Sequential(*list(model.classifier.children())[:-3])\n",
        "# ResNet GAP feature.\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model = torch.nn.Sequential(collections.OrderedDict(\n",
        "    list(model.named_children())[:-1]))\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    conv_representation = model(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJO1apNidu-_"
      },
      "source": [
        "提取 ImageNet 预训练模型多层的卷积特征"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsSSDk3edyKf"
      },
      "source": [
        "class FeatureExtractor(torch.nn.Module):\n",
        "    \"\"\"Helper class to extract several convolution features from the given\n",
        "    pre-trained model.\n",
        "\n",
        "    Attributes:\n",
        "        _model, torch.nn.Module.\n",
        "        _layers_to_extract, list<str> or set<str>\n",
        "\n",
        "    Example:\n",
        "        >>> model = torchvision.models.resnet152(pretrained=True)\n",
        "        >>> model = torch.nn.Sequential(collections.OrderedDict(\n",
        "                list(model.named_children())[:-1]))\n",
        "        >>> conv_representation = FeatureExtractor(\n",
        "                pretrained_model=model,\n",
        "                layers_to_extract={'layer1', 'layer2', 'layer3', 'layer4'})(image)\n",
        "    \"\"\"\n",
        "    def __init__(self, pretrained_model, layers_to_extract):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self._model = pretrained_model\n",
        "        self._model.eval()\n",
        "        self._layers_to_extract = set(layers_to_extract)\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            conv_representation = []\n",
        "            for name, layer in self._model.named_children():\n",
        "                x = layer(x)\n",
        "                if name in self._layers_to_extract:\n",
        "                    conv_representation.append(x)\n",
        "            return conv_representation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIsSU5BCd1fF"
      },
      "source": [
        "微调全连接层"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FvRJ56xd5NG"
      },
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.fc = nn.Linear(512, 100)  # Replace the last fc layer\n",
        "optimizer = torch.optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJpaeE5Kd7_G"
      },
      "source": [
        "以较大学习率微调全连接层，较小学习率微调卷积层"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIEI8Q-2d-s3"
      },
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "finetuned_parameters = list(map(id, model.fc.parameters()))\n",
        "conv_parameters = (p for p in model.parameters() if id(p) not in finetuned_parameters)\n",
        "parameters = [{'params': conv_parameters, 'lr': 1e-3}, \n",
        "              {'params': model.fc.parameters()}]\n",
        "optimizer = torch.optim.SGD(parameters, lr=1e-2, momentum=0.9, weight_decay=1e-4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieeDYPgEeBIi"
      },
      "source": [
        "模型训练"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_nlutRceKfR"
      },
      "source": [
        "常用训练和验证数据预处理\n",
        "其中 ToTensor 操作会将 PIL.Image 或形状为 H×W×D，数值范围为 [0, 255] 的 np.ndarray 转换为形状为 D×H×W，数值范围为 [0.0, 1.0] 的 torch.Tensor。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG-VtA4TeIA5"
      },
      "source": [
        "train_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomResizedCrop(size=224,\n",
        "                                             scale=(0.08, 1.0)),\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                                     std=(0.229, 0.224, 0.225)),\n",
        " ])\n",
        " val_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(224),\n",
        "    torchvision.transforms.CenterCrop(224),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                                     std=(0.229, 0.224, 0.225)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6MZnQ8XgPxW"
      },
      "source": [
        "训练基本代码框架"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ-QbDWOgSoo"
      },
      "source": [
        "for t in epoch(80):\n",
        "    for images, labels in tqdm.tqdm(train_loader, desc='Epoch %3d' % (t + 1)):\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        scores = model(images)\n",
        "        loss = loss_function(scores, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F45zaRIgHBT"
      },
      "source": [
        "标记平滑（label smoothing）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3IoCHfXgogW"
      },
      "source": [
        "for images, labels in train_loader:\n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "    N = labels.size(0)\n",
        "    # C is the number of classes.\n",
        "    smoothed_labels = torch.full(size=(N, C), fill_value=0.1 / (C - 1)).cuda()\n",
        "    smoothed_labels.scatter_(dim=1, index=torch.unsqueeze(labels, dim=1), value=0.9)\n",
        "\n",
        "    score = model(images)\n",
        "    log_prob = torch.nn.functional.log_softmax(score, dim=1)\n",
        "    loss = -torch.sum(log_prob * smoothed_labels) / N\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTj4b1lVgr8K"
      },
      "source": [
        "Mixup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnD6Pv_bgxLq"
      },
      "source": [
        "beta_distribution = torch.distributions.beta.Beta(alpha, alpha)\n",
        "for images, labels in train_loader:\n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "    # Mixup images.\n",
        "    lambda_ = beta_distribution.sample([]).item()\n",
        "    index = torch.randperm(images.size(0)).cuda()\n",
        "    mixed_images = lambda_ * images + (1 - lambda_) * images[index, :]\n",
        "\n",
        "    # Mixup loss.    \n",
        "    scores = model(mixed_images)\n",
        "    loss = (lambda_ * loss_function(scores, labels) \n",
        "            + (1 - lambda_) * loss_function(scores, labels[index]))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zncmCrvYg9TD"
      },
      "source": [
        "L1 正则化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXrioBOehAQp"
      },
      "source": [
        "l1_regularization = torch.nn.L1Loss(reduction='sum')\n",
        "loss = ...  # Standard cross-entropy loss\n",
        "for param in model.parameters():\n",
        "    loss += torch.sum(torch.abs(param))\n",
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrE4nswhCr3"
      },
      "source": [
        "不对偏置项进行 L2 正则化/权值衰减（weight decay）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GLoUWMVhF9N"
      },
      "source": [
        "bias_list = (param for name, param in model.named_parameters() if name[-4:] == 'bias')\n",
        "others_list = (param for name, param in model.named_parameters() if name[-4:] != 'bias')\n",
        "parameters = [{'parameters': bias_list, 'weight_decay': 0},                \n",
        "              {'parameters': others_list}]\n",
        "optimizer = torch.optim.SGD(parameters, lr=1e-2, momentum=0.9, weight_decay=1e-4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsxgTwb4hItg"
      },
      "source": [
        "梯度裁剪（gradient clipping）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zfDEy6mhW_Z"
      },
      "source": [
        "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYj6ERq_hZIV"
      },
      "source": [
        "计算 Softmax 输出的准确率"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pICTKhUzhbsx"
      },
      "source": [
        "score = model(images)\n",
        "prediction = torch.argmax(score, dim=1)\n",
        "num_correct = torch.sum(prediction == labels).item()\n",
        "accuruacy = num_correct / labels.size(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwfRuxNeheHI"
      },
      "source": [
        "可视化学习曲线 Facebook  Visdom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RyRVxQDhqPv"
      },
      "source": [
        "# Example using Visdom.\n",
        "vis = visdom.Visdom(env='Learning curve', use_incoming_socket=False)\n",
        "assert self._visdom.check_connection()\n",
        "self._visdom.close()\n",
        "options = collections.namedtuple('Options', ['loss', 'acc', 'lr'])(\n",
        "    loss={'xlabel': 'Epoch', 'ylabel': 'Loss', 'showlegend': True},\n",
        "    acc={'xlabel': 'Epoch', 'ylabel': 'Accuracy', 'showlegend': True},\n",
        "    lr={'xlabel': 'Epoch', 'ylabel': 'Learning rate', 'showlegend': True})\n",
        "\n",
        "for t in epoch(80):\n",
        "    tran(...)\n",
        "    val(...)\n",
        "    vis.line(X=torch.Tensor([t + 1]), Y=torch.Tensor([train_loss]),\n",
        "             name='train', win='Loss', update='append', opts=options.loss)\n",
        "    vis.line(X=torch.Tensor([t + 1]), Y=torch.Tensor([val_loss]),\n",
        "             name='val', win='Loss', update='append', opts=options.loss)\n",
        "    vis.line(X=torch.Tensor([t + 1]), Y=torch.Tensor([train_acc]),\n",
        "             name='train', win='Accuracy', update='append', opts=options.acc)\n",
        "    vis.line(X=torch.Tensor([t + 1]), Y=torch.Tensor([val_acc]),\n",
        "             name='val', win='Accuracy', update='append', opts=options.acc)\n",
        "    vis.line(X=torch.Tensor([t + 1]), Y=torch.Tensor([lr]),\n",
        "             win='Learning rate', update='append', opts=options.lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiaIyIxMhs_Z"
      },
      "source": [
        "得到当前学习率"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wouCBKphw8u"
      },
      "source": [
        "# If there is one global learning rate (which is the common case).\n",
        "lr = next(iter(optimizer.param_groups))['lr']\n",
        "\n",
        "# If there are multiple learning rates for different layers.\n",
        "all_lr = []\n",
        "for param_group in optimizer.param_groups:\n",
        "    all_lr.append(param_group['lr'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHCjbjrnhzDb"
      },
      "source": [
        "学习率衰减"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zyZHpEZh1V_"
      },
      "source": [
        "# Reduce learning rate when validation accuarcy plateau.\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, verbose=True)\n",
        "for t in range(0, 80):\n",
        "    train(...); val(...)\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "# Cosine annealing learning rate.\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80)\n",
        "# Reduce learning rate by 10 at given epochs.\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 70], gamma=0.1)\n",
        "for t in range(0, 80):\n",
        "    scheduler.step()    \n",
        "    train(...); val(...)\n",
        "\n",
        "# Learning rate warmup by 10 epochs.\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda t: t / 10)\n",
        "for t in range(0, 10):\n",
        "    scheduler.step()\n",
        "    train(...); val(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY8-pp1rh36_"
      },
      "source": [
        "保存与加载断点"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF8Bx6nJiAZC"
      },
      "source": [
        "# Save checkpoint.\n",
        "is_best = current_acc > best_acc\n",
        "best_acc = max(best_acc, current_acc)\n",
        "checkpoint = {\n",
        "    'best_acc': best_acc,    \n",
        "    'epoch': t + 1,\n",
        "    'model': model.state_dict(),\n",
        "    'optimizer': optimizer.state_dict(),\n",
        "}\n",
        "model_path = os.path.join('model', 'checkpoint.pth.tar')\n",
        "torch.save(checkpoint, model_path)\n",
        "if is_best:\n",
        "    shutil.copy('checkpoint.pth.tar', model_path)\n",
        "\n",
        "# Load checkpoint.\n",
        "if resume:\n",
        "    model_path = os.path.join('model', 'checkpoint.pth.tar')\n",
        "    assert os.path.isfile(model_path)\n",
        "    checkpoint = torch.load(model_path)\n",
        "    best_acc = checkpoint['best_acc']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    model.load_state_dict(checkpoint['model'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    print('Load checkpoint at epoch %d.' % start_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOFutqOUiBET"
      },
      "source": [
        "计算准确率、查准率（precision）、查全率（recall）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ile89Q4h-dl"
      },
      "source": [
        "# data['label'] and data['prediction'] are groundtruth label and prediction \n",
        "# for each image, respectively.\n",
        "accuracy = np.mean(data['label'] == data['prediction']) * 100\n",
        "\n",
        "# Compute recision and recall for each class.\n",
        "for c in range(len(num_classes)):\n",
        "    tp = np.dot((data['label'] == c).astype(int),\n",
        "                (data['prediction'] == c).astype(int))\n",
        "    tp_fp = np.sum(data['prediction'] == c)\n",
        "    tp_fn = np.sum(data['label'] == c)\n",
        "    precision = tp / tp_fp * 100\n",
        "    recall = tp / tp_fn * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz_QNZsviJfT"
      },
      "source": [
        "模型定义 注意事项"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mEK4OSRiVhP"
      },
      "source": [
        "建议有参数的层和汇合（pooling）层使用 torch.nn 模块定义，激活函数直接使用 torch.nn.functional。torch.nn 模块和 torch.nn.functional 的区别在于，torch.nn 模块在计算时底层调用了 torch.nn.functional，但 torch.nn 模块包括该层参数，还可以应对训练和测试两种网络状态。使用 torch.nn.functional 时要注意网络状态，如\n",
        "\n",
        "def forward(self, x):\n",
        "\n",
        "```\n",
        "    x = torch.nn.functional.dropout(x, p=0.5, training=self.training)\n",
        "```\n",
        "\n",
        "* model(x) 前用 model.train() 和 model.eval() 切换网络状态。\n",
        "\n",
        "* 不需要计算梯度的代码块用 with torch.no_grad() 包含起来。model.eval() 和 torch.no_grad() 的区别在于，model.eval() 是将网络切换为测试状态，例如 BN 和随机失活（dropout）在训练和测试阶段使用不同的计算方法。torch.no_grad() 是关闭 PyTorch 张量的自动求导机制，以减少存储使用和加速计算，得到的结果无法进行 loss.backward()。\n",
        "\n",
        "* torch.nn.CrossEntropyLoss 的输入不需要经过 Softmax。torch.nn.CrossEntropyLoss 等价于 torch.nn.functional.log_softmax + torch.nn.NLLLoss。\n",
        "\n",
        "* loss.backward() 前用 optimizer.zero_grad() 清除累积梯度。optimizer.zero_grad() 和 model.zero_grad() 效果一样。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vELEaKk6i8dz"
      },
      "source": [
        "PyTorch 性能与调试"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ytpJ3Ngi9j0"
      },
      "source": [
        "* torch.utils.data.DataLoader 中尽量设置 pin_memory=True，对特别小的数据集如 MNIST 设置 pin_memory=False 反而更快一些。num_workers 的设置需要在实验中找到最快的取值。\n",
        "\n",
        "* 用 del 及时删除不用的中间变量，节约 GPU 存储。\n",
        "\n",
        "* 使用 inplace 操作可节约 GPU 存储，如\n",
        "x = torch.nn.functional.relu(x, inplace=True)\n",
        "\n",
        "* 减少 CPU 和 GPU 之间的数据传输。例如如果你想知道一个 epoch 中每个 mini-batch 的 loss 和准确率，先将它们累积在 GPU 中等一个 epoch 结束之后一起传输回 CPU 会比每个 mini-batch 都进行一次 GPU 到 CPU 的传输更快。\n",
        "\n",
        "* 使用半精度浮点数 half() 会有一定的速度提升，具体效率依赖于 GPU 型号。需要小心数值精度过低带来的稳定性问题。\n",
        "\n",
        "* 时常使用 assert tensor.size() == (N, D, H, W) 作为调试手段，确保张量维度和你设想中一致。\n",
        "\n",
        "* 除了标记 y 外，尽量少使用一维张量，使用 n*1 的二维张量代替，可以避免一些意想不到的一维张量计算结果。\n",
        "\n",
        "* 统计代码各部分耗时\n",
        "\n",
        "```\n",
        "with torch.autograd.profiler.profile(enabled=True, use_cuda=False) as profile:\n",
        "    ...\n",
        "print(profile)\n",
        "```\n",
        "\n",
        "或者在命令行运行\n",
        "\n",
        "```\n",
        "python -m torch.utils.bottleneck main.py\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ELHE25ziRoR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}