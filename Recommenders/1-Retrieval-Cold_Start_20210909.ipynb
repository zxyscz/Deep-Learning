{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ae8eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea0fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c428ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd0bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61a9132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e55359",
   "metadata": {},
   "source": [
    "### Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d144f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_file_cold(file, stats):\n",
    "    print('loading file:' + file)\n",
    "    training_df = pd.read_csv(\n",
    "        file,\n",
    "        skiprows=[0],\n",
    "        names=[\"viewer\",\"broadcaster\",\"viewer_age\",\"viewer_gender\",\"viewer_longitude\",\"viewer_latitude\",\"viewer_lang\",\"viewer_country\",\"broadcaster_age\",\"broadcaster_gender\",\"broadcaster_longitude\",\"broadcaster_latitude\",\"broadcaster_lang\",\"broadcaster_country\",\"duration\", \"viewer_network\", \"broadcaster_network\", \"count\"], dtype={\n",
    "            'viewer': np.unicode,\n",
    "            'broadcaster': np.unicode,\n",
    "            'viewer_age': np.single,\n",
    "            'viewer_gender': np.unicode,\n",
    "            'viewer_longitude': np.single,\n",
    "            'viewer_latitude': np.single,\n",
    "            'viewer_lang': np.unicode,\n",
    "            'viewer_country': np.unicode,\n",
    "            'broadcaster_age': np.single,\n",
    "            'broadcaster_longitude': np.single,\n",
    "            'broadcaster_latitude': np.single,\n",
    "            'broadcaster_lang': np.unicode,\n",
    "            'broadcaster_country': np.unicode,\n",
    "            'viewer_network': np.unicode,\n",
    "            'broadcaster_network': np.unicode,\n",
    "            'count': np.int\n",
    "        })\n",
    "\n",
    "    values = {\n",
    "        'viewer': 'unknown',\n",
    "        'broadcaster': 'unknown',\n",
    "        'viewer_age': 30,\n",
    "        'viewer_gender': 'unknown',\n",
    "        'viewer_longitude': 0,\n",
    "        'viewer_latitude': 0,\n",
    "        'viewer_lang': 'unknown',\n",
    "        'viewer_country': 'unknown',\n",
    "        'broadcaster_age': 30,\n",
    "        'broadcaster_longitude': 0,\n",
    "        'broadcaster_latitude': 0,\n",
    "        'broadcaster_lang': 'unknown',\n",
    "        'broadcaster_country': 'unknown',\n",
    "        'duration': 0,\n",
    "        'viewer_network': 'unknown',\n",
    "        'broadcaster_network': 'unknown',\n",
    "        'count': 0\n",
    "    }\n",
    "    training_df.fillna(value=values, inplace=True)\n",
    "#     print(training_df.head(10))\n",
    "#     print(training_df.iloc[-10:])\n",
    "#     stats.send_stats('data-size', len(training_df.index))\n",
    "\n",
    "    sampled_df = training_df.sample(frac=0.1)\n",
    "    print(sampled_df.head(10))\n",
    "    print(sampled_df.iloc[-10:])\n",
    "    return sampled_df\n",
    "\n",
    "def load_training_data_cold(file, stats):\n",
    "    ratings_df = load_data_file_cold(file, stats)\n",
    "    print('creating data set')\n",
    "    training_ds = (\n",
    "        tf.data.Dataset.from_tensor_slices(\n",
    "            ({\n",
    "                \"viewer\": tf.cast(\n",
    "                    ratings_df['viewer'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_gender\": tf.cast(\n",
    "                    ratings_df['viewer_gender'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_lang\": tf.cast(\n",
    "                    ratings_df['viewer_lang'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_country\": tf.cast(\n",
    "                    ratings_df['viewer_country'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_age\": tf.cast(\n",
    "                    ratings_df['viewer_age'].values,\n",
    "                    tf.int16),\n",
    "                \"viewer_longitude\": tf.cast(\n",
    "                    ratings_df['viewer_longitude'].values,\n",
    "                    tf.float16),\n",
    "                \"viewer_latitude\": tf.cast(\n",
    "                    ratings_df['viewer_latitude'].values,\n",
    "                    tf.float16),\n",
    "                \"broadcaster\": tf.cast(\n",
    "                    ratings_df['broadcaster'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_network\": tf.cast(\n",
    "                    ratings_df['viewer_network'].values,\n",
    "                    tf.string),\n",
    "                \"broadcaster_network\": tf.cast(\n",
    "                    ratings_df['broadcaster_network'].values,\n",
    "                    tf.string),\n",
    "            })))\n",
    "\n",
    "    return training_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "065419a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data_cold(train_ds):\n",
    "    print('prepare_training_data')\n",
    "    training_ds = train_ds.cache().map(lambda x: {\n",
    "        \"broadcaster\": x[\"broadcaster\"],\n",
    "        \"viewer\": x[\"viewer\"],\n",
    "        \"viewer_gender\": x[\"viewer_gender\"],\n",
    "        \"viewer_lang\": x[\"viewer_lang\"],\n",
    "        \"viewer_country\": x[\"viewer_country\"],\n",
    "        \"viewer_age\": x[\"viewer_age\"],\n",
    "        \"viewer_longitude\": x[\"viewer_longitude\"],\n",
    "        \"viewer_latitude\": x[\"viewer_latitude\"],\n",
    "        \"viewer_network\": x[\"viewer_network\"],\n",
    "        \"broadcaster_network\": x[\"broadcaster_network\"],\n",
    "    }, num_parallel_calls=tf.data.AUTOTUNE,\n",
    "       deterministic=False)\n",
    "\n",
    "    print('done prepare_training_data')\n",
    "    return training_ds\n",
    "\n",
    "def get_broadcaster_data_set(train_ds):\n",
    "    broadcasters = train_ds.cache().map(lambda x: x[\"broadcaster\"], num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "    broadcasters_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        np.unique(list(broadcasters.as_numpy_iterator())))\n",
    "    return broadcasters_ds\n",
    "\n",
    "def get_list(training_data, key):\n",
    "    return training_data.batch(1_000_000).map(lambda x: x[key], num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "\n",
    "def get_unique_list(data):\n",
    "    return np.unique(np.concatenate(list(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61901fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file:a3d86f3b-eb45-4641-b05d-30dff7423e6b.csv\n",
      "                   viewer       broadcaster  viewer_age viewer_gender  \\\n",
      "3508724     pof:327647531  meetme:284944392        41.0          male   \n",
      "2917344     pof:333753109     pof:331124573        43.0          male   \n",
      "2225781     pof:142085441   skout:173905746        32.0          male   \n",
      "5015864  meetme:314815889  meetme:177004661        29.0          male   \n",
      "821050    skout:170536582   skout:169786744        33.0          male   \n",
      "1659425   skout:134491552  meetme:229602082        26.0        female   \n",
      "2679288  meetme:318071034  meetme:280218146        22.0        female   \n",
      "102293    meetme:29821282  meetme:264439298        48.0        female   \n",
      "568169    skout:105089058   skout:178518892        36.0          male   \n",
      "1448898  meetme:309480199  meetme:298423614        28.0          male   \n",
      "\n",
      "         viewer_longitude  viewer_latitude viewer_lang viewer_country  \\\n",
      "3508724        -96.800003        33.000000          en             US   \n",
      "2917344        -77.400002        38.299999          en             US   \n",
      "2225781        -73.800003        40.700001          en             US   \n",
      "5015864        -98.028297        37.154202          en             US   \n",
      "821050          39.231998        38.661999          tr             TR   \n",
      "1659425        -83.103996        42.535000          en             US   \n",
      "2679288        -99.140404        19.434799          es             US   \n",
      "102293        -102.673203        32.717800          en             US   \n",
      "568169         127.688004        34.743999          ko             KR   \n",
      "1448898         73.099998        30.666700          en             US   \n",
      "\n",
      "         broadcaster_age broadcaster_gender  broadcaster_longitude  \\\n",
      "3508724             33.0             female             -73.942497   \n",
      "2917344             43.0             female             -84.400002   \n",
      "2225781             56.0             female              48.057999   \n",
      "5015864             27.0             female             -99.399200   \n",
      "821050              40.0             female             120.503998   \n",
      "1659425             40.0               male             -75.206596   \n",
      "2679288             30.0               male             -98.281303   \n",
      "102293              42.0             female             -76.876999   \n",
      "568169              36.0             female             128.628006   \n",
      "1448898             31.0             female             -95.473099   \n",
      "\n",
      "         broadcaster_latitude broadcaster_lang broadcaster_country  duration  \\\n",
      "3508724             40.817001               en                  US       732   \n",
      "2917344             33.599998               en                  US       143   \n",
      "2225781             29.323999               en                  KW        78   \n",
      "5015864             36.429699               en                  US      1375   \n",
      "821050              15.170000               en                  PH       279   \n",
      "1659425             40.190800               en                  US        92   \n",
      "2679288             26.093399               es                  MX        65   \n",
      "102293              42.908798               en                  US     48930   \n",
      "568169              35.872002               ko                  KR      1630   \n",
      "1448898             29.705500               en                  US      1084   \n",
      "\n",
      "        viewer_network broadcaster_network  count  \n",
      "3508724            pof              meetme      2  \n",
      "2917344            pof                 pof      1  \n",
      "2225781            pof               skout      1  \n",
      "5015864         meetme              meetme      1  \n",
      "821050           skout               skout      2  \n",
      "1659425          skout              meetme      1  \n",
      "2679288         meetme              meetme      1  \n",
      "102293          meetme              meetme    122  \n",
      "568169           skout               skout      3  \n",
      "1448898         meetme              meetme      5  \n",
      "                   viewer       broadcaster  viewer_age viewer_gender  \\\n",
      "5076961  meetme:313369395  meetme:286235083        25.0          male   \n",
      "5073871     pof:256235806  meetme:234429422        32.0          male   \n",
      "375581      pof:332621219  meetme:314754059        34.0          male   \n",
      "4773237     pof:323094363  meetme:318006978        26.0          male   \n",
      "1644160  meetme:281974015  meetme:285964455        32.0          male   \n",
      "3278325  meetme:313750848  meetme:203010103        18.0        female   \n",
      "4529591  meetme:317112801   skout:183622138        25.0          male   \n",
      "2655148  meetme:270741768  meetme:267804405        41.0        female   \n",
      "4982816   skout:180623885  meetme:314334365        25.0          male   \n",
      "4813527     pof:331395353   skout:182424298        35.0          male   \n",
      "\n",
      "         viewer_longitude  viewer_latitude viewer_lang viewer_country  \\\n",
      "5076961        121.037201        14.630600          en             US   \n",
      "5073871        -96.900002        33.000000          en             US   \n",
      "375581         -83.800003        39.900002          en             US   \n",
      "4773237        -75.300003        40.099998          en             US   \n",
      "1644160        -74.505302        41.722401          en             US   \n",
      "3278325        -46.633400       -23.550699          pt             BR   \n",
      "4529591        -40.304001       -12.515800          pt             BR   \n",
      "2655148       -117.056503        32.606899          en             US   \n",
      "4982816        -91.675003        41.941002          en             US   \n",
      "4813527        -90.099998        30.000000          en             US   \n",
      "\n",
      "         broadcaster_age broadcaster_gender  broadcaster_longitude  \\\n",
      "5076961             20.0             female             121.060799   \n",
      "5073871             31.0             female             -96.829201   \n",
      "375581              39.0             female             -83.016602   \n",
      "4773237             22.0             female             -74.329300   \n",
      "1644160             26.0             female            -112.250504   \n",
      "3278325             24.0               male             -37.468102   \n",
      "4529591             23.0             female             -60.011002   \n",
      "2655148             31.0               male             -73.994499   \n",
      "4982816             32.0             female             -81.750000   \n",
      "4813527             24.0             female             -93.287003   \n",
      "\n",
      "         broadcaster_latitude broadcaster_lang broadcaster_country  duration  \\\n",
      "5076961             14.483100               en                  PH        75   \n",
      "5073871             32.959999               en                  US        84   \n",
      "375581              40.099400               en                  US       111   \n",
      "4773237             40.785702               en                  US        80   \n",
      "1644160             33.527100               en                  US       108   \n",
      "3278325            -10.673900               pt                  BR      2700   \n",
      "4529591             -3.027000               pt                  BR      1492   \n",
      "2655148             40.752102               en                  US       560   \n",
      "4982816             30.250000               en                  US       169   \n",
      "4813527             44.971001               en                  US       101   \n",
      "\n",
      "        viewer_network broadcaster_network  count  \n",
      "5076961         meetme              meetme      1  \n",
      "5073871            pof              meetme      1  \n",
      "375581             pof              meetme      1  \n",
      "4773237            pof              meetme      1  \n",
      "1644160         meetme              meetme      1  \n",
      "3278325         meetme              meetme      5  \n",
      "4529591         meetme               skout      3  \n",
      "2655148         meetme              meetme      1  \n",
      "4982816          skout              meetme      2  \n",
      "4813527            pof               skout      1  \n",
      "creating data set\n"
     ]
    }
   ],
   "source": [
    "ratings = load_training_data_cold(file=\"a3d86f3b-eb45-4641-b05d-30dff7423e6b.csv\", stats=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43f46c43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'broadcaster': b'meetme:284944392',\n",
      " 'broadcaster_network': b'meetme',\n",
      " 'viewer': b'pof:327647531',\n",
      " 'viewer_age': 41,\n",
      " 'viewer_country': b'US',\n",
      " 'viewer_gender': b'male',\n",
      " 'viewer_lang': b'en',\n",
      " 'viewer_latitude': 33.0,\n",
      " 'viewer_longitude': -96.8,\n",
      " 'viewer_network': b'pof'}\n",
      "{'broadcaster': b'pof:331124573',\n",
      " 'broadcaster_network': b'pof',\n",
      " 'viewer': b'pof:333753109',\n",
      " 'viewer_age': 43,\n",
      " 'viewer_country': b'US',\n",
      " 'viewer_gender': b'male',\n",
      " 'viewer_lang': b'en',\n",
      " 'viewer_latitude': 38.3,\n",
      " 'viewer_longitude': -77.4,\n",
      " 'viewer_network': b'pof'}\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(2).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb0915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    \"broadcaster\": x[\"broadcaster\"],\n",
    "    \"viewer\": x[\"viewer\"],    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "536127d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc4d2928c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc4d2928c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "broadcaster = ratings.map(lambda x: x[\"broadcaster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2eda356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'meetme:284944392'\n",
      "b'pof:331124573'\n"
     ]
    }
   ],
   "source": [
    "for x in broadcaster.take(2).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27210dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df164f2",
   "metadata": {},
   "source": [
    "### a vocabulary that maps a raw feature value to an integer in a contiguous range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81a612ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc5648dd320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc5648dd320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "broadcaster_id = broadcaster.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"viewer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "872151d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_broadcaster_id = np.unique(np.concatenate(list(broadcaster_id)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fe2a928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'meetme:100081867', b'meetme:100104254', b'meetme:100114731',\n",
       "       b'meetme:100130022', b'meetme:100190086', b'meetme:100201554',\n",
       "       b'meetme:100237066', b'meetme:100279809', b'meetme:100300152',\n",
       "       b'meetme:100345849'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_broadcaster_id[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2219cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'meetme:100116030', b'meetme:100142157', b'meetme:100151379',\n",
       "       b'meetme:10015227', b'meetme:100190086', b'meetme:100196265',\n",
       "       b'meetme:100197023', b'meetme:100200365', b'meetme:100201554',\n",
       "       b'meetme:100237066'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_user_ids[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538c607a",
   "metadata": {},
   "source": [
    "### Implementing a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a09202",
   "metadata": {},
   "source": [
    "### The query tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4db73c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfab271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_user_ids, mask_token=None),\n",
    "  # We add an additional embedding to account for unknown tokens.\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b41c812",
   "metadata": {},
   "source": [
    "### The candidate tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6f993a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcaster_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_broadcaster_id, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_broadcaster_id) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964393a3",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33b9d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=broadcaster.batch(128).map(broadcaster_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a6386",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dab7fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7323bf7",
   "metadata": {},
   "source": [
    "### The full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4227ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalModel(tfrs.Model):\n",
    "    def __init__(self, user_model, broadcaster_model):\n",
    "        super().__init__()\n",
    "        self.broadcaster_model: tf.keras.Model = broadcaster_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "    \n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"viewer\"])\n",
    "        # And pick out the movie features and pass them into the movie model,\n",
    "        # getting embeddings back.\n",
    "        positive_broadcaster_embeddings = self.broadcaster_model(features[\"broadcaster\"])\n",
    "        \n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(user_embeddings, positive_broadcaster_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "01b40da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoBaseClassModel ( tf.keras.Model ):\n",
    "    def __init__ ( self , user_model , broadcaster_model ):\n",
    "        super ( ).__init__ ( )\n",
    "        self.broadcaster_model: tf.keras.Model = broadcaster_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def train_step ( self , features: Dict [ Text , tf.Tensor ] ) -> tf.Tensor:\n",
    "        # Set up a gradient tape to record gradients.\n",
    "        with tf.GradientTape ( ) as tape:\n",
    "            # Loss computation.\n",
    "            user_embeddings = self.user_model ( features [ \"viewer\" ] )\n",
    "            positive_broadcaster_embeddings = self.broadcaster_model ( features [ \"broadcaster\" ] )\n",
    "            loss = self.task ( user_embeddings , positive_broadcaster_embeddings )\n",
    "\n",
    "            # Handle regularization losses as well.\n",
    "            regularization_loss = sum ( self.losses )\n",
    "\n",
    "            total_loss = loss + regularization_loss\n",
    "\n",
    "        gradients = tape.gradient ( total_loss , self.trainable_variables )\n",
    "        self.optimizer.apply_gradients ( zip ( gradients , self.trainable_variables ) )\n",
    "\n",
    "        metrics = {metric.name: metric.result ( ) for metric in self.metrics}\n",
    "        metrics [ \"loss\" ] = loss\n",
    "        metrics [ \"regularization_loss\" ] = regularization_loss\n",
    "        metrics [ \"total_loss\" ] = total_loss\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def test_step ( self , features: Dict [ Text , tf.Tensor ] ) -> tf.Tensor:\n",
    "        # Loss computation.\n",
    "        user_embeddings = self.user_model ( features [ \"viewer\" ] )\n",
    "        positive_broadcaster_embeddings = self.broadcaster_model ( features [ \"broadcaster\" ] )\n",
    "        loss = self.task ( user_embeddings , positive_broadcaster_embeddings )\n",
    "\n",
    "        # Handle regularization losses as well.\n",
    "        regularization_loss = sum ( self.losses )\n",
    "\n",
    "        total_loss = loss + regularization_loss\n",
    "\n",
    "        metrics = {metric.name: metric.result ( ) for metric in self.metrics}\n",
    "        metrics [ \"loss\" ] = loss\n",
    "        metrics [ \"regularization_loss\" ] = regularization_loss\n",
    "        metrics [ \"total_loss\" ] = total_loss\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fdd573",
   "metadata": {},
   "source": [
    "### Fitting and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb811d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FinalModel(user_model, broadcaster_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6abc4f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a691bc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4bf8e2200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc4bf8e2200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Retrieval.call of <tensorflow_recommenders.tasks.retrieval.Retrieval object at 0x7fc5555403d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Retrieval.call of <tensorflow_recommenders.tasks.retrieval.Retrieval object at 0x7fc5555403d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Streaming.call of <tensorflow_recommenders.layers.factorized_top_k.Streaming object at 0x7fc552d419d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Streaming.call of <tensorflow_recommenders.layers.factorized_top_k.Streaming object at 0x7fc552d419d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fc526405b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fc526405b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fc526405cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fc526405cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fc5264059e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fc5264059e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fc58326b290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fc58326b290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fc590fceb90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fc590fceb90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fc58326b200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fc58326b200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 760s 77s/step - factorized_top_k/top_1_categorical_accuracy: 1.2500e-05 - factorized_top_k/top_5_categorical_accuracy: 2.5000e-05 - factorized_top_k/top_10_categorical_accuracy: 3.7500e-05 - factorized_top_k/top_50_categorical_accuracy: 7.5000e-05 - factorized_top_k/top_100_categorical_accuracy: 1.1250e-04 - loss: 70367.2578 - regularization_loss: 0.0000e+00 - total_loss: 70367.2578\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 773s 77s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.2500e-05 - factorized_top_k/top_10_categorical_accuracy: 1.2500e-05 - factorized_top_k/top_50_categorical_accuracy: 4.8750e-04 - factorized_top_k/top_100_categorical_accuracy: 0.0013 - loss: 70166.4027 - regularization_loss: 0.0000e+00 - total_loss: 70166.4027\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 749s 75s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 5.0000e-04 - factorized_top_k/top_100_categorical_accuracy: 0.0061 - loss: 69427.9695 - regularization_loss: 0.0000e+00 - total_loss: 69427.9695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4dc3d0950>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8409e312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fc594b60dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fc594b60dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fc4ef9be9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fc4ef9be9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fc4ef9be170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fc4ef9be170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fc4ef9be950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fc4ef9be950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "5/5 [==============================] - 194s 38s/step - factorized_top_k/top_1_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_10_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_50_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 5.0000e-04 - loss: 32590.9746 - regularization_loss: 0.0000e+00 - total_loss: 32590.9746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.00044999999227002263,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.00044999999227002263,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.00044999999227002263,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.00044999999227002263,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.0005000000237487257,\n",
       " 'loss': 29620.759765625,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 29620.759765625}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cba4c7",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20ffec50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'viewer': <tf.Tensor 'args_2:0' shape=(None,) dtype=string>, 'viewer_gender': <tf.Tensor 'args_5:0' shape=(None,) dtype=string>, 'viewer_lang': <tf.Tensor 'args_6:0' shape=(None,) dtype=string>, 'viewer_country': <tf.Tensor 'args_4:0' shape=(None,) dtype=string>, 'viewer_age': <tf.Tensor 'args_3:0' shape=(None,) dtype=int16>, 'viewer_longitude': <tf.Tensor 'args_8:0' shape=(None,) dtype=float16>, 'viewer_latitude': <tf.Tensor 'args_7:0' shape=(None,) dtype=float16>, 'broadcaster': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>, 'viewer_network': <tf.Tensor 'args_9:0' shape=(None,) dtype=string>, 'broadcaster_network': <tf.Tensor 'args_1:0' shape=(None,) dtype=string>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lhuang/opt/miniconda3/envs/tensorflow3.7/lib/python3.7/site-packages/keras/engine/functional.py:585: UserWarning: Input dict contained keys ['viewer', 'viewer_gender', 'viewer_lang', 'viewer_country', 'viewer_age', 'viewer_longitude', 'viewer_latitude', 'broadcaster', 'viewer_network', 'broadcaster_network'] which did not match any model input. They will be ignored by the model.\n",
      "  [n for n in tensors.keys() if n not in ref_input_names])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user meetme:100116030: [b'pof:312971369' b'pof:312971369' b'pof:312971369']\n"
     ]
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((broadcaster.batch(100), ratings.batch(100).map(model.broadcaster_model)))\n",
    ")\n",
    "\n",
    "# Get recommendations.\n",
    "_, titles = index(tf.constant([\"meetme:100116030\"]))\n",
    "print(f\"Recommendations for user meetme:100116030: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f117b6",
   "metadata": {},
   "source": [
    "### Model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4df42dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fc5708747a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fc5708747a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method BruteForce.call of <tensorflow_recommenders.layers.factorized_top_k.BruteForce object at 0x7fc56235c710>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method BruteForce.call of <tensorflow_recommenders.layers.factorized_top_k.BruteForce object at 0x7fc56235c710>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fc471328050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fc471328050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc4703f85f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc4703f85f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7fc4703f85f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: /var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/tmpc41cp75_/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/tmpc41cp75_/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [b'pof:312971369' b'pof:312971369' b'pof:312971369']\n"
     ]
    }
   ],
   "source": [
    "# Export the query model.\n",
    "with tempfile.TemporaryDirectory ( ) as tmp:\n",
    "    path = os.path.join(tmp , \"model\" )\n",
    "    \n",
    "    # Save the index.\n",
    "    tf.saved_model.save (index , path )\n",
    "    \n",
    "    # Load it back; can also be done in TensorFlow Serving.\n",
    "    loaded = tf.saved_model.load ( path )\n",
    "    \n",
    "    # Pass a user id in, get top predicted movie titles back.\n",
    "    scores , broadcasters = loaded ( [ \"meetme:100116030\" ] )\n",
    "    \n",
    "    print ( f\"Recommendations: {broadcasters [ 0 ] [ :3 ]}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba528c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
