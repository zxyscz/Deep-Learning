{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c08264a",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/recommenders/examples/featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff71ba95",
   "metadata": {},
   "source": [
    "One of the great advantages of using a deep learning framework to build recommender models is the freedom to build rich, flexible feature representations.\n",
    "\n",
    "The first step in doing so is preparing the features, as raw features will usually not be immediately usable in a model.\n",
    "\n",
    "For example:\n",
    "\n",
    "- User and item ids may be strings (titles, usernames) or large, noncontiguous integers (database IDs).\n",
    "- Item descriptions could be raw text.\n",
    "- Interaction timestamps could be raw Unix timestamps.\n",
    "\n",
    "These need to be appropriately transformed in order to be useful in building models:\n",
    "\n",
    "- User and item ids have to be translated into embedding vectors: high-dimensional numerical representations that are adjusted during training to help the model predict its objective better.\n",
    "- Raw text needs to be tokenized (split into smaller parts such as individual words) and translated into embeddings.\n",
    "- Numerical features need to be normalized so that their values lie in a small interval around 0.\n",
    "\n",
    "Fortunately, by using TensorFlow we can make such preprocessing part of our model rather than a separate preprocessing step. This is not only convenient, but also ensures that our pre-processing is exactly the same during training and during serving. This makes it safe and easy to deploy models that include even very sophisticated pre-processing.\n",
    "\n",
    "In this tutorial, we are going to focus on recommenders and the preprocessing we need to do on the MovieLens dataset. If you're interested in a larger tutorial without a recommender system focus, have a look at the full Keras preprocessing guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51fef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pprint\n",
    "\n",
    "from typing import Dict, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62626833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06b3d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f076bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8510e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_file_cold(file, stats=\"\"):\n",
    "    print('loading file:' + file)\n",
    "    training_df = pd.read_csv(\n",
    "        file,\n",
    "        skiprows=[0],\n",
    "        names=[\"viewer\",\"broadcaster\",\"viewer_age\",\"viewer_gender\",\"viewer_longitude\",\"viewer_latitude\",\"viewer_lang\",\"viewer_country\",\"broadcaster_age\",\"broadcaster_gender\",\"broadcaster_longitude\",\"broadcaster_latitude\",\"broadcaster_lang\",\"broadcaster_country\",\"duration\", \"viewer_network\", \"broadcaster_network\", \"count\"], dtype={\n",
    "            'viewer': np.unicode,\n",
    "            'broadcaster': np.unicode,\n",
    "            'viewer_age': np.single,\n",
    "            'viewer_gender': np.unicode,\n",
    "            'viewer_longitude': np.single,\n",
    "            'viewer_latitude': np.single,\n",
    "            'viewer_lang': np.unicode,\n",
    "            'viewer_country': np.unicode,\n",
    "            'broadcaster_age': np.single,\n",
    "            'broadcaster_longitude': np.single,\n",
    "            'broadcaster_latitude': np.single,\n",
    "            'broadcaster_lang': np.unicode,\n",
    "            'broadcaster_country': np.unicode,\n",
    "            'viewer_network': np.unicode,\n",
    "            'broadcaster_network': np.unicode,\n",
    "            'count': np.unicode,\n",
    "        })\n",
    "\n",
    "    values = {\n",
    "        'viewer': 'unknown',\n",
    "        'broadcaster': 'unknown',\n",
    "        'viewer_age': 30,\n",
    "        'viewer_gender': 'unknown',\n",
    "        'viewer_longitude': 0,\n",
    "        'viewer_latitude': 0,\n",
    "        'viewer_lang': 'unknown',\n",
    "        'viewer_country': 'unknown',\n",
    "        'broadcaster_age': 30,\n",
    "        'broadcaster_longitude': 0,\n",
    "        'broadcaster_latitude': 0,\n",
    "        'broadcaster_lang': 'unknown',\n",
    "        'broadcaster_country': 'unknown',\n",
    "        'duration': 0,\n",
    "        'viewer_network': 'unknown',\n",
    "        'broadcaster_network': 'unknown',\n",
    "        'count': '0',\n",
    "    }\n",
    "    training_df = training_df.sample(frac = 0.001)\n",
    "    training_df.fillna(value=values, inplace=True)\n",
    "    training_df['viewer_lat_long'] = training_df[['viewer_latitude', 'viewer_longitude']].apply(lambda x: '{},{}'.format(x[0],x[1]), axis=1)\n",
    "    print(training_df.head(10))\n",
    "    print(training_df.iloc[-10:])\n",
    "    return training_df\n",
    "\n",
    "\n",
    "def load_training_data_cold(file, stats):\n",
    "    ratings_df = load_data_file_cold(file, stats)\n",
    "    print('creating data set')\n",
    "    training_ds = (\n",
    "        tf.data.Dataset.from_tensor_slices(\n",
    "            ({\n",
    "                \"viewer\": tf.cast(\n",
    "                    ratings_df['viewer'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_gender\": tf.cast(\n",
    "                    ratings_df['viewer_gender'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_lang\": tf.cast(\n",
    "                    ratings_df['viewer_lang'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_country\": tf.cast(\n",
    "                    ratings_df['viewer_country'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_age\": tf.cast(\n",
    "                    ratings_df['viewer_age'].values,\n",
    "                    tf.int16),\n",
    "                \"viewer_longitude\": tf.cast(\n",
    "                    ratings_df['viewer_longitude'].values,\n",
    "                    tf.float16),\n",
    "                \"viewer_latitude\": tf.cast(\n",
    "                    ratings_df['viewer_latitude'].values,\n",
    "                    tf.float16),\n",
    "                \"broadcaster\": tf.cast(\n",
    "                    ratings_df['broadcaster'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_network\": tf.cast(\n",
    "                    ratings_df['viewer_network'].values,\n",
    "                    tf.string),\n",
    "                \"broadcaster_network\": tf.cast(\n",
    "                    ratings_df['broadcaster_network'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_lat_long\": tf.cast(\n",
    "                    ratings_df['viewer_lat_long'].values,\n",
    "                    tf.string),\n",
    "            })))\n",
    "\n",
    "    return training_ds\n",
    "\n",
    "\n",
    "def prepare_training_data_cold(train_ds):\n",
    "    print('prepare_training_data')\n",
    "    training_ds = train_ds.cache().map(lambda x: {\n",
    "        \"broadcaster\": x[\"broadcaster\"],\n",
    "        \"viewer\": x[\"viewer\"],\n",
    "        \"viewer_gender\": x[\"viewer_gender\"],\n",
    "        \"viewer_lang\": x[\"viewer_lang\"],\n",
    "        \"viewer_country\": x[\"viewer_country\"],\n",
    "        \"viewer_age\": x[\"viewer_age\"],\n",
    "        \"viewer_longitude\": x[\"viewer_longitude\"],\n",
    "        \"viewer_latitude\": x[\"viewer_latitude\"],\n",
    "        \"viewer_network\": x[\"viewer_network\"],\n",
    "        \"broadcaster_network\": x[\"broadcaster_network\"],\n",
    "        \"viewer_lat_long\": x[\"viewer_lat_long\"],\n",
    "    }, num_parallel_calls=tf.data.AUTOTUNE,\n",
    "       deterministic=False)\n",
    "\n",
    "    print('done prepare_training_data')\n",
    "    return training_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3dbdd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file:csv/a3d86f3b-eb45-4641-b05d-30dff7423e6b.csv\n",
      "                   viewer       broadcaster  viewer_age viewer_gender  \\\n",
      "4129856   skout:183939265  meetme:250339028        29.0          male   \n",
      "4642062   skout:183504804   skout:183348180        28.0          male   \n",
      "1471301  meetme:253949213     pof:331596292        41.0          male   \n",
      "2640883   skout:164668693   skout:158946969        56.0          male   \n",
      "1826086  meetme:316347618  meetme:317022882        60.0          male   \n",
      "4615372  meetme:299434476  meetme:312750515        28.0          male   \n",
      "4971800  meetme:316353025   skout:127053087        34.0          male   \n",
      "2626976   skout:153125384  meetme:236794915        44.0          male   \n",
      "448094      pof:280603467     pof:268252594        33.0        female   \n",
      "4618366     pof:332744870     pof:310626492        37.0          male   \n",
      "\n",
      "         viewer_longitude  viewer_latitude viewer_lang viewer_country  \\\n",
      "4129856         77.583000        12.983000          en             IN   \n",
      "4642062       -118.120003        34.591000          en             US   \n",
      "1471301        -73.254501        40.780899          es             US   \n",
      "2640883        126.981003        37.162998          ko             KR   \n",
      "1826086          1.861100        41.636002          es             ES   \n",
      "4615372        -76.325996       -12.237400          es             US   \n",
      "4971800        -75.259903         5.284200          en             US   \n",
      "2626976        121.503998        25.257999          zh             TW   \n",
      "448094         -78.400002        36.299999          en             US   \n",
      "4618366         -2.700000        53.299999          en             US   \n",
      "\n",
      "         broadcaster_age broadcaster_gender  broadcaster_longitude  \\\n",
      "4129856             36.0             female             100.900803   \n",
      "4642062             28.0             female            -118.244003   \n",
      "1471301             46.0             female             -73.199997   \n",
      "2640883             36.0             female             126.538002   \n",
      "1826086             29.0               male               2.070400   \n",
      "4615372             20.0             female             -73.446800   \n",
      "4971800             35.0             female            -124.117996   \n",
      "2626976             27.0             female             121.987000   \n",
      "448094              28.0               male             -97.300003   \n",
      "4618366             32.0             female              -1.700000   \n",
      "\n",
      "         broadcaster_latitude broadcaster_lang broadcaster_country  duration  \\\n",
      "4129856             12.916100               en                  TH        83   \n",
      "4642062             34.054001               en                  US      2628   \n",
      "1471301             40.799999               en                  US       632   \n",
      "2640883             33.262001               ko                  KR        71   \n",
      "1826086             41.355598               es                  ES        73   \n",
      "4615372              8.510800               es                  CO       109   \n",
      "4971800             43.695999               en                  US      1751   \n",
      "2626976              6.429600               en                  PH       161   \n",
      "448094              33.000000               en                  US       575   \n",
      "4618366             53.799999               en                  GB       119   \n",
      "\n",
      "        viewer_network broadcaster_network count  \\\n",
      "4129856          skout              meetme     1   \n",
      "4642062          skout               skout     4   \n",
      "1471301         meetme                 pof     3   \n",
      "2640883          skout               skout     2   \n",
      "1826086         meetme              meetme     2   \n",
      "4615372         meetme              meetme     2   \n",
      "4971800         meetme               skout     1   \n",
      "2626976          skout              meetme     1   \n",
      "448094             pof                 pof     1   \n",
      "4618366            pof                 pof     1   \n",
      "\n",
      "                                viewer_lat_long  \n",
      "4129856    12.982999801635742,77.58300018310547  \n",
      "4642062  34.590999603271484,-118.12000274658203  \n",
      "1471301    40.78089904785156,-73.25450134277344  \n",
      "2640883    37.16299819946289,126.98100280761719  \n",
      "1826086    41.63600158691406,1.8610999584197998  \n",
      "4615372   -12.23740005493164,-76.32599639892578  \n",
      "4971800    5.284200191497803,-75.25990295410156  \n",
      "2626976   25.257999420166016,121.50399780273438  \n",
      "448094      36.29999923706055,-78.4000015258789  \n",
      "4618366    53.29999923706055,-2.700000047683716  \n",
      "                   viewer       broadcaster  viewer_age viewer_gender  \\\n",
      "3947345   skout:177532849   skout:183924377        43.0          male   \n",
      "1966579     pof:300836320  meetme:310889068        34.0          male   \n",
      "5373944  meetme:295888020     pof:333216523        19.0          male   \n",
      "1972951  meetme:311186898  meetme:318043425        35.0          male   \n",
      "3437726   skout:183980999   skout:175506070        28.0          male   \n",
      "2646783  meetme:315161042  meetme:317819222        25.0          male   \n",
      "3955206  meetme:260272496  meetme:299018031        22.0          male   \n",
      "2867483     pof:151715918     pof:163068442        31.0          male   \n",
      "4647237   skout:158708209  meetme:311824537        29.0          male   \n",
      "354548   meetme:282097834     pof:325410156        42.0          male   \n",
      "\n",
      "         viewer_longitude  viewer_latitude viewer_lang viewer_country  \\\n",
      "3947345        -84.361000        33.848999          en             US   \n",
      "1966579        -97.699997        30.200001          en             US   \n",
      "5373944       -117.197601        33.831902          en             US   \n",
      "1972951         51.532501        25.232100          en             US   \n",
      "3437726        121.037003        14.587000          en             GB   \n",
      "2646783       -107.447304        24.809900          es             ES   \n",
      "3955206       -100.756798        46.794701          en             US   \n",
      "2867483        -80.900002        35.099998          en             US   \n",
      "4647237        -73.917999        40.631001          en             US   \n",
      "354548         121.059998        14.091900          en             US   \n",
      "\n",
      "         broadcaster_age broadcaster_gender  broadcaster_longitude  \\\n",
      "3947345             28.0               male              -0.258000   \n",
      "1966579             22.0             female            -118.239304   \n",
      "5373944             37.0             female            -118.300003   \n",
      "1972951             29.0             female              51.531898   \n",
      "3437726             30.0             female             120.995003   \n",
      "2646783             26.0             female             -73.105003   \n",
      "3955206             39.0             female             -74.525200   \n",
      "2867483             30.0               male            -119.800003   \n",
      "4647237             25.0             female             -73.994499   \n",
      "354548              19.0               male              -1.700000   \n",
      "\n",
      "         broadcaster_latitude broadcaster_lang broadcaster_country  duration  \\\n",
      "3947345             52.368000               en                  GB        84   \n",
      "1966579             34.063400               en                  US        73   \n",
      "5373944             33.799999               en                  US      1337   \n",
      "1972951             25.285200               en                  QA       250   \n",
      "3437726             14.552000               en                  PH        82   \n",
      "2646783              7.099800               es                  CO      1117   \n",
      "3955206             40.311199               en                  US        95   \n",
      "2867483             36.799999               en                  US        79   \n",
      "4647237             40.752102               en                  US       450   \n",
      "354548              54.599998               en                  GB      4358   \n",
      "\n",
      "        viewer_network broadcaster_network count  \\\n",
      "3947345          skout               skout     2   \n",
      "1966579            pof              meetme     2   \n",
      "5373944         meetme                 pof     1   \n",
      "1972951         meetme              meetme     1   \n",
      "3437726          skout               skout     3   \n",
      "2646783         meetme              meetme    10   \n",
      "3955206         meetme              meetme     1   \n",
      "2867483            pof                 pof     1   \n",
      "4647237          skout              meetme     1   \n",
      "354548          meetme                 pof     1   \n",
      "\n",
      "                                viewer_lat_long  \n",
      "3947345     33.8489990234375,-84.36100006103516  \n",
      "1966579   30.200000762939453,-97.69999694824219  \n",
      "5373944   33.83190155029297,-117.19760131835938  \n",
      "1972951   25.232099533081055,51.532501220703125  \n",
      "3437726   14.586999893188477,121.03700256347656  \n",
      "2646783  24.809900283813477,-107.44730377197266  \n",
      "3955206  46.794700622558594,-100.75679779052734  \n",
      "2867483    35.099998474121094,-80.9000015258789  \n",
      "4647237    40.63100051879883,-73.91799926757812  \n",
      "354548    14.091899871826172,121.05999755859375  \n",
      "creating data set\n",
      "{'broadcaster': b'meetme:250339028',\n",
      " 'broadcaster_network': b'meetme',\n",
      " 'viewer': b'skout:183939265',\n",
      " 'viewer_age': 29,\n",
      " 'viewer_country': b'IN',\n",
      " 'viewer_gender': b'male',\n",
      " 'viewer_lang': b'en',\n",
      " 'viewer_lat_long': b'12.982999801635742,77.58300018310547',\n",
      " 'viewer_latitude': 12.984,\n",
      " 'viewer_longitude': 77.56,\n",
      " 'viewer_network': b'skout'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-15 14:22:32.448036: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "ratings = load_training_data_cold(file=\"csv/a3d86f3b-eb45-4641-b05d-30dff7423e6b.csv\", stats=\"\")\n",
    "\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc0540",
   "metadata": {},
   "source": [
    "### Defining the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83c7bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcaster_lookup = tf.keras.layers.experimental.preprocessing.StringLookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fef4c9ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0f31cdc20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0f31cdc20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0f31cddd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0f31cddd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "broadcaster_lookup.adapt(ratings.map(lambda x: x[\"broadcaster\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28aeee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['[UNK]', 'meetme:277903808', 'meetme:50697624', 'meetme:219070323', 'pof:300442673', 'pof:322045884', 'pof:319663298', 'pof:315853960', 'pof:297373249', 'meetme:283611530', 'pof:79582086', 'skout:150743909', 'pof:299641758', 'meetme:309755964', 'meetme:197536011', 'meetme:294844287', 'meetme:308663123', 'skout:39313218', 'meetme:228586518', 'meetme:195325769']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulary: {broadcaster_lookup.get_vocabulary()[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "690ca2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69797"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcaster_lookup.vocabulary_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d83446fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([0, 1, 2])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcaster_lookup([\"[UNK]\", \"meetme:277903808\", \"meetme:50697624\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5f214",
   "metadata": {},
   "source": [
    "### Using feature hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81404e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set up a large number of bins to reduce the chance of hash collisions.\n",
    "num_hashing_bins = 200_000\n",
    "\n",
    "broadcaster_hashing = tf.keras.layers.experimental.preprocessing.Hashing(\n",
    "    num_bins=num_hashing_bins\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b928b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([ 18280, 193815, 180119])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcaster_hashing([\"[UNK]\", \"meetme:277903808\", \"meetme:50697624\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f7650f",
   "metadata": {},
   "source": [
    "### Defining the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d84a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcaster_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=broadcaster_lookup.vocabulary_size(),\n",
    "    output_dim=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31bd8334",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcaster_model = tf.keras.Sequential([broadcaster_lookup, broadcaster_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd48088e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['meetme:277903808']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[-0.00220549,  0.00318506, -0.04274105, -0.03318482,  0.01996905,\n",
       "        -0.00360984,  0.03728544,  0.04276649,  0.02944965, -0.01693236,\n",
       "        -0.03837664,  0.02658382, -0.01988866, -0.02986122,  0.02398682,\n",
       "        -0.00580009,  0.0463425 , -0.02724286,  0.03874153, -0.00180887,\n",
       "        -0.00071955, -0.02124978, -0.03418276,  0.03018219, -0.02725717,\n",
       "         0.03669694,  0.04854344,  0.0132411 ,  0.02092062,  0.04907768,\n",
       "        -0.04367078, -0.01637457]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcaster_model([\"meetme:277903808\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c592e0c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc17b19d170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc17b19d170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc17b19d9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc17b19d9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# user embedding\n",
    "user_id_lookup = tf.keras.layers.experimental.preprocessing.StringLookup()\n",
    "user_id_lookup.adapt(ratings.map(lambda x: x[\"viewer\"]))\n",
    "\n",
    "user_id_embedding = tf.keras.layers.Embedding(user_id_lookup.vocabulary_size(), 32)\n",
    "user_id_model = tf.keras.Sequential([user_id_lookup, user_id_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c81d6876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['meetme:277903808']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[ 0.01943531, -0.00493991, -0.00137669,  0.0355396 , -0.02645339,\n",
       "        -0.00294147,  0.03740872,  0.02480601, -0.04640242,  0.03370896,\n",
       "        -0.02711483,  0.00093615,  0.01668551,  0.03670264,  0.01320238,\n",
       "        -0.0214431 ,  0.04782381,  0.00272961,  0.04388637,  0.02362683,\n",
       "         0.02637327, -0.02401898, -0.03807665, -0.00941879,  0.0490785 ,\n",
       "        -0.04063647,  0.03368082, -0.01720614, -0.0470655 , -0.00019421,\n",
       "        -0.04578037,  0.04345498]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_model([\"meetme:277903808\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16727aa",
   "metadata": {},
   "source": [
    "### Normalizing continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50bdbb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viewer_age: 29.\n",
      "viewer_age: 26.\n",
      "viewer_age: 25.\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(3).as_numpy_iterator():\n",
    "    print(f\"viewer_age: {x['viewer_age']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b905c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0f15030e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0f15030e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0f1503440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0f1503440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Normalized viewer age: [-0.52391666].\n",
      "Normalized viewer age: [-0.83302295].\n",
      "Normalized viewer age: [-0.9360584].\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "viewer_age_normalization = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "    axis=None\n",
    ")\n",
    "viewer_age_normalization.adapt(ratings.map(lambda x: x['viewer_age']).batch(32))\n",
    "\n",
    "for x in ratings.take(3).as_numpy_iterator():\n",
    "    print(f\"Normalized viewer age: {viewer_age_normalization(x['viewer_age'])}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d66332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0f14e4320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0f14e4320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0f14e4830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0f14e4830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Buckets: [ 18.          38.22222222  58.44444444  78.66666667  98.88888889\n",
      " 119.11111111 139.33333333 159.55555556 179.77777778 200.        ]\n"
     ]
    }
   ],
   "source": [
    "# Discretization\n",
    "max_viewer_age = ratings.map(lambda x: x[\"viewer_age\"]).reduce(\n",
    "    tf.cast(0, tf.int32), tf.maximum).numpy().max()\n",
    "min_viewer_age = ratings.map(lambda x: x[\"viewer_age\"]).reduce(\n",
    "    np.int32(100), tf.minimum).numpy().min()\n",
    "\n",
    "viewer_age_buckets = np.linspace(\n",
    "    min_viewer_age, max_viewer_age, num=10)\n",
    "\n",
    "print(f\"Buckets: {viewer_age_buckets[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "818bfca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc18c4469e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc18c4469e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Viewer_age embedding: [[-0.03302993  0.03110944  0.01416438 -0.01521438 -0.03592966 -0.02223239\n",
      "  -0.04625424 -0.00605955  0.00684149 -0.02312992 -0.01667572 -0.03321574\n",
      "  -0.02386065 -0.02983061  0.0152416   0.03268285  0.04790663  0.04542525\n",
      "  -0.02657044 -0.04043273 -0.03326219  0.04068789  0.04848525  0.02951981\n",
      "   0.04435328  0.02764675 -0.00330366 -0.03459014  0.00951219 -0.04073434\n",
      "   0.017962    0.01527431]].\n"
     ]
    }
   ],
   "source": [
    "# Given the bucket boundaries we can transform timestamps into embeddings:\n",
    "viewer_age_embedding_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Discretization(viewer_age_buckets.tolist()),\n",
    "  tf.keras.layers.Embedding(len(viewer_age_buckets) + 1, 32)\n",
    "])\n",
    "\n",
    "for viewer_age in ratings.take(1).map(lambda x: x[\"viewer_age\"]).batch(1).as_numpy_iterator():\n",
    "    print(f\"Viewer_age embedding: {viewer_age_embedding_model(viewer_age)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681eea49",
   "metadata": {},
   "source": [
    "### Processing text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d372997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_colons(text):\n",
    "    return tf.strings.split(text, sep=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a46d7977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0deadba70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0deadba70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0deaf3f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0deaf3f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "broadcaster_text = tf.keras.layers.experimental.preprocessing.TextVectorization(standardize= None, split=split_on_colons)\n",
    "broadcaster_text.adapt(ratings.map(lambda x: x[\"broadcaster\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63ac3797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc13bf7b560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc13bf7b560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "tf.Tensor([[    3 13467]], shape=(1, 2), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for row in ratings.batch(1).map(lambda x: x[\"broadcaster\"]).take(1):\n",
    "  print(broadcaster_text(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa6cda09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'meetme',\n",
       " 'pof',\n",
       " 'skout',\n",
       " '277903808',\n",
       " '50697624',\n",
       " 'zoosk',\n",
       " '219070323',\n",
       " '300442673']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcaster_text.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5992dede",
   "metadata": {},
   "source": [
    "### User Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "094d845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.user_embedding = tf.keras.Sequential([\n",
    "\t\t\tuser_id_lookup,\n",
    "\t\t\ttf.keras.layers.Embedding(user_id_lookup.vocabulary_size(), 32),\n",
    "\t\t])\n",
    "        \n",
    "\t\tself.viewer_age_embedding = tf.keras.Sequential([\n",
    "\t\t\ttf.keras.layers.experimental.preprocessing.Discretization(viewer_age_buckets.tolist()),\n",
    "\t\t\ttf.keras.layers.Embedding(len(viewer_age_buckets) + 1, 32)\n",
    "\t\t])\n",
    "\t\tself.normalized_viewer_age = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "\t\t\taxis = None\n",
    "\t\t)\n",
    "\n",
    "\tdef call(self, inputs):\n",
    "\t\t# Take the input dictionary, pass it through each input layer,\n",
    "\t\t# and concatenate the result.\n",
    "\t\treturn tf.concat([\n",
    "\t\t\tself.user_embedding(inputs[\"viewer\"]),\n",
    "\t\t\tself.viewer_age_embedding(inputs[\"viewer_age\"]),\n",
    "\t\t\ttf.reshape(self.normalized_viewer_age(inputs[\"viewer_age\"]), (-1, 1))\n",
    "\t\t], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43c1e345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0c9606050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0c9606050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0deadbcb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0deadbcb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Computed representations: [-0.03831752 -0.03813299  0.0499326 ]\n"
     ]
    }
   ],
   "source": [
    "user_model = UserModel()\n",
    "\n",
    "user_model.normalized_viewer_age.adapt(\n",
    "    ratings.map(lambda x: x[\"viewer_age\"]).batch(128))\n",
    "\n",
    "for row in ratings.batch(1).take(1):\n",
    "    print(f\"Computed representations: {user_model(row)[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a45541",
   "metadata": {},
   "source": [
    "### Broadcaster model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b312323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0db1ad950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0db1ad950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "broadcaster_ids = ratings.batch(100_000).map(lambda x: x[\"broadcaster\"])\n",
    "unique_broadcaster_ids = np.unique(np.concatenate(list(broadcaster_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49390625",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BroadcasterModel(tf.keras.Model) :\n",
    "\n",
    "\tdef __init__(self) :\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tmax_tokens = 32\n",
    "\t\tself.broadcaster_embedding = tf.keras.Sequential([\n",
    "\t\t\ttf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "\t\t\t\tvocabulary = unique_broadcaster_ids, max_tokens=None),\n",
    "\t\t\ttf.keras.layers.Embedding(len(unique_broadcaster_ids) + 1, 32)\n",
    "\t\t])\n",
    "        \n",
    "\t\tself.broadcaster_text_embedding = tf.keras.Sequential([\n",
    "\t\t\ttf.keras.layers.experimental.preprocessing.TextVectorization(standardize= None, split=split_on_colons, max_tokens=32),\n",
    "\t\t\ttf.keras.layers.Embedding(max_tokens, 32, mask_zero = True),\n",
    "\t\t\t# We average the embedding of individual words to get one embedding vector\n",
    "\t\t\t# per title.\n",
    "\t\t\ttf.keras.layers.GlobalAveragePooling1D(),\n",
    "\t\t])\n",
    "\n",
    "\n",
    "\tdef call(self, inputs) :\n",
    "\t\treturn tf.concat([\n",
    "\t\t\tself.broadcaster_embedding(inputs[\"broadcaster\"]),\n",
    "\t\t\tself.broadcaster_text_embedding(inputs[\"broadcaster\"]),\n",
    "\t\t], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26da5b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0f1780f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0f1780f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0cddd5170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0cddd5170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Computed representations: [ 0.0276117  -0.04592123  0.02068477]\n"
     ]
    }
   ],
   "source": [
    "broadcaster_model = BroadcasterModel()\n",
    "\n",
    "broadcaster_model.broadcaster_text_embedding.layers[0].adapt(\n",
    "    ratings.map(lambda x: x[\"broadcaster\"]))\n",
    "\n",
    "for row in ratings.batch(1).take(1):\n",
    "    print(f\"Computed representations: {broadcaster_model(row)[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e46f2",
   "metadata": {},
   "source": [
    "### Preprocessing Lat/Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ba88355c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f9861689290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7f9861689290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "lat_long = (ratings\n",
    "           # Retain only the fields we need.\n",
    "           .map(lambda x: {\"viewer_latitude\": x[\"viewer_latitude\"], \n",
    "                           \"viewer_longitude\": x[\"viewer_longitude\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e170ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "CENTROIDS = np.array([[36.68147669256268, -82.8910274009993],\n",
    "                      [23.22243322909555, 78.23027450833709],\n",
    "                      [50.04997682638993, 0.22379313938744885],\n",
    "                      [37.9309447099281, -117.00741350764692],\n",
    "                      [-32.795864819917725, 148.7159172660312],\n",
    "                      [-18.570548393114084, -54.280255665692565],\n",
    "                      [13.921140442819565, 116.38740315555172],\n",
    "                      [29.78951080730802, 40.279515865947936]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a8f8cb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CENTROIDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "acb2b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(datapoint):\n",
    "    \"\"\"\n",
    "    given a datapoint, compute the cluster closest to the\n",
    "    datapoint. Return the cluster ID of that cluster.\n",
    "    :param datapoint:\n",
    "    :return: cluster ID\n",
    "    \"\"\"\n",
    "#     datapoint = np.zeros(shape=(1, 2))\n",
    "#     datapoint[0] = lat\n",
    "#     print(datapoint)\n",
    "#     datapoint[1] = long\n",
    "#     datapoint = [lat, long]\n",
    "    print(datapoint)\n",
    "    dists = np.sqrt(np.sum((CENTROIDS - datapoint) ** 2, axis = 1))\n",
    "    return np.argmin(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b361861e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.7, 77.1]\n",
      "1\n",
      "[40.22, -84.8]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for row in lat_long.take(2).as_numpy_iterator():\n",
    "    res = classify([row['viewer_latitude'], row['viewer_longitude']])\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "04e21f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c7927a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_clusters = 8\n",
    "viewer_lat_long_embedding = tf.keras.Sequential([\n",
    "    tf.keras.layers.Lambda(lambda x: classify(x)), \n",
    "    tf.keras.layers.Embedding(unique_clusters + 1, 2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "26582bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'28.7|77.1'\n",
      "'40.22|-84.8'\n",
      "'37.0|-122.0'\n",
      "'41.5|-87.7'\n",
      "'29.77|-95.7'\n",
      "'32.2|-90.3'\n",
      "'32.7|-97.0'\n",
      "'-7.938|-34.88'\n",
      "'42.44|-83.3'\n",
      "'43.28|-76.4'\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(10).as_numpy_iterator():\n",
    "    pprint.pprint(str(x['viewer_latitude']) + \"|\" + str(x['viewer_longitude']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62293a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(\"1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6409af5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "90aa830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(pair):\n",
    "    \"\"\"\n",
    "    given a datapoint, compute the cluster closest to the\n",
    "    datapoint. Return the cluster ID of that cluster.\n",
    "    :param datapoint:\n",
    "    :return: cluster ID\n",
    "    \"\"\"\n",
    "    datapoint = pair.numpy().tolist()\n",
    "    dists = np.sqrt(np.sum((CENTROIDS - datapoint) ** 2, axis = 1))\n",
    "    return tf.constant([np.argmin(dists)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7c9e669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7ffbc0e7a560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7ffbc0e7a560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "array([ 43.9, -78.9], dtype=float16)\n",
      "array([ 14.51, 121.  ], dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "latlong = ratings.map(lambda x: tf.stack([x[\"viewer_latitude\"], x[\"viewer_longitude\"]]))\n",
    "for val in latlong.take(2).as_numpy_iterator():\n",
    "    pprint.pprint(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ef9dd77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28.703125, 77.125]]\n",
      "tf.Tensor(\n",
      "[[ 0.00398612  0.0471969  -0.00608052 -0.02895863 -0.03615345 -0.0151992\n",
      "  -0.04495274 -0.04468764 -0.0247431   0.02581981  0.04732665  0.04497429\n",
      "  -0.01733258  0.01310393 -0.02832994 -0.04735022  0.0124325  -0.01465311\n",
      "   0.04150859 -0.00486708 -0.02039013  0.02938708  0.03096035  0.01580676\n",
      "  -0.0127617  -0.02478284 -0.02168956  0.01502671 -0.04769066  0.02023294\n",
      "  -0.02210033  0.01853705]], shape=(1, 32), dtype=float32)\n",
      "[[40.21875, -84.8125]]\n",
      "tf.Tensor(\n",
      "[[-0.02717905  0.03290197 -0.04601464  0.00960105 -0.03947737 -0.02975992\n",
      "   0.0410358  -0.00295651 -0.01346616  0.01446816  0.02706251 -0.01199473\n",
      "  -0.0110734  -0.00836089  0.04716246  0.04230661 -0.00511326 -0.03318679\n",
      "   0.03733987 -0.04369868 -0.03661479 -0.00964867  0.03899993  0.04625989\n",
      "   0.02531463 -0.00039531  0.02407861 -0.01779387  0.02972336 -0.02403492\n",
      "   0.01394169  0.01960785]], shape=(1, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "viewer_latitude_longitude = tf.keras.Sequential([\n",
    "  tf.keras.layers.Lambda(lambda x: classify(x)), \n",
    "  tf.keras.layers.Embedding(len(viewer_latitude_longitude_buckets) + 1, 32)\n",
    "])\n",
    "\n",
    "for val in latlong.take(2).batch(1).as_numpy_iterator():\n",
    "    print(viewer_latitude_longitude(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4189156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72401031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 1, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "353d152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = tf.constant([[36.68147669256268, -82.8910274009993],[13.921140442819565, 116.38740315555172],[29.78951080730802, 40.279515865947936]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "042b4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_vectors = tf.expand_dims(samples, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d1445cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 2), dtype=float32, numpy=\n",
       "array([[[ 36.681477, -82.89103 ],\n",
       "        [ 13.921141, 116.387405],\n",
       "        [ 29.78951 ,  40.279514]]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0fd95689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[    0.     40229.93   15218.482 ]\n",
      " [26141.223   1542.4805  1483.387 ]\n",
      " [ 7086.7905 14799.277   2014.9473]\n",
      " [ 1165.489  55049.613  24805.46  ]\n",
      " [58468.875   3227.6106 15675.382 ]\n",
      " [ 3871.3628 30183.162  11280.245 ]\n",
      " [40229.93       0.      6044.217 ]\n",
      " [15218.482   6044.217      0.    ]], shape=(8, 3), dtype=float32)\n",
      "tf.Tensor([0 6 7], shape=(3,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "distances = tf.reduce_sum(tf.square(tf.subtract(expanded_vectors, expanded_centroids)), 2)\n",
    "print(distances)\n",
    "cluster = tf.math.argmin(distances)\n",
    "print(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "86477683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(pair):\n",
    "    \"\"\"\n",
    "    given a datapoint, compute the cluster closest to the datapoint. Return the cluster ID of that cluster.\n",
    "    :param pair:\n",
    "    :return: cluster ID\n",
    "    \"\"\"\n",
    "    centroids = tf.constant([\n",
    "         [36.68147669256268, -82.8910274009993],\n",
    "         [23.22243322909555, 78.23027450833709],\n",
    "         [50.04997682638993, 0.22379313938744885],\n",
    "         [37.9309447099281, -117.00741350764692],\n",
    "         [-32.795864819917725, 148.7159172660312],\n",
    "         [-18.570548393114084, -54.280255665692565],\n",
    "         [13.921140442819565, 116.38740315555172],\n",
    "         [29.78951080730802, 40.279515865947936]]\n",
    "    )\n",
    "    expanded_centroids = tf.expand_dims(centroids, 1)\n",
    "\n",
    "    latlong = tf.strings.split(pair, sep=\",\")\n",
    "    datapoints = [tf.strings.to_number(splits) for splits in latlong]\n",
    "    expanded_vectors = tf.expand_dims(datapoints, 0)\n",
    "    \n",
    "    distances = tf.reduce_sum(tf.square(tf.subtract(expanded_vectors, expanded_centroids)), 2)\n",
    "    clusters = tf.math.argmin(distances)\n",
    "    print(clusters)\n",
    "    return tf.strings.as_string(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "16a3e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_lat_long_embedding = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    standardize= None, split=classify, vocabulary=['0', '1', '2', '3', '4', '5', '6', '7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bc62cc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc898287d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc898287d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "tf.Tensor([b'12.982999801635742,77.58300018310547'], shape=(1,), dtype=string)\n",
      "tf.Tensor([1], shape=(1,), dtype=int64)\n",
      "Viewer_latlong embedding: [3].\n",
      "tf.Tensor([b'34.590999603271484,-118.12000274658203'], shape=(1,), dtype=string)\n",
      "tf.Tensor([3], shape=(1,), dtype=int64)\n",
      "Viewer_latlong embedding: [5].\n",
      "tf.Tensor([b'40.78089904785156,-73.25450134277344'], shape=(1,), dtype=string)\n",
      "tf.Tensor([0], shape=(1,), dtype=int64)\n",
      "Viewer_latlong embedding: [2].\n",
      "tf.Tensor([b'37.16299819946289,126.98100280761719'], shape=(1,), dtype=string)\n",
      "tf.Tensor([6], shape=(1,), dtype=int64)\n",
      "Viewer_latlong embedding: [8].\n",
      "tf.Tensor([b'41.63600158691406,1.8610999584197998'], shape=(1,), dtype=string)\n",
      "tf.Tensor([2], shape=(1,), dtype=int64)\n",
      "Viewer_latlong embedding: [4].\n",
      "tf.Tensor([b'-12.23740005493164,-76.32599639892578'], shape=(1,), dtype=string)\n",
      "tf.Tensor([5], shape=(1,), dtype=int64)\n",
      "Viewer_latlong embedding: [7].\n",
      "tf.Tensor([b'5.284200191497803,-75.25990295410156'], shape=(1,), dtype=string)\n",
      "tf.Tensor([5], shape=(1,), dtype=int64)\n",
      "Viewer_latlong embedding: [7].\n",
      "tf.Tensor([b'25.257999420166016,121.50399780273438'], shape=(1,), dtype=string)\n",
      "tf.Tensor([6], shape=(1,), dtype=int64)\n",
      "Viewer_latlong embedding: [8].\n",
      "tf.Tensor([b'36.29999923706055,-78.4000015258789'], shape=(1,), dtype=string)\n",
      "tf.Tensor([0], shape=(1,), dtype=int64)\n",
      "Viewer_latlong embedding: [2].\n",
      "tf.Tensor([b'53.29999923706055,-2.700000047683716'], shape=(1,), dtype=string)\n",
      "tf.Tensor([2], shape=(1,), dtype=int64)\n",
      "Viewer_latlong embedding: [4].\n"
     ]
    }
   ],
   "source": [
    "for pair in ratings.batch(1).map(lambda x: x[\"viewer_lat_long\"]).take(10):\n",
    "    print(pair)\n",
    "    print(f\"Viewer_latlong embedding: {viewer_lat_long_embedding(pair)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f87eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d5b8e74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f9850dedef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7f9850dedef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function pfor.<locals>.f at 0x7f98ba08e950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function pfor.<locals>.f at 0x7f98ba08e950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7f98ba08e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Viewer_age embedding: [[-0.04835718  0.0053164   0.01803212  0.00861342 -0.01517547 -0.03086997\n",
      "  -0.00026621  0.00785236 -0.03899376  0.02694774 -0.03538787  0.04030177\n",
      "   0.02204723 -0.00679271  0.02655813  0.02311156 -0.00105906 -0.02897467\n",
      "  -0.02644916  0.03826013 -0.00648944 -0.00723293  0.00612266  0.04484392\n",
      "  -0.03673737  0.0118299   0.01947837 -0.02774694 -0.02952962  0.04815197\n",
      "   0.01437924 -0.00040182]].\n"
     ]
    }
   ],
   "source": [
    "viewer_age_buckets = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "# Given the bucket boundaries we can transform timestamps into embeddings:\n",
    "viewer_age_embedding_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Lambda(lambda x: x ** 2), \n",
    "  tf.keras.layers.experimental.preprocessing.Discretization(viewer_age_buckets),\n",
    "  tf.keras.layers.Embedding(len(viewer_age_buckets) + 1, 32)\n",
    "])\n",
    "\n",
    "for viewer_age in ratings.take(1).map(lambda x: x[\"viewer_age\"]).batch(1).as_numpy_iterator():\n",
    "    print(f\"Viewer_age embedding: {viewer_age_embedding_model(viewer_age)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "43a2fa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7f9850dedb90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7f9850dedb90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "<MapDataset shapes: {viewer_latitude: (), viewer_longitude: ()}, types: {viewer_latitude: tf.float16, viewer_longitude: tf.float16}>\n"
     ]
    }
   ],
   "source": [
    "latlong = (ratings\n",
    "           .take(1)\n",
    "           # Retain only the fields we need.\n",
    "           .map(lambda x: {\"viewer_latitude\": x[\"viewer_latitude\"], \n",
    "                           \"viewer_longitude\": x[\"viewer_longitude\"]}))\n",
    "print(latlong)\n",
    "    \n",
    "#     print(f\"Viewer_lat_long_cluster: {viewer_lat_long_cluster_embedding(latlong)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a4f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
