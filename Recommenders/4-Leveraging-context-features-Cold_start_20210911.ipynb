{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64aac552",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/recommenders/examples/context_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74002f2",
   "metadata": {},
   "source": [
    "In the featurization tutorial we incorporated multiple features beyond just user and movie identifiers into our models, but we haven't explored whether those features improve model accuracy.\n",
    "\n",
    "Many factors affect whether features beyond ids are useful in a recommender model:\n",
    "\n",
    "- Importance of context: if user preferences are relatively stable across contexts and time, context features may not provide much benefit. If, however, users preferences are highly contextual, adding context will improve the model significantly. For example, day of the week may be an important feature when deciding whether to recommend a short clip or a movie: users may only have time to watch short content during the week, but can relax and enjoy a full-length movie during the weekend. Similarly, query timestamps may play an important role in modelling popularity dynamics: one movie may be highly popular around the time of its release, but decay quickly afterwards. Conversely, other movies may be evergreens that are happily watched time and time again.\n",
    "\n",
    "- Data sparsity: using non-id features may be critical if data is sparse. With few observations available for a given user or item, the model may struggle with estimating a good per-user or per-item representation. To build an accurate model, other features such as item categories, descriptions, and images have to be used to help the model generalize beyond the training data. This is especially relevant in cold-start situations, where relatively little data is available on some items or users.\n",
    "\n",
    "In this tutorial, we'll experiment with using features beyond movie titles and user ids to our MovieLens model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43a06d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2495d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98778e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3af789a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_file_cold(file, stats):\n",
    "    print('loading file:' + file)\n",
    "    training_df = pd.read_csv(\n",
    "        file,\n",
    "        skiprows=[0],\n",
    "        names=[\"viewer\",\"broadcaster\",\"viewer_age\",\"viewer_gender\",\"viewer_longitude\",\"viewer_latitude\",\"viewer_lang\",\"viewer_country\",\"broadcaster_age\",\"broadcaster_gender\",\"broadcaster_longitude\",\"broadcaster_latitude\",\"broadcaster_lang\",\"broadcaster_country\",\"duration\", \"viewer_network\", \"broadcaster_network\", \"count\"], dtype={\n",
    "            'viewer': np.unicode,\n",
    "            'broadcaster': np.unicode,\n",
    "            'viewer_age': np.single,\n",
    "            'viewer_gender': np.unicode,\n",
    "            'viewer_longitude': np.single,\n",
    "            'viewer_latitude': np.single,\n",
    "            'viewer_lang': np.unicode,\n",
    "            'viewer_country': np.unicode,\n",
    "            'broadcaster_age': np.single,\n",
    "            'broadcaster_longitude': np.single,\n",
    "            'broadcaster_latitude': np.single,\n",
    "            'broadcaster_lang': np.unicode,\n",
    "            'broadcaster_country': np.unicode,\n",
    "            'viewer_network': np.unicode,\n",
    "            'broadcaster_network': np.unicode,\n",
    "            'count': np.int\n",
    "        })\n",
    "\n",
    "    values = {\n",
    "        'viewer': 'unknown',\n",
    "        'broadcaster': 'unknown',\n",
    "        'viewer_age': 30,\n",
    "        'viewer_gender': 'unknown',\n",
    "        'viewer_longitude': 0,\n",
    "        'viewer_latitude': 0,\n",
    "        'viewer_lang': 'unknown',\n",
    "        'viewer_country': 'unknown',\n",
    "        'broadcaster_age': 30,\n",
    "        'broadcaster_longitude': 0,\n",
    "        'broadcaster_latitude': 0,\n",
    "        'broadcaster_lang': 'unknown',\n",
    "        'broadcaster_country': 'unknown',\n",
    "        'duration': 0,\n",
    "        'viewer_network': 'unknown',\n",
    "        'broadcaster_network': 'unknown',\n",
    "        'count': 0\n",
    "    }\n",
    "    training_df.fillna(value=values, inplace=True)\n",
    "#     print(training_df.head(10))\n",
    "#     print(training_df.iloc[-10:])\n",
    "#     stats.send_stats('data-size', len(training_df.index))\n",
    "\n",
    "    sampled_df = training_df.sample(frac=0.1)\n",
    "    print(sampled_df.head(10))\n",
    "    print(sampled_df.iloc[-10:])\n",
    "    return sampled_df\n",
    "\n",
    "def load_training_data_cold(file, stats):\n",
    "    ratings_df = load_data_file_cold(file, stats)\n",
    "    print('creating data set')\n",
    "    training_ds = (\n",
    "        tf.data.Dataset.from_tensor_slices(\n",
    "            ({\n",
    "                \"viewer\": tf.cast(\n",
    "                    ratings_df['viewer'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_gender\": tf.cast(\n",
    "                    ratings_df['viewer_gender'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_lang\": tf.cast(\n",
    "                    ratings_df['viewer_lang'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_country\": tf.cast(\n",
    "                    ratings_df['viewer_country'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_age\": tf.cast(\n",
    "                    ratings_df['viewer_age'].values,\n",
    "                    tf.int32),\n",
    "                \"viewer_longitude\": tf.cast(\n",
    "                    ratings_df['viewer_longitude'].values,\n",
    "                    tf.float16),\n",
    "                \"viewer_latitude\": tf.cast(\n",
    "                    ratings_df['viewer_latitude'].values,\n",
    "                    tf.float16),\n",
    "                \"broadcaster\": tf.cast(\n",
    "                    ratings_df['broadcaster'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_network\": tf.cast(\n",
    "                    ratings_df['viewer_network'].values,\n",
    "                    tf.string),\n",
    "                \"broadcaster_network\": tf.cast(\n",
    "                    ratings_df['broadcaster_network'].values,\n",
    "                    tf.string),\n",
    "                \"duration\": tf.cast(\n",
    "                    ratings_df['duration'].values,\n",
    "                    tf.float16),\n",
    "                \"count\": tf.cast(\n",
    "                    ratings_df['count'].values,\n",
    "                    tf.int16),\n",
    "            })))\n",
    "\n",
    "    return training_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50cead25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file:a3d86f3b-eb45-4641-b05d-30dff7423e6b.csv\n",
      "                   viewer       broadcaster  viewer_age viewer_gender  \\\n",
      "4731785   skout:131343149   meetme:50697624        28.0          male   \n",
      "1028085  meetme:317851691  meetme:197352169        23.0        female   \n",
      "1002542     pof:139511590     pof:311948919        32.0          male   \n",
      "4870167  meetme:282350997   skout:182442567        26.0          male   \n",
      "3982465     pof:331724060  meetme:217326384        18.0          male   \n",
      "621051    skout:174803193   skout:176883477        23.0          male   \n",
      "5331658  meetme:272474641  meetme:217011623        30.0          male   \n",
      "5060029     pof:230907379  meetme:260137685        27.0          male   \n",
      "3856104  meetme:315932535     pof:324926889        31.0        female   \n",
      "5305467  meetme:318155027  meetme:158435532        35.0        female   \n",
      "\n",
      "         viewer_longitude  viewer_latitude viewer_lang viewer_country  \\\n",
      "4731785         47.967999        29.294001          en             US   \n",
      "1028085         28.060499        41.237202          de             DE   \n",
      "1002542         -1.900000        52.500000          en             US   \n",
      "4870167        -95.363403        29.763399          en             US   \n",
      "3982465        -77.900002        34.099998          en             US   \n",
      "621051         124.029999         9.962000          en             US   \n",
      "5331658        -82.459297        28.055201          en             US   \n",
      "5060029       -118.500000        34.099998          en             US   \n",
      "3856104        -78.501404        41.257801          en             US   \n",
      "5305467       -118.932701        35.388500          en             US   \n",
      "\n",
      "         broadcaster_age broadcaster_gender  broadcaster_longitude  \\\n",
      "4731785             33.0             female             -80.144699   \n",
      "1028085             29.0               male              27.182199   \n",
      "1002542             46.0             female              -2.500000   \n",
      "4870167             19.0             female             -82.302002   \n",
      "3982465             28.0             female             -82.375702   \n",
      "621051              26.0             female             123.912003   \n",
      "5331658             28.0               male             -75.291603   \n",
      "5060029             25.0             female            -118.524597   \n",
      "3856104             38.0             female             -81.199997   \n",
      "5305467             31.0               male            -118.708099   \n",
      "\n",
      "         broadcaster_latitude broadcaster_lang broadcaster_country  duration  \\\n",
      "4731785             25.784901               en                  US      1073   \n",
      "1028085             38.455799               tr                  TR      3206   \n",
      "1002542             51.500000               en                  GB      1271   \n",
      "4870167             27.900000               en                  US       143   \n",
      "3982465             40.177399               en                  US        88   \n",
      "621051              10.338000               en                  PH        48   \n",
      "5331658             43.069099               en                  US        72   \n",
      "5060029             34.264801               en                  US        79   \n",
      "3856104             42.900002               en                  CA        55   \n",
      "5305467             34.271702               en                  US      1261   \n",
      "\n",
      "        viewer_network broadcaster_network  count  \n",
      "4731785          skout              meetme      5  \n",
      "1028085         meetme              meetme      5  \n",
      "1002542            pof                 pof      4  \n",
      "4870167         meetme               skout      1  \n",
      "3982465            pof              meetme      1  \n",
      "621051           skout               skout      2  \n",
      "5331658         meetme              meetme      2  \n",
      "5060029            pof              meetme      1  \n",
      "3856104         meetme                 pof      2  \n",
      "5305467         meetme              meetme      1  \n",
      "                   viewer       broadcaster  viewer_age viewer_gender  \\\n",
      "4325884   skout:153125384   skout:172176448        44.0          male   \n",
      "2003863  meetme:206472832     pof:131142959        33.0        female   \n",
      "1657382  meetme:227592925  meetme:286716063        31.0          male   \n",
      "1778473     pof:236165091  meetme:316986314        42.0          male   \n",
      "2345462     pof:325797906     pof:316863102        29.0          male   \n",
      "710381   meetme:269127675      pof:79582086        26.0        female   \n",
      "4498848     pof:289882636     pof:332305113        26.0          male   \n",
      "736640    skout:179737710  meetme:314420331        28.0        female   \n",
      "753798      pof:258398204  meetme:265519573        34.0          male   \n",
      "3358311   skout:179025650  meetme:317995261        44.0          male   \n",
      "\n",
      "         viewer_longitude  viewer_latitude viewer_lang viewer_country  \\\n",
      "4325884        121.503998        25.257999          zh             TW   \n",
      "2003863        -73.994499        40.752102          en             US   \n",
      "1657382         -3.685100        40.426201          en             US   \n",
      "1778473         -0.400000        51.500000          en             US   \n",
      "2345462        153.500000       -28.100000          en             US   \n",
      "710381         -73.994499        40.752102          en             US   \n",
      "4498848        -92.300003        39.000000          en             US   \n",
      "736640         114.223000        22.332001          en             HK   \n",
      "753798         -86.900002        33.500000          en             US   \n",
      "3358311        -97.362000        31.070000          en             US   \n",
      "\n",
      "         broadcaster_age broadcaster_gender  broadcaster_longitude  \\\n",
      "4325884             35.0             female             120.647003   \n",
      "2003863             38.0               male             -97.699997   \n",
      "1657382             23.0             female             -73.856598   \n",
      "1778473             27.0             female              -0.275300   \n",
      "2345462             25.0             female             -82.800003   \n",
      "710381              37.0             female            -118.400002   \n",
      "4498848             37.0             female             -84.500000   \n",
      "736640              28.0               male             -77.250397   \n",
      "753798              30.0             female             -86.094299   \n",
      "3358311             45.0             female             -97.537003   \n",
      "\n",
      "         broadcaster_latitude broadcaster_lang broadcaster_country  duration  \\\n",
      "4325884             24.141001               zh                  TW        89   \n",
      "2003863             30.200001               en                  US       245   \n",
      "1657382             40.691502               en                  US       586   \n",
      "1778473             51.339199               en                  GB       523   \n",
      "2345462             40.000000               en                  US       132   \n",
      "710381              34.099998               en                  US      1405   \n",
      "4498848             42.700001               en                  US        91   \n",
      "736640              37.509102               en                  US        63   \n",
      "753798              32.323898               en                  US       776   \n",
      "3358311             30.319000               en                  US        83   \n",
      "\n",
      "        viewer_network broadcaster_network  count  \n",
      "4325884          skout               skout      1  \n",
      "2003863         meetme                 pof      2  \n",
      "1657382         meetme              meetme      1  \n",
      "1778473            pof              meetme      2  \n",
      "2345462            pof                 pof      1  \n",
      "710381          meetme                 pof     11  \n",
      "4498848            pof                 pof      1  \n",
      "736640           skout              meetme      1  \n",
      "753798             pof              meetme      4  \n",
      "3358311          skout              meetme      1  \n",
      "creating data set\n",
      "{'broadcaster': b'meetme:50697624',\n",
      " 'broadcaster_network': b'meetme',\n",
      " 'count': 5,\n",
      " 'duration': 1073.0,\n",
      " 'viewer': b'skout:131343149',\n",
      " 'viewer_age': 28,\n",
      " 'viewer_country': b'US',\n",
      " 'viewer_gender': b'male',\n",
      " 'viewer_lang': b'en',\n",
      " 'viewer_latitude': 29.3,\n",
      " 'viewer_longitude': 47.97,\n",
      " 'viewer_network': b'skout'}\n"
     ]
    }
   ],
   "source": [
    "ratings = load_training_data_cold(file=\"a3d86f3b-eb45-4641-b05d-30dff7423e6b.csv\", stats=\"\")\n",
    "\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f66e9239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fb4c60cbd40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fb4c60cbd40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "broadcasters = ratings.map(lambda x: x[\"broadcaster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a94618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'meetme:50697624'\n",
      "b'meetme:197352169'\n"
     ]
    }
   ],
   "source": [
    "for x in broadcasters.take(2).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f528a5b",
   "metadata": {},
   "source": [
    "### Prepare  features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7480c4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fb5302a74d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fb5302a74d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fb4c60cbb00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fb4c60cbb00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# Discretization\n",
    "max_viewer_age = ratings.map(lambda x: x[\"viewer_age\"]).reduce(\n",
    "    tf.cast(0, tf.int32), tf.maximum).numpy().max()\n",
    "min_viewer_age = ratings.map(lambda x: x[\"viewer_age\"]).reduce(\n",
    "    np.int32(100), tf.minimum).numpy().min()\n",
    "\n",
    "viewer_age_buckets = np.linspace(\n",
    "    min_viewer_age, max_viewer_age, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da861cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fb4b4daca70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fb4b4daca70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "249912"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = ratings.batch(1_00_000).map(lambda x: x[\"viewer\"])\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "len(unique_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52b6baf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fb4b4dac560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fb4b4dac560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69666"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcaster_ids = ratings.batch(1_00_000).map(lambda x: x[\"broadcaster\"])\n",
    "unique_broadcaster_ids = np.unique(np.concatenate(list(broadcaster_ids)))\n",
    "len(unique_broadcaster_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643bcda5",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311cff1c",
   "metadata": {},
   "source": [
    "### Query model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54f39792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fb4b4a0e7a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fb4b4a0e7a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "viewer_ages = np.concatenate(list(ratings.map(lambda x: x[\"viewer_age\"]).batch(1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d98c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "\tdef __init__(self, has_viewer_age):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself._viewer_age = has_viewer_age\n",
    "\n",
    "\t\tself.user_embedding = tf.keras.Sequential([\n",
    "\t\t\ttf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "\t\t\t\tvocabulary = unique_user_ids, mask_token = None),\n",
    "\t\t\ttf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
    "\t\t])\n",
    "\n",
    "\t\tif has_viewer_age:\n",
    "\t\t\tself.viewer_age_embedding = tf.keras.Sequential([\n",
    "\t\t\t\ttf.keras.layers.experimental.preprocessing.Discretization(viewer_age_buckets.tolist()),\n",
    "\t\t\t\ttf.keras.layers.Embedding(len(viewer_age_buckets) + 1, 32),\n",
    "\t\t\t])\n",
    "\t\t\tself.normalized_viewer_age = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "\t\t\t\taxis = None\n",
    "\t\t\t)\n",
    "\t\t\tself.normalized_viewer_age.adapt(viewer_ages)\n",
    "\n",
    "\tdef call(self, inputs):\n",
    "\t\tif not self._viewer_age:\n",
    "\t\t\treturn self.user_embedding(inputs[\"viewer\"])\n",
    "\n",
    "\t\treturn tf.concat([\n",
    "\t\t\tself.user_embedding(inputs[\"viewer\"]),\n",
    "\t\t\tself.viewer_age_embedding(inputs[\"viewer_age\"]),\n",
    "\t\t\ttf.reshape(self.normalized_viewer_age(inputs[\"viewer_age\"]), (-1, 1))\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24921ffd",
   "metadata": {},
   "source": [
    "### Candidate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60431082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_colons(text):\n",
    "    return tf.strings.split(text, sep=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59a8c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BroadcasterModel(tf.keras.Model) :\n",
    "\n",
    "\tdef __init__(self) :\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tmax_tokens = 32\n",
    "\n",
    "\t\tself.broadcaster_embedding = tf.keras.Sequential([\n",
    "\t\t\ttf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "\t\t\t\tvocabulary = unique_broadcaster_ids, max_tokens=None),\n",
    "\t\t\ttf.keras.layers.Embedding(len(unique_broadcaster_ids) + 1, 32)\n",
    "\t\t])\n",
    "        \n",
    "\t\tself.broadcaster_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "\t\t\tstandardize= None, split=split_on_colons, max_tokens = max_tokens)\n",
    "\n",
    "\t\tself.broadcaster_text_embedding = tf.keras.Sequential([\n",
    "\t\t\tself.broadcaster_vectorizer,\n",
    "\t\t\ttf.keras.layers.Embedding(max_tokens, 32, mask_zero = True),\n",
    "\t\t\ttf.keras.layers.GlobalAveragePooling1D(),\n",
    "\t\t])\n",
    "\n",
    "\t\tself.broadcaster_vectorizer.adapt(broadcasters)\n",
    "\n",
    "\tdef call(self, broadcaster) :\n",
    "\t\treturn tf.concat([\n",
    "\t\t\tself.broadcaster_embedding(broadcaster),\n",
    "\t\t\tself.broadcaster_text_embedding(broadcaster),\n",
    "\t\t], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4f169",
   "metadata": {},
   "source": [
    "### Combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "199874ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalModel(tfrs.models.Model) :\n",
    "\n",
    "\tdef __init__(self, has_viewer_age) :\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.query_model = tf.keras.Sequential([\n",
    "\t\t\tUserModel(has_viewer_age),\n",
    "\t\t\ttf.keras.layers.Dense(32)\n",
    "\t\t])\n",
    "        \n",
    "\t\tself.candidate_model = tf.keras.Sequential([\n",
    "\t\t\tBroadcasterModel(),\n",
    "\t\t\ttf.keras.layers.Dense(32)\n",
    "\t\t])\n",
    "        \n",
    "\t\tself.task = tfrs.tasks.Retrieval(\n",
    "\t\t\tmetrics = tfrs.metrics.FactorizedTopK(\n",
    "\t\t\t\tcandidates = broadcasters.batch(128).map(self.candidate_model),\n",
    "\t\t\t),\n",
    "\t\t)\n",
    "\n",
    "\tdef compute_loss(self, features, training = False) :\n",
    "\t\t# We only pass the user id and timestamp features into the query model. This\n",
    "\t\t# is to ensure that the training inputs would have the same keys as the\n",
    "\t\t# query inputs. Otherwise the discrepancy in input structure would cause an\n",
    "\t\t# error when loading the query model after saving it.\n",
    "\t\tquery_embeddings = self.query_model({\n",
    "\t\t\t\"viewer\" :features[\"viewer\"],\n",
    "\t\t\t\"viewer_age\" :features[\"viewer_age\"],\n",
    "\t\t})\n",
    "\t\tbroadcaster_embeddings = self.candidate_model(features[\"broadcaster\"])\n",
    "\n",
    "\t\treturn self.task(query_embeddings, broadcaster_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff839c6e",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e25bf",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ac21520",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dc1693",
   "metadata": {},
   "source": [
    "### Baseline: no timestamp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba346164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fb4c90ca290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fb4c90ca290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method BroadcasterModel.call of <__main__.BroadcasterModel object at 0x7fb4ac02c450>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method BroadcasterModel.call of <__main__.BroadcasterModel object at 0x7fb4ac02c450>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fb4a85b8290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fb4a85b8290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'viewer': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'viewer_age': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fb5512d4680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fb5512d4680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fb4a85cf170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fb4a85cf170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fb5512d43b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fb5512d43b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'viewer': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'viewer_age': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fb502f9ab00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fb502f9ab00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fb502f66a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fb502f66a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fb502f9aa70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fb502f9aa70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "40/40 [==============================] - 891s 22s/step - factorized_top_k/top_1_categorical_accuracy: 0.0489 - factorized_top_k/top_5_categorical_accuracy: 0.0495 - factorized_top_k/top_10_categorical_accuracy: 0.0498 - factorized_top_k/top_50_categorical_accuracy: 0.0514 - factorized_top_k/top_100_categorical_accuracy: 0.0530 - loss: 14877.8932 - regularization_loss: 0.0000e+00 - total_loss: 14877.8932\n",
      "Epoch 2/3\n",
      "40/40 [==============================] - 926s 23s/step - factorized_top_k/top_1_categorical_accuracy: 0.0154 - factorized_top_k/top_5_categorical_accuracy: 0.0155 - factorized_top_k/top_10_categorical_accuracy: 0.0155 - factorized_top_k/top_50_categorical_accuracy: 0.0174 - factorized_top_k/top_100_categorical_accuracy: 0.0196 - loss: 14015.7877 - regularization_loss: 0.0000e+00 - total_loss: 14015.7877\n",
      "Epoch 3/3\n",
      "40/40 [==============================] - 949s 24s/step - factorized_top_k/top_1_categorical_accuracy: 0.0293 - factorized_top_k/top_5_categorical_accuracy: 0.0300 - factorized_top_k/top_10_categorical_accuracy: 0.0322 - factorized_top_k/top_50_categorical_accuracy: 0.0505 - factorized_top_k/top_100_categorical_accuracy: 0.0694 - loss: 10497.9829 - regularization_loss: 0.0000e+00 - total_loss: 10497.9829\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fb530f1eef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fb530f1eef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'viewer': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'viewer_age': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fb4d2a648c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fb4d2a648c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fb502ff5cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fb502ff5cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fb4d2a64950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fb4d2a64950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "40/40 [==============================] - 953s 24s/step - factorized_top_k/top_1_categorical_accuracy: 0.1389 - factorized_top_k/top_5_categorical_accuracy: 0.1585 - factorized_top_k/top_10_categorical_accuracy: 0.1778 - factorized_top_k/top_50_categorical_accuracy: 0.2941 - factorized_top_k/top_100_categorical_accuracy: 0.3748 - loss: 5744.7773 - regularization_loss: 0.0000e+00 - total_loss: 5744.7773\n",
      "5/5 [==============================] - 225s 45s/step - factorized_top_k/top_1_categorical_accuracy: 2.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 3.0000e-04 - factorized_top_k/top_10_categorical_accuracy: 3.0000e-04 - factorized_top_k/top_50_categorical_accuracy: 5.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 9.0000e-04 - loss: 37743.0762 - regularization_loss: 0.0000e+00 - total_loss: 37743.0762\n",
      "Top-100 accuracy (train): 0.37.\n",
      "Top-100 accuracy (test): 0.00.\n"
     ]
    }
   ],
   "source": [
    "model = FinalModel(has_viewer_age=False)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, epochs=3)\n",
    "\n",
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "\n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f436a",
   "metadata": {},
   "source": [
    "### Capturing time dynamics with time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1638c831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fb4b4a22830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fb4b4a22830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fb440023200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fb440023200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fb4d0767d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fb4d0767d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'viewer': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'viewer_age': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method UserModel.call of <__main__.UserModel object at 0x7fb4a9443950>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method UserModel.call of <__main__.UserModel object at 0x7fb4a9443950>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fb530fd5050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fb530fd5050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fb4c843a950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fb4c843a950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fb530fbfd40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fb530fbfd40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'viewer': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'viewer_age': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fb54113c170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fb54113c170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fb551255dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fb551255dd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fb54113c4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fb54113c4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "40/40 [==============================] - 866s 22s/step - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0015 - factorized_top_k/top_10_categorical_accuracy: 0.0015 - factorized_top_k/top_50_categorical_accuracy: 0.0016 - factorized_top_k/top_100_categorical_accuracy: 0.0019 - loss: 14878.9730 - regularization_loss: 0.0000e+00 - total_loss: 14878.9730\n",
      "Epoch 2/3\n",
      "40/40 [==============================] - 927s 23s/step - factorized_top_k/top_1_categorical_accuracy: 0.0036 - factorized_top_k/top_5_categorical_accuracy: 0.0037 - factorized_top_k/top_10_categorical_accuracy: 0.0039 - factorized_top_k/top_50_categorical_accuracy: 0.0055 - factorized_top_k/top_100_categorical_accuracy: 0.0074 - loss: 13924.1824 - regularization_loss: 0.0000e+00 - total_loss: 13924.1824\n",
      "Epoch 3/3\n",
      "40/40 [==============================] - 938s 23s/step - factorized_top_k/top_1_categorical_accuracy: 0.0194 - factorized_top_k/top_5_categorical_accuracy: 0.0204 - factorized_top_k/top_10_categorical_accuracy: 0.0221 - factorized_top_k/top_50_categorical_accuracy: 0.0349 - factorized_top_k/top_100_categorical_accuracy: 0.0474 - loss: 10852.3661 - regularization_loss: 0.0000e+00 - total_loss: 10852.3661\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fb4d0767cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fb4d0767cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'viewer': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'viewer_age': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fb4a8541c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fb4a8541c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fb4c80d83b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fb4c80d83b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fb4a8541ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fb4a8541ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "40/40 [==============================] - 913s 23s/step - factorized_top_k/top_1_categorical_accuracy: 0.0899 - factorized_top_k/top_5_categorical_accuracy: 0.1038 - factorized_top_k/top_10_categorical_accuracy: 0.1148 - factorized_top_k/top_50_categorical_accuracy: 0.1954 - factorized_top_k/top_100_categorical_accuracy: 0.2598 - loss: 7039.4840 - regularization_loss: 0.0000e+00 - total_loss: 7039.4840\n",
      "5/5 [==============================] - 211s 42s/step - factorized_top_k/top_1_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_10_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_50_categorical_accuracy: 3.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 4.5000e-04 - loss: 37375.9310 - regularization_loss: 0.0000e+00 - total_loss: 37375.9310\n",
      "Top-100 accuracy (train): 0.26.\n",
      "Top-100 accuracy (test): 0.00.\n"
     ]
    }
   ],
   "source": [
    "model = FinalModel(has_viewer_age=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, epochs=3)\n",
    "\n",
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "\n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2e2ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
