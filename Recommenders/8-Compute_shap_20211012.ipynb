{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a09534",
   "metadata": {},
   "source": [
    "### Read-in downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e0f6071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9da8f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_broadcaster_data_set(train_ds):\n",
    "    broadcasters = train_ds.cache().map(lambda x: x[\"broadcaster\"], num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "    broadcasters_ds = tf.data.Dataset.from_tensor_slices(\n",
    "        np.unique(list(broadcasters.as_numpy_iterator())))\n",
    "    return broadcasters_ds\n",
    "\n",
    "\n",
    "def get_list(training_data, key):\n",
    "    return training_data.batch(1_000_000).map(lambda x: x[key], num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "\n",
    "\n",
    "def get_unique_list(data):\n",
    "    return np.unique(np.concatenate(list(data)))\n",
    "\n",
    "\n",
    "def load_data_file_cold(file, stats):\n",
    "    print('loading file:' + file)\n",
    "    training_df = pd.read_csv(\n",
    "        file,\n",
    "        skiprows=[0],\n",
    "        names=[\"viewer\",\n",
    "               \"broadcaster\",\n",
    "               \"viewer_age\",\n",
    "               \"viewer_gender\",\n",
    "               \"viewer_longitude\",\n",
    "               \"viewer_latitude\",\n",
    "               \"viewer_lang\",\n",
    "               \"viewer_country\",\n",
    "               \"broadcaster_age\",\n",
    "               \"broadcaster_gender\",\n",
    "               \"broadcaster_longitude\",\n",
    "               \"broadcaster_latitude\",\n",
    "               \"broadcaster_lang\",\n",
    "               \"broadcaster_country\",\n",
    "               \"duration\", \n",
    "               \"viewer_network\", \n",
    "               \"broadcaster_network\", \n",
    "               \"viewer_lat_long_cluster\",\n",
    "               \"rank\"], \n",
    "        dtype={\n",
    "            'viewer': np.unicode,\n",
    "            'broadcaster': np.unicode,\n",
    "            'viewer_age': np.single,\n",
    "            'viewer_gender': np.unicode,\n",
    "            'viewer_longitude': np.single,\n",
    "            'viewer_latitude': np.single,\n",
    "            'viewer_lang': np.unicode,\n",
    "            'viewer_country': np.unicode,\n",
    "            'broadcaster_age': np.single,\n",
    "            'broadcaster_longitude': np.single,\n",
    "            'broadcaster_latitude': np.single,\n",
    "            'broadcaster_lang': np.unicode,\n",
    "            'broadcaster_country': np.unicode,\n",
    "            'viewer_network': np.unicode,\n",
    "            'broadcaster_network': np.unicode,\n",
    "            'viewer_lat_long_cluster': np.unicode,\n",
    "            'rank': np.int\n",
    "        })\n",
    "\n",
    "    values = {\n",
    "        'viewer': 'unknown',\n",
    "        'broadcaster': 'unknown',\n",
    "        'viewer_age': 30,\n",
    "        'viewer_gender': 'unknown',\n",
    "        'viewer_longitude': 0,\n",
    "        'viewer_latitude': 0,\n",
    "        'viewer_lang': 'unknown',\n",
    "        'viewer_country': 'unknown',\n",
    "        'broadcaster_age': 30,\n",
    "        'broadcaster_longitude': 0,\n",
    "        'broadcaster_latitude': 0,\n",
    "        'broadcaster_lang': 'unknown',\n",
    "        'broadcaster_country': 'unknown',\n",
    "        'duration': 0,\n",
    "        'viewer_network': 'unknown',\n",
    "        'broadcaster_network': 'unknown',\n",
    "        'viewer_lat_long_cluster': '0',\n",
    "        'rank': 1\n",
    "    }\n",
    "    training_df.fillna(value=values, inplace=True)\n",
    "    print(training_df.head(10))\n",
    "    print(training_df.iloc[-10:])\n",
    "    # stats.send_stats('data-size', len(training_df.index))\n",
    "    samples = training_df.sample(frac=.1)\n",
    "    return samples\n",
    "\n",
    "\n",
    "def load_training_data_cold(file, stats):\n",
    "    ratings_df = load_data_file_cold(file, stats)\n",
    "    print('creating data set')\n",
    "    training_ds = (\n",
    "        tf.data.Dataset.from_tensor_slices(\n",
    "            ({\n",
    "                \"viewer\": tf.cast(\n",
    "                    ratings_df['viewer'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_gender\": tf.cast(\n",
    "                    ratings_df['viewer_gender'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_lang\": tf.cast(\n",
    "                    ratings_df['viewer_lang'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_country\": tf.cast(\n",
    "                    ratings_df['viewer_country'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_age\": tf.cast(\n",
    "                    ratings_df['viewer_age'].values,\n",
    "                    tf.int32),\n",
    "                \"viewer_longitude\": tf.cast(\n",
    "                    ratings_df['viewer_longitude'].values,\n",
    "                    tf.float16),\n",
    "                \"viewer_latitude\": tf.cast(\n",
    "                    ratings_df['viewer_latitude'].values,\n",
    "                    tf.float16),\n",
    "                \"broadcaster\": tf.cast(\n",
    "                    ratings_df['broadcaster'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_network\": tf.cast(\n",
    "                    ratings_df['viewer_network'].values,\n",
    "                    tf.string),\n",
    "                \"broadcaster_network\": tf.cast(\n",
    "                    ratings_df['broadcaster_network'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_lat_long_cluster\": tf.cast(\n",
    "                    ratings_df['viewer_lat_long_cluster'].values,\n",
    "                    tf.string),\n",
    "            })))\n",
    "\n",
    "    return training_ds\n",
    "\n",
    "\n",
    "def prepare_training_data_cold(train_ds):\n",
    "    print('prepare_training_data')\n",
    "    training_ds = train_ds.cache().map(lambda x: {\n",
    "        \"broadcaster\": x[\"broadcaster\"],\n",
    "        \"viewer\": x[\"viewer\"],\n",
    "        \"viewer_gender\": x[\"viewer_gender\"],\n",
    "        \"viewer_lang\": x[\"viewer_lang\"],\n",
    "        \"viewer_country\": x[\"viewer_country\"],\n",
    "        \"viewer_age\": x[\"viewer_age\"],\n",
    "        \"viewer_longitude\": x[\"viewer_longitude\"],\n",
    "        \"viewer_latitude\": x[\"viewer_latitude\"],\n",
    "        \"viewer_network\": x[\"viewer_network\"],\n",
    "        \"broadcaster_network\": x[\"broadcaster_network\"],\n",
    "        \"viewer_lat_long_cluster\": x[\"viewer_lat_long_cluster\"],\n",
    "    }, num_parallel_calls=tf.data.AUTOTUNE,\n",
    "       deterministic=False)\n",
    "\n",
    "    print('done prepare_training_data')\n",
    "    return training_ds\n",
    "\n",
    "\n",
    "def current_milli_time():\n",
    "    return round(time.time() * 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9a175e",
   "metadata": {},
   "source": [
    "### Read-in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6164ebb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_process\n"
     ]
    }
   ],
   "source": [
    "print(\"training_process\")\n",
    "start_time = current_milli_time()\n",
    "broadcaster_embedding_dimension = 32\n",
    "viewer_embedding_dimension = 32\n",
    "\n",
    "batch_size = 1638\n",
    "learning_rate = 0.05\n",
    "epochs = 10\n",
    "top_k = 199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7270ff73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0e9cd673-8e06-4810-b370-8b9930ee312a.csv\r\n",
      "2021-09-22.csv\r\n",
      "2021-09-23.csv\r\n",
      "2021-10-01.csv\r\n",
      "2021-10-05.csv\r\n",
      "2021-10-07.csv\r\n",
      "50c39121-3de2-4b6b-b134-bb51732c1d6f.csv\r\n",
      "a3d86f3b-eb45-4641-b05d-30dff7423e6b.csv\r\n",
      "viewer_lat_long_centroids.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "897cda83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file:csv/2021-10-05.csv\n",
      "                                            viewer  \\\n",
      "0  37 5e 49 40 70 ff b1 a1 51 e1 f0 d6 77 15 d2 32   \n",
      "1  dd 83 c6 59 b2 3c e3 3c a1 49 47 1c ef 5f 1d 53   \n",
      "2  d5 e3 54 3c be 21 ee 42 c5 db 19 60 3e 9e b7 72   \n",
      "3  dd 83 c6 59 b2 3c e3 3c a1 49 47 1c ef 5f 1d 53   \n",
      "4  08 c7 b8 62 05 d4 b9 80 5b 96 a2 93 0e 48 88 6b   \n",
      "5  dd 83 c6 59 b2 3c e3 3c a1 49 47 1c ef 5f 1d 53   \n",
      "6  37 5e 49 40 70 ff b1 a1 51 e1 f0 d6 77 15 d2 32   \n",
      "7  dd 83 c6 59 b2 3c e3 3c a1 49 47 1c ef 5f 1d 53   \n",
      "8  37 5e 49 40 70 ff b1 a1 51 e1 f0 d6 77 15 d2 32   \n",
      "9  dd 83 c6 59 b2 3c e3 3c a1 49 47 1c ef 5f 1d 53   \n",
      "\n",
      "                                       broadcaster  viewer_age viewer_gender  \\\n",
      "0  34 9a c3 50 0e cf a4 a8 b7 d0 a4 a1 b9 d1 bd f2        43.0        female   \n",
      "1  b6 cb 91 77 b1 7f 4e 70 be 4d bb 5e 88 3f c2 dd        50.0          male   \n",
      "2  7f 8c 21 c9 e4 6f a2 fe 01 fa 97 4f 5b 2a 82 3d        22.0        female   \n",
      "3  73 83 97 f7 28 69 1c 25 4a ca d4 f6 24 9a a6 32        50.0          male   \n",
      "4  21 df 41 b0 62 1c da 73 e4 a7 da 6e 97 f4 6d d4        56.0          male   \n",
      "5  d1 bc 15 78 09 c7 18 67 41 0f b7 8f 3c 56 7e a6        50.0          male   \n",
      "6  61 cf a9 39 0a 71 44 96 f2 82 75 57 ae 1a 67 91        43.0        female   \n",
      "7  b7 8a 75 bd 74 96 a1 3c de 2f a9 76 31 6d 17 f4        50.0          male   \n",
      "8  03 ae 58 c7 be 90 17 a2 21 1e f8 f5 4a 5e ad 8d        43.0        female   \n",
      "9  47 cd 3e cc 1b 58 20 de d8 7d ab 3e f4 ba 15 ae        50.0          male   \n",
      "\n",
      "   viewer_longitude  viewer_latitude viewer_lang viewer_country  \\\n",
      "0        -97.619301          39.8424          en             US   \n",
      "1        -96.619301          39.8424          en             US   \n",
      "2        -97.619301          38.8424          en             US   \n",
      "3        -96.619301          38.8424          en             US   \n",
      "4        -97.619301          38.8424          en             US   \n",
      "5        -96.619301          39.8424          en             US   \n",
      "6        -96.619301          38.8424          en             US   \n",
      "7        -96.619301          39.8424          en             US   \n",
      "8        -97.619301          39.8424          en             US   \n",
      "9        -96.619301          39.8424          en             US   \n",
      "\n",
      "   broadcaster_age broadcaster_gender  broadcaster_longitude  \\\n",
      "0             44.0               male             -94.456299   \n",
      "1             21.0             female             -87.638100   \n",
      "2             30.0               male            -117.112198   \n",
      "3             28.0             female             -86.816498   \n",
      "4             35.0             female             -78.300003   \n",
      "5             33.0             female            -122.724098   \n",
      "6             25.0             female             -80.588997   \n",
      "7             26.0             female             -91.366997   \n",
      "8             29.0               male             -97.076401   \n",
      "9             24.0             female            -105.668503   \n",
      "\n",
      "   broadcaster_latitude broadcaster_lang broadcaster_country  duration  \\\n",
      "0             40.564800               en                  US       206   \n",
      "1             39.712101               en                  US       110   \n",
      "2             33.583801               en                  US      4674   \n",
      "3             42.963699               en                  US       101   \n",
      "4             45.299999               en                  CA       161   \n",
      "5             46.410801               en                  US        65   \n",
      "6             28.830999               en                  US       739   \n",
      "7             39.528999               en                  US        55   \n",
      "8             37.108002               en                  US        68   \n",
      "9             36.238499               en                  US       188   \n",
      "\n",
      "  viewer_network broadcaster_network viewer_lat_long_cluster  rank  \n",
      "0         meetme              meetme                       0     1  \n",
      "1         meetme              meetme                       0     1  \n",
      "2         meetme              meetme                       0     1  \n",
      "3         meetme              meetme                       0     1  \n",
      "4         meetme                 pof                       0     1  \n",
      "5         meetme              meetme                       0     1  \n",
      "6         meetme               skout                       0     1  \n",
      "7         meetme               skout                       0     1  \n",
      "8         meetme              meetme                       0     1  \n",
      "9         meetme              meetme                       0     1  \n",
      "                                                  viewer  \\\n",
      "5207247  8e ce 9f 19 06 cb 13 99 88 30 15 2e 1a ac 79 67   \n",
      "5207248  70 c1 40 ae 90 89 e2 f5 96 60 23 7f 51 b0 e3 84   \n",
      "5207249  cf 1d 68 cc 40 3f 4a c8 10 f9 85 4e d1 01 a0 d0   \n",
      "5207250  40 b4 28 b6 c6 31 b9 fb c7 a6 0e 59 1a 76 46 fc   \n",
      "5207251  88 f9 61 93 86 ef 2e c5 94 3b 07 16 6e cd aa 12   \n",
      "5207252  29 aa 76 80 81 25 e4 9a e8 d5 f2 7e 92 5c fa 4e   \n",
      "5207253  cb d1 c2 10 a9 5e 5d f2 56 b8 a4 af ef 62 38 83   \n",
      "5207254  a3 4b 04 7c 26 77 ec fd 1b 4f c5 e3 29 d1 db 4f   \n",
      "5207255  f7 f1 1a 4f 68 b1 b8 8d 8a e5 33 90 61 04 b6 b7   \n",
      "5207256  ac 65 9a 22 60 e9 a0 fc 6e fe a4 89 7c af 7d f7   \n",
      "\n",
      "                                             broadcaster  viewer_age  \\\n",
      "5207247  2a 11 04 28 7a a1 3f a7 9b a0 6a 9e 1c 7e f3 b7        34.0   \n",
      "5207248  b7 03 e6 d8 de b9 51 b4 49 59 9f 94 63 69 22 d1        50.0   \n",
      "5207249  3b 1e 94 b0 21 84 a1 4c 9e e2 52 a1 61 78 28 82        35.0   \n",
      "5207250  a9 cd 4c a9 f9 ab 0e 53 1d 2b af 52 a3 e8 b5 a5        25.0   \n",
      "5207251  ad a7 e7 02 45 bb 48 c7 85 e3 8d d3 43 c7 74 1e        53.0   \n",
      "5207252  c5 13 62 6f 99 5c 15 d9 17 31 73 2b b3 bf b3 7e        40.0   \n",
      "5207253  ee 6c eb 9a f9 74 e4 1b 1f f7 7c 5c 3c 19 e1 23        25.0   \n",
      "5207254  29 21 61 09 01 74 53 78 59 82 e7 2a 17 dc 8f ec        19.0   \n",
      "5207255  73 e7 d5 d4 4e b7 e0 e7 cb 8e 36 6b a4 2d b8 87        44.0   \n",
      "5207256  e3 58 69 73 98 e2 ab ae 8e 1d 73 4c 7b d7 f5 49        42.0   \n",
      "\n",
      "        viewer_gender  viewer_longitude  viewer_latitude viewer_lang  \\\n",
      "5207247          male        107.782997        -6.365000          in   \n",
      "5207248          male        -70.128998        42.686001          es   \n",
      "5207249          male        -80.153000        32.984001          en   \n",
      "5207250          male        -73.001999        41.674000          en   \n",
      "5207251          male        -75.878998        41.991001          en   \n",
      "5207252          male        -73.958000         4.977000          en   \n",
      "5207253          male        -77.900002        36.200001          en   \n",
      "5207254        female        121.161003        15.545000          en   \n",
      "5207255          male         72.549004        34.903000          en   \n",
      "5207256          male        102.896004        15.936000          th   \n",
      "\n",
      "        viewer_country  broadcaster_age broadcaster_gender  \\\n",
      "5207247             ID             45.0             female   \n",
      "5207248             US             33.0               male   \n",
      "5207249             US             40.0             female   \n",
      "5207250             US             21.0             female   \n",
      "5207251             US             25.0             female   \n",
      "5207252             US             23.0               male   \n",
      "5207253             US             36.0             female   \n",
      "5207254             PH             27.0             female   \n",
      "5207255             US             27.0             female   \n",
      "5207256             TH             27.0             female   \n",
      "\n",
      "         broadcaster_longitude  broadcaster_latitude broadcaster_lang  \\\n",
      "5207247             107.830299             -6.154600               id   \n",
      "5207248             -71.699997             42.799999               en   \n",
      "5207249             -81.285400             32.874401               en   \n",
      "5207250             -72.858002             40.894001               es   \n",
      "5207251             -80.268898             26.721201               en   \n",
      "5207252             -73.343803              4.605800               es   \n",
      "5207253             -78.400002             36.599998               en   \n",
      "5207254             121.029602             15.606900               en   \n",
      "5207255             -73.989098             41.731602               en   \n",
      "5207256             100.720001             13.728000               th   \n",
      "\n",
      "        broadcaster_country  duration viewer_network broadcaster_network  \\\n",
      "5207247                  ID       128          skout              meetme   \n",
      "5207248                  US        64          skout                 pof   \n",
      "5207249                  US       652          skout              meetme   \n",
      "5207250                  US        53          skout               skout   \n",
      "5207251                  US       130          skout              meetme   \n",
      "5207252                  CO        73          skout              meetme   \n",
      "5207253                  US      4301            pof                 pof   \n",
      "5207254                  PH      1934          skout              meetme   \n",
      "5207255                  US       196          skout              meetme   \n",
      "5207256                  TH        75          skout               skout   \n",
      "\n",
      "        viewer_lat_long_cluster  rank  \n",
      "5207247                       6     1  \n",
      "5207248                       0     1  \n",
      "5207249                       0     1  \n",
      "5207250                       0     1  \n",
      "5207251                       0     1  \n",
      "5207252                       5     1  \n",
      "5207253                       0     1  \n",
      "5207254                       6     1  \n",
      "5207255                       1     1  \n",
      "5207256                       6     1  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating data set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-12 10:07:01.560177: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_training_data\n",
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_training_data_cold.<locals>.<lambda> at 0x7f972bebdc20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function prepare_training_data_cold.<locals>.<lambda> at 0x7f972bebdc20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "done prepare_training_data\n",
      "WARNING:tensorflow:AutoGraph could not transform <function get_broadcaster_data_set.<locals>.<lambda> at 0x7f972bebdef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function get_broadcaster_data_set.<locals>.<lambda> at 0x7f972bebdef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-12 10:07:02.093192: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "training_dataset = load_training_data_cold(\"csv/2021-10-05.csv\", \"\")\n",
    "train = prepare_training_data_cold(training_dataset)\n",
    "broadcasters_data_set = get_broadcaster_data_set(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0dd7fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get lists\n",
      "WARNING:tensorflow:AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f9728357d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f9728357d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f96f880d9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f96f880d9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f96f880d0e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f96f880d0e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f9691a71a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f9691a71a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f9691a719e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f9691a719e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f9691a3cb90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f9691a3cb90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f9691a3cdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f9691a3cdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f9691a3cef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f9691a3cef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "print(\"get lists\")\n",
    "\n",
    "user_genders = get_list(train, \"viewer_gender\")\n",
    "user_langs = get_list(train, \"viewer_lang\")\n",
    "user_countries = get_list(train, \"viewer_country\")\n",
    "user_networks = get_list(train, \"viewer_network\")\n",
    "\n",
    "viewer_age = get_list(train, \"viewer_age\")\n",
    "viewer_longitude = get_list(train, \"viewer_longitude\")\n",
    "viewer_latitude = get_list(train, \"viewer_latitude\")\n",
    "\n",
    "broadcaster_ids = get_list(train, \"broadcaster\")\n",
    "\n",
    "data_set_size = len(broadcaster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9366ee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_unique_list\n",
      "[b'00 00 0a 1a ff 0b cc 16 8b 23 11 ec 96 6c 1a 55'\n",
      " b'00 00 78 66 2d 75 57 6e 79 62 cf 33 51 c7 16 86'\n",
      " b'00 01 8e a9 29 29 a6 ee 3f 57 10 73 f2 8f 2e 9a' ...\n",
      " b'ff ff 88 08 7c 1e c7 d0 f7 2e d2 59 34 b2 ec 5f'\n",
      " b'ff ff ae 98 59 eb 0a 9b 9b 59 3c 3f 9f c7 1e 37'\n",
      " b'ff ff d7 35 f3 a8 66 fd 21 7a 78 07 1d 15 0c 78']\n"
     ]
    }
   ],
   "source": [
    "print(\"get_unique_list\")\n",
    "unique_broadcasters = get_unique_list(broadcaster_ids)\n",
    "unique_user_genders = get_unique_list(user_genders)\n",
    "unique_user_langs = get_unique_list(user_langs)\n",
    "unique_user_countries = get_unique_list(user_countries)\n",
    "unique_user_networks = get_unique_list(user_networks)\n",
    "print(unique_broadcasters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f696b422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique broadcasters: 67366\n"
     ]
    }
   ],
   "source": [
    " print(\"unique broadcasters: \" + str(len(unique_broadcasters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d21109b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model) :\n",
    "\n",
    "    def __init__(self, unique_genders, unique_langs, unique_countries, viewer_age, unique_networks) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.gender_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_genders, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_genders) + 1, 4),\n",
    "        ])\n",
    "\n",
    "        self.lang_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_langs, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_langs) + 1, 11),\n",
    "        ])\n",
    "\n",
    "        self.country_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_countries, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_countries) + 1, 11),\n",
    "        ])\n",
    "\n",
    "        self.network_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_networks, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_networks) + 1, 4),\n",
    "        ])\n",
    "\n",
    "        age_boundaries = np.array([18, 25, 30, 35, 40, 45, 50, 55, 60, 65, float(\"inf\")])\n",
    "        self.viewer_age_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.Discretization(age_boundaries.tolist()),\n",
    "            tf.keras.layers.Embedding(len(age_boundaries) + 2, 2)\n",
    "        ])            \n",
    "\n",
    "\n",
    "    def call(self, inputs) :\n",
    "        return tf.concat([\n",
    "            self.gender_embedding(inputs[\"viewer_gender\"]),\n",
    "            self.lang_embedding(inputs[\"viewer_lang\"]),\n",
    "            self.country_embedding(inputs[\"viewer_country\"]),\n",
    "            self.network_embedding(inputs[\"viewer_network\"]),\n",
    "            self.viewer_age_embedding(inputs[\"viewer_age\"]),\n",
    "        ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35ad0e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = UserModel(unique_user_genders, unique_user_langs, unique_user_countries, viewer_age, unique_user_networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b27d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BroadcasterModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, unique_broadcaster_titles, dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.broadcaster_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_broadcaster_titles, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_broadcaster_titles) + 1, dims)\n",
    "        ])\n",
    "\n",
    "    def call(self, broadcaster):\n",
    "        return tf.concat([\n",
    "            self.broadcaster_embedding(broadcaster),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff329ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcaster_model = BroadcasterModel(unique_broadcasters, broadcaster_embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54e797fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "class TwoTowers(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, broadcaster_model, user_model, task):\n",
    "        super().__init__()\n",
    "        self.broadcaster_model: tf.keras.Model = broadcaster_model\n",
    "        self.embedding_model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def train_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "\n",
    "        # Set up a gradient tape to record gradients.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Loss computation.\n",
    "\n",
    "            user_embeddings = self.embedding_model({\n",
    "                \"viewer_gender\": features[\"viewer_gender\"],\n",
    "                \"viewer_lang\": features[\"viewer_lang\"],\n",
    "                \"viewer_country\": features[\"viewer_country\"],\n",
    "                \"viewer_age\": features[\"viewer_age\"],\n",
    "                \"viewer_network\": features[\"viewer_network\"],\n",
    "                \"viewer_latitude\": features[\"viewer_latitude\"],\n",
    "                \"viewer_longitude\": features[\"viewer_longitude\"]\n",
    "            })\n",
    "            positive_broadcaster_embeddings = self.broadcaster_model(\n",
    "                features[\"broadcaster\"])\n",
    "            loss = self.task(user_embeddings, positive_broadcaster_embeddings)\n",
    "\n",
    "            # Handle regularization losses as well.\n",
    "            regularization_loss = sum(self.losses)\n",
    "\n",
    "            total_loss = loss + regularization_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.trainable_variables))\n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        metrics[\"loss\"] = loss\n",
    "        metrics[\"regularization_loss\"] = regularization_loss\n",
    "        metrics[\"total_loss\"] = total_loss\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "\n",
    "        # Loss computation.\n",
    "\n",
    "        user_embeddings = self.embedding_model({\n",
    "                \"viewer_gender\": features[\"viewer_gender\"],\n",
    "                \"viewer_lang\": features[\"viewer_lang\"],\n",
    "                \"viewer_country\": features[\"viewer_country\"],\n",
    "                \"viewer_age\": features[\"viewer_age\"],\n",
    "                \"viewer_network\": features[\"viewer_network\"],\n",
    "                \"viewer_latitude\": features[\"viewer_latitude\"],\n",
    "                \"viewer_longitude\": features[\"viewer_longitude\"]\n",
    "        })\n",
    "        positive_broadcaster_embeddings = self.broadcaster_model(\n",
    "            features[\"broadcaster\"])\n",
    "        loss = self.task(user_embeddings, positive_broadcaster_embeddings)\n",
    "\n",
    "        # Handle regularization losses as well.\n",
    "        regularization_loss = sum(self.losses)\n",
    "\n",
    "        total_loss = loss + regularization_loss\n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        metrics[\"loss\"] = loss\n",
    "        metrics[\"regularization_loss\"] = regularization_loss\n",
    "        metrics[\"total_loss\"] = total_loss\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d48a9ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method BroadcasterModel.call of <__main__.BroadcasterModel object at 0x7f9680e59fd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method BroadcasterModel.call of <__main__.BroadcasterModel object at 0x7f9680e59fd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=broadcasters_data_set.batch(128).map(broadcaster_model)\n",
    ")\n",
    "\n",
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "041e1687",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoTowers(broadcaster_model, user_model, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff79a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adagrad(\n",
    "        learning_rate=learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c37a40b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = train.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train_p80 = shuffled.take(80_000)\n",
    "test_p20 = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "cached_train = train_p80.shuffle(100_000).batch(2048)\n",
    "cached_test = test_p20.batch(2048).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b6a3cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9680e6cf80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9680e6cf80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method UserModel.call of <__main__.UserModel object at 0x7f968bf5dfd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method UserModel.call of <__main__.UserModel object at 0x7f968bf5dfd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:From /Users/lhuang/opt/miniconda3/envs/tensorflow3.7/lib/python3.7/site-packages/tensorflow/python/ops/parallel_for/pfor.py:2382: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n",
      "WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Retrieval.call of <tensorflow_recommenders.tasks.retrieval.Retrieval object at 0x7f9680e4f810>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Retrieval.call of <tensorflow_recommenders.tasks.retrieval.Retrieval object at 0x7f9680e4f810>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Streaming.call of <tensorflow_recommenders.layers.factorized_top_k.Streaming object at 0x7f9680e4f650>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Streaming.call of <tensorflow_recommenders.layers.factorized_top_k.Streaming object at 0x7f9680e4f650>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7f9681a50b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7f9681a50b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7f96813bd680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7f96813bd680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7f96813bd3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7f96813bd3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7f9681321e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7f9681321e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7f9681601c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7f9681601c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7f9681303d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7f9681303d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9705b62cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f9705b62cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7f9681321050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7f9681321050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7f96813a2ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7f96813a2ef0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7f9704b77200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7f9704b77200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# model.fit(train_ds, epochs=epochs)\n",
    "old_model_history = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=5,\n",
    "    epochs=10,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b22f3587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': [0.0002749999985098839,\n",
       "  0.0008500000112690032,\n",
       "  0.0011874999618157744,\n",
       "  0.0011874999618157744,\n",
       "  0.001550000044517219,\n",
       "  0.001537499949336052,\n",
       "  0.001637500012293458,\n",
       "  0.0017374999588355422,\n",
       "  0.002012500073760748,\n",
       "  0.0018875000532716513],\n",
       " 'factorized_top_k/top_5_categorical_accuracy': [0.004212500061839819,\n",
       "  0.006300000008195639,\n",
       "  0.006750000175088644,\n",
       "  0.0075125000439584255,\n",
       "  0.008112500421702862,\n",
       "  0.007825000211596489,\n",
       "  0.008487500250339508,\n",
       "  0.008825000375509262,\n",
       "  0.010324999690055847,\n",
       "  0.011274999938905239],\n",
       " 'factorized_top_k/top_10_categorical_accuracy': [0.007499999832361937,\n",
       "  0.01145000010728836,\n",
       "  0.012600000016391277,\n",
       "  0.01412499975413084,\n",
       "  0.014525000005960464,\n",
       "  0.013949999585747719,\n",
       "  0.014712500385940075,\n",
       "  0.01627499982714653,\n",
       "  0.01887499913573265,\n",
       "  0.020800000056624413],\n",
       " 'factorized_top_k/top_50_categorical_accuracy': [0.024512499570846558,\n",
       "  0.039774999022483826,\n",
       "  0.04508750140666962,\n",
       "  0.049949999898672104,\n",
       "  0.04503750056028366,\n",
       "  0.04558749869465828,\n",
       "  0.0515500009059906,\n",
       "  0.057750001549720764,\n",
       "  0.06437499821186066,\n",
       "  0.06960000097751617],\n",
       " 'factorized_top_k/top_100_categorical_accuracy': [0.03815000131726265,\n",
       "  0.06297499686479568,\n",
       "  0.07270000129938126,\n",
       "  0.07631249725818634,\n",
       "  0.0706624984741211,\n",
       "  0.07717499881982803,\n",
       "  0.08728750050067902,\n",
       "  0.09589999914169312,\n",
       "  0.1042499989271164,\n",
       "  0.11052499711513519],\n",
       " 'loss': [593.135986328125,\n",
       "  557.5894775390625,\n",
       "  507.9190368652344,\n",
       "  479.9144287109375,\n",
       "  481.69561767578125,\n",
       "  463.66204833984375,\n",
       "  435.1846923828125,\n",
       "  457.4112243652344,\n",
       "  463.7049560546875,\n",
       "  425.42388916015625],\n",
       " 'regularization_loss': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'total_loss': [593.135986328125,\n",
       "  557.5894775390625,\n",
       "  507.9190368652344,\n",
       "  479.9144287109375,\n",
       "  481.69561767578125,\n",
       "  463.66204833984375,\n",
       "  435.1846923828125,\n",
       "  457.4112243652344,\n",
       "  463.7049560546875,\n",
       "  425.42388916015625],\n",
       " 'val_factorized_top_k/top_1_categorical_accuracy': [0.00044999999227002263,\n",
       "  0.0001500000071246177],\n",
       " 'val_factorized_top_k/top_5_categorical_accuracy': [0.002400000113993883,\n",
       "  0.0013500000350177288],\n",
       " 'val_factorized_top_k/top_10_categorical_accuracy': [0.0044999998062849045,\n",
       "  0.0026000000070780516],\n",
       " 'val_factorized_top_k/top_50_categorical_accuracy': [0.015399999916553497,\n",
       "  0.009750000201165676],\n",
       " 'val_factorized_top_k/top_100_categorical_accuracy': [0.025049999356269836,\n",
       "  0.018549999222159386],\n",
       " 'val_loss': [11471.359375, 12177.435546875],\n",
       " 'val_regularization_loss': [0, 0],\n",
       " 'val_total_loss': [11471.359375, 12177.435546875]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_model_history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2154cae9",
   "metadata": {},
   "source": [
    "### New User Model with Viewer Lat and Log Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96f40b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model) :\n",
    "\n",
    "    def __init__(self, unique_genders, unique_langs, unique_countries, viewer_age, unique_networks, unique_clusters) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.gender_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_genders, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_genders) + 1, 4),\n",
    "        ])\n",
    "\n",
    "        self.lang_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_langs, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_langs) + 1, 10),\n",
    "        ])\n",
    "\n",
    "        self.country_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_countries, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_countries) + 1, 10),\n",
    "        ])\n",
    "\n",
    "        self.network_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_networks, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_networks) + 1, 4),\n",
    "        ])\n",
    "\n",
    "        age_boundaries = np.array([18, 25, 30, 35, 40, 45, 50, 55, 60, 65, float(\"inf\")])\n",
    "        self.viewer_age_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.Discretization(age_boundaries.tolist()),\n",
    "            tf.keras.layers.Embedding(len(age_boundaries), 2)\n",
    "        ])\n",
    "        \n",
    "        self.viewer_lat_long_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_clusters, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_clusters) + 1, 2),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, inputs) :\n",
    "        return tf.concat([\n",
    "            self.gender_embedding(inputs[\"viewer_gender\"]),\n",
    "            self.lang_embedding(inputs[\"viewer_lang\"]),\n",
    "            self.country_embedding(inputs[\"viewer_country\"]),\n",
    "            self.network_embedding(inputs[\"viewer_network\"]),\n",
    "            self.viewer_age_embedding(inputs[\"viewer_age\"]),\n",
    "            self.viewer_lat_long_embedding(inputs[\"viewer_lat_long_cluster\"]),\n",
    "        ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6aa73a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f9681d39c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function get_list.<locals>.<lambda> at 0x7f9681d39c20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "user_clusters = get_list(train, \"viewer_lat_long_cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc797ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'0' b'1' b'2' b'3' b'4' b'5' b'6' b'7']\n"
     ]
    }
   ],
   "source": [
    "unique_user_clusters = get_unique_list(user_clusters)\n",
    "print(unique_user_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b7539a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = UserModel(unique_user_genders, unique_user_langs, unique_user_countries, viewer_age, unique_user_networks, unique_user_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8031447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BroadcasterModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, unique_broadcaster_titles, dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.broadcaster_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_broadcaster_titles, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_broadcaster_titles) + 1, dims)\n",
    "        ])\n",
    "\n",
    "    def call(self, broadcaster):\n",
    "        return tf.concat([\n",
    "            self.broadcaster_embedding(broadcaster),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cfde525",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcaster_model = BroadcasterModel(\n",
    "    unique_broadcasters,\n",
    "    broadcaster_embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3efc850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method BroadcasterModel.call of <__main__.BroadcasterModel object at 0x7f9680d46290>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method BroadcasterModel.call of <__main__.BroadcasterModel object at 0x7f9680d46290>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=broadcasters_data_set.batch(128).map(broadcaster_model)\n",
    ")\n",
    "\n",
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbb7575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "class TwoTowers(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, broadcaster_model, user_model, task):\n",
    "        super().__init__()\n",
    "        self.broadcaster_model: tf.keras.Model = broadcaster_model\n",
    "        self.embedding_model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def train_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "\n",
    "        # Set up a gradient tape to record gradients.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Loss computation.\n",
    "\n",
    "            user_embeddings = self.embedding_model({\n",
    "                \"viewer_gender\": features[\"viewer_gender\"],\n",
    "                \"viewer_lang\": features[\"viewer_lang\"],\n",
    "                \"viewer_country\": features[\"viewer_country\"],\n",
    "                \"viewer_age\": features[\"viewer_age\"],\n",
    "                \"viewer_network\": features[\"viewer_network\"],\n",
    "                \"viewer_latitude\": features[\"viewer_latitude\"],\n",
    "                \"viewer_longitude\": features[\"viewer_longitude\"],\n",
    "                \"viewer_lat_long_cluster\": features[\"viewer_lat_long_cluster\"]\n",
    "            })\n",
    "            positive_broadcaster_embeddings = self.broadcaster_model(\n",
    "                features[\"broadcaster\"])\n",
    "            loss = self.task(user_embeddings, positive_broadcaster_embeddings)\n",
    "\n",
    "            # Handle regularization losses as well.\n",
    "            regularization_loss = sum(self.losses)\n",
    "\n",
    "            total_loss = loss + regularization_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.trainable_variables))\n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        metrics[\"loss\"] = loss\n",
    "        metrics[\"regularization_loss\"] = regularization_loss\n",
    "        metrics[\"total_loss\"] = total_loss\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "\n",
    "        # Loss computation.\n",
    "\n",
    "        user_embeddings = self.embedding_model({\n",
    "                \"viewer_gender\": features[\"viewer_gender\"],\n",
    "                \"viewer_lang\": features[\"viewer_lang\"],\n",
    "                \"viewer_country\": features[\"viewer_country\"],\n",
    "                \"viewer_age\": features[\"viewer_age\"],\n",
    "                \"viewer_network\": features[\"viewer_network\"],\n",
    "                \"viewer_latitude\": features[\"viewer_latitude\"],\n",
    "                \"viewer_longitude\": features[\"viewer_longitude\"],\n",
    "                \"viewer_lat_long_cluster\": features[\"viewer_lat_long_cluster\"]\n",
    "        })\n",
    "        positive_broadcaster_embeddings = self.broadcaster_model(\n",
    "            features[\"broadcaster\"])\n",
    "        loss = self.task(user_embeddings, positive_broadcaster_embeddings)\n",
    "\n",
    "        # Handle regularization losses as well.\n",
    "        regularization_loss = sum(self.losses)\n",
    "\n",
    "        total_loss = loss + regularization_loss\n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        metrics[\"loss\"] = loss\n",
    "        metrics[\"regularization_loss\"] = regularization_loss\n",
    "        metrics[\"total_loss\"] = total_loss\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c035f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoTowers(broadcaster_model, user_model, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b82faec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adagrad(\n",
    "        learning_rate=learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f76adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = train.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train_p80 = shuffled.take(80_000)\n",
    "test_p20 = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "cached_train = train_p80.shuffle(100_000).batch(2048)\n",
    "cached_test = test_p20.batch(2048).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1da870bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9680e53680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f9680e53680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method UserModel.call of <__main__.UserModel object at 0x7f9681d11050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method UserModel.call of <__main__.UserModel object at 0x7f9681d11050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n",
      "WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7f9680a09680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7f9680a09680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7f9681dd84d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7f9681dd84d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7f9681dd8200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7f9681dd8200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7f96800d55f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7f96800d55f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7f96816dc3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7f96816dc3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7f9681448170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7f9681448170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f97058d4290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f97058d4290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Using a while_loop for converting BoostedTreesBucketize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7f97058d3b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7f97058d3b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7f9681374b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7f9681374b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7f97058d4830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7f97058d4830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# model.fit(train_ds, epochs=epochs)\n",
    "new_model_history = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=5,\n",
    "    epochs=10,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebfb3d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': [0.00028750000637955964,\n",
       "  0.0012000000569969416,\n",
       "  0.001449999981559813,\n",
       "  0.0017000000225380063,\n",
       "  0.0022249999456107616,\n",
       "  0.0023125000298023224,\n",
       "  0.002199999988079071,\n",
       "  0.002400000113993883,\n",
       "  0.0024999999441206455,\n",
       "  0.002812500111758709],\n",
       " 'factorized_top_k/top_5_categorical_accuracy': [0.0043875002302229404,\n",
       "  0.008137499913573265,\n",
       "  0.009512499906122684,\n",
       "  0.010812499560415745,\n",
       "  0.011662499979138374,\n",
       "  0.011625000275671482,\n",
       "  0.01192499976605177,\n",
       "  0.01211250014603138,\n",
       "  0.014074999839067459,\n",
       "  0.015250000171363354],\n",
       " 'factorized_top_k/top_10_categorical_accuracy': [0.007862499915063381,\n",
       "  0.01472499966621399,\n",
       "  0.017224999144673347,\n",
       "  0.02046249993145466,\n",
       "  0.020237499848008156,\n",
       "  0.02019999921321869,\n",
       "  0.0215000007301569,\n",
       "  0.022762499749660492,\n",
       "  0.02513750083744526,\n",
       "  0.026525000110268593],\n",
       " 'factorized_top_k/top_50_categorical_accuracy': [0.02693749964237213,\n",
       "  0.049424998462200165,\n",
       "  0.06116250157356262,\n",
       "  0.06706249713897705,\n",
       "  0.06391250342130661,\n",
       "  0.06925000250339508,\n",
       "  0.07581250369548798,\n",
       "  0.07954999804496765,\n",
       "  0.08477500081062317,\n",
       "  0.08877500146627426],\n",
       " 'factorized_top_k/top_100_categorical_accuracy': [0.0419749990105629,\n",
       "  0.0791499987244606,\n",
       "  0.09751249849796295,\n",
       "  0.10346250236034393,\n",
       "  0.10352499783039093,\n",
       "  0.11458750069141388,\n",
       "  0.12373749911785126,\n",
       "  0.13173750042915344,\n",
       "  0.1370750069618225,\n",
       "  0.1443749964237213],\n",
       " 'loss': [588.045166015625,\n",
       "  545.378173828125,\n",
       "  487.6571044921875,\n",
       "  453.2718200683594,\n",
       "  440.2977294921875,\n",
       "  420.6926574707031,\n",
       "  404.1701354980469,\n",
       "  415.869384765625,\n",
       "  413.5608215332031,\n",
       "  375.83404541015625],\n",
       " 'regularization_loss': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'total_loss': [588.045166015625,\n",
       "  545.378173828125,\n",
       "  487.6571044921875,\n",
       "  453.2718200683594,\n",
       "  440.2977294921875,\n",
       "  420.6926574707031,\n",
       "  404.1701354980469,\n",
       "  415.869384765625,\n",
       "  413.5608215332031,\n",
       "  375.83404541015625],\n",
       " 'val_factorized_top_k/top_1_categorical_accuracy': [0.00044999999227002263,\n",
       "  9.999999747378752e-05],\n",
       " 'val_factorized_top_k/top_5_categorical_accuracy': [0.002749999985098839,\n",
       "  0.001500000013038516],\n",
       " 'val_factorized_top_k/top_10_categorical_accuracy': [0.005200000014156103,\n",
       "  0.002749999985098839],\n",
       " 'val_factorized_top_k/top_50_categorical_accuracy': [0.018300000578165054,\n",
       "  0.011850000359117985],\n",
       " 'val_factorized_top_k/top_100_categorical_accuracy': [0.031599998474121094,\n",
       "  0.023749999701976776],\n",
       " 'val_loss': [11274.6357421875, 12047.517578125],\n",
       " 'val_regularization_loss': [0, 0],\n",
       " 'val_total_loss': [11274.6357421875, 12047.517578125]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93a25d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c91a40dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_runs = len(new_model_history.history[\"factorized_top_k/top_100_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21fe3e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f970427b8d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = [(x + 1)* 5 for x in range(num_validation_runs)]\n",
    "\n",
    "plt.plot(epochs, old_model_history.history[\"factorized_top_k/top_100_categorical_accuracy\"], label=\"Existing Model\")\n",
    "plt.plot(epochs, new_model_history.history[\"factorized_top_k/top_100_categorical_accuracy\"], label=\"New Model with Viewer Lat/Long Clusters\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Top-100 accuracy\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91af95d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-100 accuracy: 0.1105.\n"
     ]
    }
   ],
   "source": [
    "accuracy = old_model_history.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "print(f\"Top-100 accuracy: {accuracy:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18697f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-100 accuracy: 0.1444.\n"
     ]
    }
   ],
   "source": [
    "accuracy = new_model_history.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "print(f\"Top-100 accuracy: {accuracy:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7027846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
