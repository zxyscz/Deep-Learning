{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T11:12:59.889579Z",
     "iopub.status.busy": "2021-08-14T11:12:59.888985Z",
     "iopub.status.idle": "2021-08-14T11:12:59.891460Z",
     "shell.execute_reply": "2021-08-14T11:12:59.891020Z"
    },
    "id": "uWqCArLO_kez"
   },
   "source": [
    "https://www.tensorflow.org/recommenders/examples/deep_recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrDVNe7Vdqhr"
   },
   "source": [
    "In [the featurization tutorial](featurization) we incorporated multiple features into our models, but the models consist of only an embedding layer. We can add more dense layers to our models to increase their expressive power.\n",
    "\n",
    "In general, deeper models are capable of learning more complex patterns than shallower models. For example, our [user model](featurization#user_model) incorporates user ids and timestamps to model user preferences at a point in time. A shallow model (say, a single embedding layer) may only be able to learn the simplest relationships between those features and movies: a given movie is most popular around the time of its release, and a given user generally prefers horror movies to comedies. To capture more complex relationships, such as user preferences evolving over time, we may need a deeper model with multiple stacked dense layers.\n",
    "\n",
    "Of course, complex models also have their disadvantages. The first is computational cost, as larger models require both more memory and more computation to fit and serve. The second is the requirement for more data: in general, more training data is needed to take advantage of deeper models. With more parameters, deep models might overfit or even simply memorize the training examples instead of learning a function that can generalize. Finally, training deeper models may be harder, and more care needs to be taken in choosing settings like regularization and learning rate.\n",
    "\n",
    "Finding a good architecture for a real-world recommender system is a complex art, requiring good intuition and careful [hyperparameter tuning](https://en.wikipedia.org/wiki/Hyperparameter_optimization). For example, factors such as the depth and width of the model, activation function, learning rate, and optimizer can radically change the performance of the model. Modelling choices are further complicated by the fact that good offline evaluation metrics may not correspond to good online performance, and that the choice of what to optimize for is often more critical than the choice of model itself.\n",
    "\n",
    "Nevertheless, effort put into building and fine-tuning larger models often pays off. In this tutorial, we will illustrate how to build deep retrieval models using TensorFlow Recommenders. We'll do this by building progressively more complex models to see how this affects model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7RYXwgbAcbU"
   },
   "source": [
    "## Preliminaries\n",
    "\n",
    "We first import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T11:13:02.980559Z",
     "iopub.status.busy": "2021-08-14T11:13:02.979894Z",
     "iopub.status.idle": "2021-08-14T11:13:05.639645Z",
     "shell.execute_reply": "2021-08-14T11:13:05.639128Z"
    },
    "id": "XbwMjnLP5nZ_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgKIjpQLAiax"
   },
   "source": [
    "In this tutorial we will use the models from [the featurization tutorial](featurization) to generate embeddings. Hence we will only be using the user id, timestamp, and movie title features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T11:13:05.645133Z",
     "iopub.status.busy": "2021-08-14T11:13:05.644503Z",
     "iopub.status.idle": "2021-08-14T11:13:07.206138Z",
     "shell.execute_reply": "2021-08-14T11:13:07.205653Z"
    },
    "id": "kc2REbOO52Fl"
   },
   "outputs": [],
   "source": [
    "def load_data_file_cold(file, stats):\n",
    "    print('loading file:' + file)\n",
    "    training_df = pd.read_csv(\n",
    "        file,\n",
    "        skiprows=[0],\n",
    "        names=[\"viewer\",\"broadcaster\",\"viewer_age\",\"viewer_gender\",\"viewer_longitude\",\"viewer_latitude\",\"viewer_lang\",\"viewer_country\",\"broadcaster_age\",\"broadcaster_gender\",\"broadcaster_longitude\",\"broadcaster_latitude\",\"broadcaster_lang\",\"broadcaster_country\",\"duration\", \"viewer_network\", \"broadcaster_network\", \"count\"], dtype={\n",
    "            'viewer': np.unicode,\n",
    "            'broadcaster': np.unicode,\n",
    "            'viewer_age': np.single,\n",
    "            'viewer_gender': np.unicode,\n",
    "            'viewer_longitude': np.single,\n",
    "            'viewer_latitude': np.single,\n",
    "            'viewer_lang': np.unicode,\n",
    "            'viewer_country': np.unicode,\n",
    "            'broadcaster_age': np.single,\n",
    "            'broadcaster_longitude': np.single,\n",
    "            'broadcaster_latitude': np.single,\n",
    "            'broadcaster_lang': np.unicode,\n",
    "            'broadcaster_country': np.unicode,\n",
    "            'viewer_network': np.unicode,\n",
    "            'broadcaster_network': np.unicode,\n",
    "            'count': np.int\n",
    "        })\n",
    "\n",
    "    values = {\n",
    "        'viewer': 'unknown',\n",
    "        'broadcaster': 'unknown',\n",
    "        'viewer_age': 30,\n",
    "        'viewer_gender': 'unknown',\n",
    "        'viewer_longitude': 0,\n",
    "        'viewer_latitude': 0,\n",
    "        'viewer_lang': 'unknown',\n",
    "        'viewer_country': 'unknown',\n",
    "        'broadcaster_age': 30,\n",
    "        'broadcaster_longitude': 0,\n",
    "        'broadcaster_latitude': 0,\n",
    "        'broadcaster_lang': 'unknown',\n",
    "        'broadcaster_country': 'unknown',\n",
    "        'duration': 0,\n",
    "        'viewer_network': 'unknown',\n",
    "        'broadcaster_network': 'unknown',\n",
    "        'count': 0\n",
    "    }\n",
    "    training_df.fillna(value=values, inplace=True)\n",
    "#     print(training_df.head(10))\n",
    "#     print(training_df.iloc[-10:])\n",
    "#     stats.send_stats('data-size', len(training_df.index))\n",
    "\n",
    "    sampled_df = training_df.sample(frac=0.1)\n",
    "    print(sampled_df.head(10))\n",
    "    print(sampled_df.iloc[-10:])\n",
    "    return sampled_df\n",
    "\n",
    "def load_training_data_cold(file, stats):\n",
    "    ratings_df = load_data_file_cold(file, stats)\n",
    "    print('creating data set')\n",
    "    training_ds = (\n",
    "        tf.data.Dataset.from_tensor_slices(\n",
    "            ({\n",
    "                \"viewer\": tf.cast(\n",
    "                    ratings_df['viewer'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_gender\": tf.cast(\n",
    "                    ratings_df['viewer_gender'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_lang\": tf.cast(\n",
    "                    ratings_df['viewer_lang'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_country\": tf.cast(\n",
    "                    ratings_df['viewer_country'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_age\": tf.cast(\n",
    "                    ratings_df['viewer_age'].values,\n",
    "                    tf.int32),\n",
    "                \"viewer_longitude\": tf.cast(\n",
    "                    ratings_df['viewer_longitude'].values,\n",
    "                    tf.float16),\n",
    "                \"viewer_latitude\": tf.cast(\n",
    "                    ratings_df['viewer_latitude'].values,\n",
    "                    tf.float16),\n",
    "                \"broadcaster\": tf.cast(\n",
    "                    ratings_df['broadcaster'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_network\": tf.cast(\n",
    "                    ratings_df['viewer_network'].values,\n",
    "                    tf.string),\n",
    "                \"broadcaster_network\": tf.cast(\n",
    "                    ratings_df['broadcaster_network'].values,\n",
    "                    tf.string),\n",
    "                \"duration\": tf.cast(\n",
    "                    ratings_df['duration'].values,\n",
    "                    tf.float16),\n",
    "                \"count\": tf.cast(\n",
    "                    ratings_df['count'].values,\n",
    "                    tf.int16),\n",
    "            })))\n",
    "\n",
    "    return training_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file:a3d86f3b-eb45-4641-b05d-30dff7423e6b.csv\n",
      "                   viewer       broadcaster  viewer_age viewer_gender  \\\n",
      "5071003   skout:156268438     pof:331132033        28.0          male   \n",
      "2049838     pof:267137322     pof:193323152        62.0          male   \n",
      "4417634   skout:175060864  meetme:313280942        22.0          male   \n",
      "4223325   skout:153601763   skout:145741502        41.0        female   \n",
      "4258428  meetme:143235327  meetme:317639867        37.0          male   \n",
      "478633      pof:315890709     pof:321142024        46.0        female   \n",
      "2049849  meetme:313870545  meetme:312653567        35.0          male   \n",
      "2196723  meetme:318175917  meetme:271805974        28.0          male   \n",
      "4817147   skout:164012548   skout:117430880        21.0        female   \n",
      "332009    skout:179332733   skout:173008999        25.0          male   \n",
      "\n",
      "         viewer_longitude  viewer_latitude viewer_lang viewer_country  \\\n",
      "5071003        150.843994       -34.067001          en             AU   \n",
      "2049838         -3.000000        53.799999          en             US   \n",
      "4417634        -98.209000        29.896999          en             US   \n",
      "4223325        126.732002        37.372002          ko             KR   \n",
      "4258428       -103.428001        25.543900          es             US   \n",
      "478633         -90.400002        34.700001          en             US   \n",
      "2049849        107.293602        -6.335500          id             ID   \n",
      "2196723          3.150000         6.450000          en             US   \n",
      "4817147        121.021004        14.572000          en             US   \n",
      "332009          28.851999        41.007000          tr             TR   \n",
      "\n",
      "         broadcaster_age broadcaster_gender  broadcaster_longitude  \\\n",
      "5071003             30.0             female             153.000000   \n",
      "2049838             38.0             female              -3.000000   \n",
      "4417634             27.0             female             -76.092102   \n",
      "4223325             52.0             female             126.785004   \n",
      "4258428             26.0             female             -68.666702   \n",
      "478633              35.0               male            -122.300003   \n",
      "2049849             35.0               male             106.700302   \n",
      "2196723             34.0             female            -121.492500   \n",
      "4817147             23.0             female             123.589996   \n",
      "332009              21.0             female              29.152000   \n",
      "\n",
      "         broadcaster_latitude broadcaster_lang broadcaster_country  duration  \\\n",
      "5071003            -27.500000               en                  AU      3775   \n",
      "2049838             53.299999               en                  GB        78   \n",
      "4417634             36.846001               en                  US       689   \n",
      "4223325             37.526001               ko                  KR        91   \n",
      "4258428             18.433300               es                  DO        49   \n",
      "478633              40.500000               en                  US       101   \n",
      "2049849             -6.124700               id                  ID       200   \n",
      "2196723             38.585400               en                  US        66   \n",
      "4817147              7.944000               en                  PH        64   \n",
      "332009              41.011002               tr                  TR       980   \n",
      "\n",
      "        viewer_network broadcaster_network  count  \n",
      "5071003          skout                 pof      1  \n",
      "2049838            pof                 pof      1  \n",
      "4417634          skout              meetme      1  \n",
      "4223325          skout               skout      1  \n",
      "4258428         meetme              meetme      2  \n",
      "478633             pof                 pof      1  \n",
      "2049849         meetme              meetme      1  \n",
      "2196723         meetme              meetme      1  \n",
      "4817147          skout               skout      1  \n",
      "332009           skout               skout      1  \n",
      "                                         viewer       broadcaster  viewer_age  \\\n",
      "4157349                           pof:328250087      pof:69646361        57.0   \n",
      "3250851                         skout:172582770     pof:299900929        29.0   \n",
      "4477326                           pof:328560789     pof:313962595        21.0   \n",
      "3375145  zoosk:a0727db83b7178bde237341ab6d1ddfc     pof:310585398        61.0   \n",
      "1423525                        meetme:314103125  meetme:314103125        28.0   \n",
      "1118314                         skout:184026665  meetme:104333970        36.0   \n",
      "3841260                        meetme:133252767  meetme:281601341        60.0   \n",
      "3019315                        meetme:308883350  meetme:309755358        27.0   \n",
      "2184062                        meetme:180102420  meetme:226819978        32.0   \n",
      "1176541                           pof:333332258     pof:328582109        60.0   \n",
      "\n",
      "        viewer_gender  viewer_longitude  viewer_latitude viewer_lang  \\\n",
      "4157349          male        -83.900002        34.099998          en   \n",
      "3250851          male        -79.777000        43.581001          en   \n",
      "4477326        female         -3.800000        56.000000          en   \n",
      "3375145          male       -122.239998        38.099998          en   \n",
      "1423525        female        -97.341499        37.689800          en   \n",
      "1118314        female        121.072998        14.526000          en   \n",
      "3841260          male          4.829100        45.759300          fr   \n",
      "3019315          male          1.247000        41.114498          es   \n",
      "2184062          male        -80.169701        41.640999          en   \n",
      "1176541          male        -81.300003        28.600000          en   \n",
      "\n",
      "        viewer_country  broadcaster_age broadcaster_gender  \\\n",
      "4157349             US             52.0             female   \n",
      "3250851             CA             27.0               male   \n",
      "4477326             US             32.0               male   \n",
      "3375145             US             38.0             female   \n",
      "1423525             US             28.0             female   \n",
      "1118314             US             26.0               male   \n",
      "3841260             FR             30.0             female   \n",
      "3019315             ES             20.0               male   \n",
      "2184062             US             23.0             female   \n",
      "1176541             US             26.0             female   \n",
      "\n",
      "         broadcaster_longitude  broadcaster_latitude broadcaster_lang  \\\n",
      "4157349             -84.400002             33.700001               en   \n",
      "3250851             -79.500000             43.700001               en   \n",
      "4477326              -3.900000             56.099998               en   \n",
      "3375145              -0.500000             51.900002               en   \n",
      "1423525             -97.341499             37.689800               en   \n",
      "1118314            -119.778503             34.006901               en   \n",
      "3841260             121.022301             14.609100               en   \n",
      "3019315             -70.408997             18.932199               es   \n",
      "2184062             -90.215599             29.996099               en   \n",
      "1176541             -79.800003             43.299999               en   \n",
      "\n",
      "        broadcaster_country  duration viewer_network broadcaster_network  \\\n",
      "4157349                  US       217            pof                 pof   \n",
      "3250851                  CA      2572          skout                 pof   \n",
      "4477326                  GB        72            pof                 pof   \n",
      "3375145                  GB       202          zoosk                 pof   \n",
      "1423525                  US      4039         meetme              meetme   \n",
      "1118314                  GB        89          skout              meetme   \n",
      "3841260                  PH        51         meetme              meetme   \n",
      "3019315                  DO        73         meetme              meetme   \n",
      "2184062                  US       138         meetme              meetme   \n",
      "1176541                  CA        68            pof                 pof   \n",
      "\n",
      "         count  \n",
      "4157349      2  \n",
      "3250851      6  \n",
      "4477326      2  \n",
      "3375145      1  \n",
      "1423525      1  \n",
      "1118314      1  \n",
      "3841260      3  \n",
      "3019315      2  \n",
      "2184062      2  \n",
      "1176541      1  \n",
      "creating data set\n",
      "{'broadcaster': b'pof:331132033',\n",
      " 'broadcaster_network': b'pof',\n",
      " 'count': 1,\n",
      " 'duration': 3776.0,\n",
      " 'viewer': b'skout:156268438',\n",
      " 'viewer_age': 28,\n",
      " 'viewer_country': b'AU',\n",
      " 'viewer_gender': b'male',\n",
      " 'viewer_lang': b'en',\n",
      " 'viewer_latitude': -34.06,\n",
      " 'viewer_longitude': 150.9,\n",
      " 'viewer_network': b'skout'}\n"
     ]
    }
   ],
   "source": [
    "ratings = load_training_data_cold(file=\"a3d86f3b-eb45-4641-b05d-30dff7423e6b.csv\", stats=\"\")\n",
    "\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fd56299cd40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fd56299cd40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "broadcasters = ratings.map(lambda x: x[\"broadcaster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'pof:331132033'\n",
      "b'pof:193323152'\n"
     ]
    }
   ],
   "source": [
    "for x in broadcasters.take(2).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YZ2q5RXYNI6"
   },
   "source": [
    "We also do some housekeeping to prepare feature vocabularies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fd56299c8c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fd56299c8c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fd56299cdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fd56299cdd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# Discretization\n",
    "max_viewer_age = ratings.map(lambda x: x[\"viewer_age\"]).reduce(\n",
    "    tf.cast(0, tf.int32), tf.maximum).numpy().max()\n",
    "min_viewer_age = ratings.map(lambda x: x[\"viewer_age\"]).reduce(\n",
    "    np.int32(100), tf.minimum).numpy().min()\n",
    "\n",
    "viewer_age_buckets = np.linspace(\n",
    "    min_viewer_age, max_viewer_age, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T11:13:07.212602Z",
     "iopub.status.busy": "2021-08-14T11:13:07.212043Z",
     "iopub.status.idle": "2021-08-14T11:13:11.211481Z",
     "shell.execute_reply": "2021-08-14T11:13:11.210956Z"
    },
    "id": "G5CVveCS9Doq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fd55c6fb290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fd55c6fb290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250293"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = ratings.batch(1_00_000).map(lambda x: x[\"viewer\"])\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "len(unique_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fd55c6fba70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fd55c6fba70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69669"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcaster_ids = ratings.batch(1_00_000).map(lambda x: x[\"broadcaster\"])\n",
    "unique_broadcaster_ids = np.unique(np.concatenate(list(broadcaster_ids)))\n",
    "len(unique_broadcaster_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFJcCVMUQou3"
   },
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtS6a4sgmI-c"
   },
   "source": [
    "### Query model\n",
    "\n",
    "We start with the user model defined in [the featurization tutorial](featurization) as the first layer of our model, tasked with converting raw input examples into feature embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fd56fb37cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fd56fb37cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "viewer_ages = np.concatenate(list(ratings.map(lambda x: x[\"viewer_age\"]).batch(1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T11:13:11.219142Z",
     "iopub.status.busy": "2021-08-14T11:13:11.214393Z",
     "iopub.status.idle": "2021-08-14T11:13:11.220882Z",
     "shell.execute_reply": "2021-08-14T11:13:11.221245Z"
    },
    "id": "_ItzYwMW42cb"
   },
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
    "        ])\n",
    "        self.viewer_age_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.Discretization(viewer_age_buckets.tolist()),\n",
    "            tf.keras.layers.Embedding(len(viewer_age_buckets) + 1, 32),\n",
    "        ])\n",
    "        self.normalized_viewer_age = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "            axis=None\n",
    "        )\n",
    "\n",
    "        self.normalized_viewer_age.adapt(viewer_ages)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Take the input dictionary, pass it through each input layer,\n",
    "        # and concatenate the result.\n",
    "        return tf.concat([\n",
    "            self.user_embedding(inputs[\"viewer\"]),\n",
    "            self.viewer_age_embedding(inputs[\"viewer_age\"]),\n",
    "            tf.reshape(self.normalized_viewer_age\n",
    "                       (inputs[\"viewer_age\"]), (-1, 1)),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fd5b34465f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fd5b34465f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fd55c6fb8c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fd55c6fb8c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Computed representations: [-0.03925911 -0.01930448  0.04127583]\n"
     ]
    }
   ],
   "source": [
    "user_model = UserModel()\n",
    "\n",
    "user_model.normalized_viewer_age.adapt(\n",
    "    ratings.map(lambda x: x[\"viewer_age\"]).batch(128))\n",
    "\n",
    "for row in ratings.batch(1).take(1):\n",
    "    print(f\"Computed representations: {user_model(row)[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMQzxLqh42on"
   },
   "source": [
    "Defining deeper models will require us to stack mode layers on top of this first input. A progressively narrower stack of layers, separated by an activation function, is a common pattern:\n",
    "\n",
    "```\n",
    "                            +----------------------+\n",
    "                            |      128 x 64        |\n",
    "                            +----------------------+\n",
    "                                       | relu\n",
    "                          +--------------------------+\n",
    "                          |        256 x 128         |\n",
    "                          +--------------------------+\n",
    "                                       | relu\n",
    "                        +------------------------------+\n",
    "                        |          ... x 256           |\n",
    "                        +------------------------------+\n",
    "```\n",
    "Since the expressive power of deep linear models is no greater than that of shallow linear models, we use ReLU activations for all but the last hidden layer. The final hidden layer does not use any activation function: using an activation function would limit the output space of the final embeddings and might negatively impact the performance of the model. For instance, if ReLUs are used in the projection layer, all components in the output embedding would be non-negative.\n",
    "\n",
    "We're going to try something similar here. To make experimentation with different depths easy, let's define a model whose depth (and width) is defined by a set of constructor parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T11:13:11.227987Z",
     "iopub.status.busy": "2021-08-14T11:13:11.227358Z",
     "iopub.status.idle": "2021-08-14T11:13:11.229637Z",
     "shell.execute_reply": "2021-08-14T11:13:11.229235Z"
    },
    "id": "5qfPi4I-Z0ph"
   },
   "outputs": [],
   "source": [
    "class QueryModel ( tf.keras.Model ):\n",
    "\t\"\"\"Model for encoding user queries.\"\"\"\n",
    "\n",
    "\tdef __init__ ( self , layer_sizes ):\n",
    "\t\t\"\"\"Model for encoding user queries.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t  layer_sizes:\n",
    "\t\t\tA list of integers where the i-th entry represents the number of units\n",
    "\t\t\tthe i-th layer contains.\n",
    "\t\t\"\"\"\n",
    "\t\tsuper ( ).__init__ ( )\n",
    "\n",
    "\t\t# We first use the user model for generating embeddings.\n",
    "\t\tself.embedding_model = UserModel ( )\n",
    "\n",
    "\t\t# Then construct the layers.\n",
    "\t\tself.dense_layers = tf.keras.Sequential ( )\n",
    "\n",
    "\t\t# Use the ReLU activation for all but the last layer.\n",
    "\t\tfor layer_size in layer_sizes [ :-1 ]:\n",
    "\t\t\tself.dense_layers.add ( tf.keras.layers.Dense ( layer_size , activation = \"relu\" ) )\n",
    "\n",
    "\t\t# No activation for the last layer.\n",
    "\t\tfor layer_size in layer_sizes [ -1: ]:\n",
    "\t\t\tself.dense_layers.add ( tf.keras.layers.Dense ( layer_size ) )\n",
    "\n",
    "\tdef call ( self , inputs ):\n",
    "\t\tfeature_embedding = self.embedding_model ( inputs )\n",
    "\t\treturn self.dense_layers ( feature_embedding )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9IqNTLmpJzs"
   },
   "source": [
    "The `layer_sizes` parameter gives us the depth and width of the model. We can vary it to experiment with shallower or deeper models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XleMceZNHC__"
   },
   "source": [
    "### Candidate model\n",
    "\n",
    "We can adopt the same approach for the movie model. Again, we start with the `MovieModel` from the [featurization](featurization) tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fd5894119e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fd5894119e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "broadcaster_ids = ratings.batch(100_000).map(lambda x: x[\"broadcaster\"])\n",
    "unique_broadcaster_ids = np.unique(np.concatenate(list(broadcaster_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_colons(text):\n",
    "    return tf.strings.split(text, sep=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T11:13:11.235958Z",
     "iopub.status.busy": "2021-08-14T11:13:11.235350Z",
     "iopub.status.idle": "2021-08-14T11:13:11.236990Z",
     "shell.execute_reply": "2021-08-14T11:13:11.237295Z"
    },
    "id": "oQZHX8bEHPOk"
   },
   "outputs": [],
   "source": [
    "class BroadcasterModel(tf.keras.Model):\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tmax_tokens = 10_000\n",
    "\n",
    "\t\tself.broadcaster_embedding = tf.keras.Sequential([\n",
    "\t\t\ttf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "\t\t\t\tvocabulary=unique_broadcaster_ids, mask_token=None),\n",
    "\t\t\ttf.keras.layers.Embedding(len(unique_broadcaster_ids) + 1, 32)\n",
    "\t\t])\n",
    "\n",
    "\t\tself.broadcaster_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "\t\t\tstandardize= None, split=split_on_colons, max_tokens = max_tokens)\n",
    "\n",
    "\t\tself.broadcaster_text_embedding = tf.keras.Sequential([\n",
    "\t\t\tself.broadcaster_vectorizer,\n",
    "\t\t\ttf.keras.layers.Embedding(max_tokens, 32, mask_zero = True),\n",
    "\t\t\ttf.keras.layers.GlobalAveragePooling1D(),\n",
    "\t\t])\n",
    "\n",
    "\t\tself.broadcaster_vectorizer.adapt(broadcasters)\n",
    "\n",
    "\tdef call(self, broadcaster) :\n",
    "\t\treturn tf.concat([\n",
    "\t\t\tself.broadcaster_embedding(broadcaster),\n",
    "\t\t\tself.broadcaster_text_embedding(broadcaster),\n",
    "\t\t], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6vssqPYp-gY"
   },
   "source": [
    "And expand it with hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T11:13:11.242812Z",
     "iopub.status.busy": "2021-08-14T11:13:11.242131Z",
     "iopub.status.idle": "2021-08-14T11:13:11.245094Z",
     "shell.execute_reply": "2021-08-14T11:13:11.244535Z"
    },
    "id": "l1gTXkvQqHGA"
   },
   "outputs": [],
   "source": [
    "class CandidateModel(tf.keras.Model):\n",
    "\t\"\"\"Model for encoding movies.\"\"\"\n",
    "\n",
    "\tdef __init__(self, layer_sizes):\n",
    "\t\t\"\"\"Model for encoding movies.\n",
    "\t\n",
    "\t\tArgs:\n",
    "\t\t  layer_sizes:\n",
    "\t\t\tA list of integers where the i-th entry represents the number of units\n",
    "\t\t\tthe i-th layer contains.\n",
    "\t\t\"\"\"\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.embedding_model = BroadcasterModel()\n",
    "\n",
    "\t\t# Then construct the layers.\n",
    "\t\tself.dense_layers = tf.keras.Sequential()\n",
    "\n",
    "\t\t# Use the ReLU activation for all but the last layer.\n",
    "\t\tfor layer_size in layer_sizes[:-1]:\n",
    "\t\t\tself.dense_layers.add(tf.keras.layers.Dense(layer_size, activation=\"relu\"))\n",
    "\n",
    "\t\t# No activation for the last layer.\n",
    "\t\tfor layer_size in layer_sizes[-1:]:\n",
    "\t\t\tself.dense_layers.add(tf.keras.layers.Dense(layer_size))\n",
    "\n",
    "\tdef call(self, inputs):\n",
    "\t\tfeature_embedding = self.embedding_model(inputs)\n",
    "\t\treturn self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cc4KbTNwHSvD"
   },
   "source": [
    "### Combined model\n",
    "\n",
    "With both `QueryModel` and `CandidateModel` defined, we can put together a combined model and implement our loss and metrics logic. To make things simple, we'll enforce that the model structure is the same across the query and candidate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T11:13:11.251189Z",
     "iopub.status.busy": "2021-08-14T11:13:11.250595Z",
     "iopub.status.idle": "2021-08-14T11:13:11.252789Z",
     "shell.execute_reply": "2021-08-14T11:13:11.252412Z"
    },
    "id": "26_hNJPKIh4-"
   },
   "outputs": [],
   "source": [
    "class FinalModel ( tfrs.models.Model ):\n",
    "\n",
    "\tdef __init__ ( self , layer_sizes ):\n",
    "\t\tsuper ( ).__init__ ( )\n",
    "\t\tself.query_model = QueryModel ( layer_sizes )\n",
    "\t\tself.candidate_model = CandidateModel ( layer_sizes )\n",
    "\t\tself.task = tfrs.tasks.Retrieval (\n",
    "\t\t\tmetrics = tfrs.metrics.FactorizedTopK (\n",
    "\t\t\t\tcandidates = broadcasters.batch ( 128 ).map ( self.candidate_model ) ,\n",
    "\t\t\t) ,\n",
    "\t\t)\n",
    "\n",
    "\tdef compute_loss ( self , features , training = False ):\n",
    "\t\t# We only pass the user id and timestamp features into the query model. This\n",
    "\t\t# is to ensure that the training inputs would have the same keys as the\n",
    "\t\t# query inputs. Otherwise the discrepancy in input structure would cause an\n",
    "\t\t# error when loading the query model after saving it.\n",
    "\t\tquery_embeddings = self.query_model ( {\n",
    "\t\t\t\"viewer\": features [ \"viewer\" ] ,\n",
    "\t\t\t\"viewer_age\": features [ \"viewer_age\" ] ,\n",
    "\t\t} )\n",
    "\t\tmovie_embeddings = self.candidate_model ( features [ \"broadcaster\" ] )\n",
    "\n",
    "\t\treturn self.task (\n",
    "\t\t\tquery_embeddings , movie_embeddings , compute_metrics = not training )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YXjsRsLTVzt"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QY7MTwMruoKh"
   },
   "source": [
    "### Prepare the data\n",
    "\n",
    "We first split the data into a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T11:13:11.257899Z",
     "iopub.status.busy": "2021-08-14T11:13:11.257307Z",
     "iopub.status.idle": "2021-08-14T11:13:11.263191Z",
     "shell.execute_reply": "2021-08-14T11:13:11.262737Z"
    },
    "id": "wMFUZ4dyTdYd"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2HEuTBzJ9w5"
   },
   "source": [
    "### Shallow model\n",
    "\n",
    "We're ready to try out our first, shallow, model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T11:13:11.268304Z",
     "iopub.status.busy": "2021-08-14T11:13:11.267713Z",
     "iopub.status.idle": "2021-08-14T11:24:58.236270Z",
     "shell.execute_reply": "2021-08-14T11:24:58.235774Z"
    },
    "id": "NkoLkiQdK4Um"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f925193a560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f925193a560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f92a630b4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f92a630b4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f925335a3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f925335a3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "40/40 [==============================] - 3s 35ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 14889.1923 - regularization_loss: 0.0000e+00 - total_loss: 14889.1923\n",
      "Epoch 2/3\n",
      "40/40 [==============================] - 3s 37ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 13891.1194 - regularization_loss: 0.0000e+00 - total_loss: 13891.1194\n",
      "Epoch 3/3\n",
      "40/40 [==============================] - 3s 35ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 9942.9238 - regularization_loss: 0.0000e+00 - total_loss: 9942.9238\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f92bbc95d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f92bbc95d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7f92e6981b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7f92e6981b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7f92530e5f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7f92530e5f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7f92530e5cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7f92530e5cb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "40/40 [==============================] - 922s 23s/step - factorized_top_k/top_1_categorical_accuracy: 0.1434 - factorized_top_k/top_5_categorical_accuracy: 0.1638 - factorized_top_k/top_10_categorical_accuracy: 0.1816 - factorized_top_k/top_50_categorical_accuracy: 0.3196 - factorized_top_k/top_100_categorical_accuracy: 0.4119 - loss: 5484.1483 - regularization_loss: 0.0000e+00 - total_loss: 5484.1483\n",
      "5/5 [==============================] - 201s 40s/step - factorized_top_k/top_1_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 1.5000e-04 - factorized_top_k/top_10_categorical_accuracy: 2.0000e-04 - factorized_top_k/top_50_categorical_accuracy: 6.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 8.0000e-04 - loss: 38849.2253 - regularization_loss: 0.0000e+00 - total_loss: 38849.2253\n",
      "Top-100 accuracy (train): 0.41.\n",
      "Top-100 accuracy (test): 0.00.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "model = FinalModel([32])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, epochs=3)\n",
    "\n",
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "\n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")\n",
    "\n",
    "\n",
    "# one_layer_history = model.fit(\n",
    "#     cached_train,\n",
    "#     validation_data=cached_test,\n",
    "#     validation_freq=5,\n",
    "#     epochs=num_epochs,\n",
    "#     verbose=0)\n",
    "\n",
    "# accuracy = one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "# print(f\"Top-100 accuracy: {accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p90vFk8LvJXp"
   },
   "source": [
    "This gives us a top-100 accuracy of around 0.27. We can use this as a reference point for evaluating deeper models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjJ1anzuLXgN"
   },
   "source": [
    "### Deeper model\n",
    "\n",
    "What about a deeper model with two layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T11:24:58.243309Z",
     "iopub.status.busy": "2021-08-14T11:24:58.242682Z",
     "iopub.status.idle": "2021-08-14T11:36:47.037515Z",
     "shell.execute_reply": "2021-08-14T11:36:47.037044Z"
    },
    "id": "11qAr5gGMUxE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fd589413830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fd589413830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fd54b4074d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fd54b4074d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method CandidateModel.call of <__main__.CandidateModel object at 0x7fd5abb57110>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method CandidateModel.call of <__main__.CandidateModel object at 0x7fd5abb57110>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method BroadcasterModel.call of <__main__.BroadcasterModel object at 0x7fd5b3198e10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method BroadcasterModel.call of <__main__.BroadcasterModel object at 0x7fd5b3198e10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd5b3446d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd5b3446d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method QueryModel.call of <__main__.QueryModel object at 0x7fd54b3e7550>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method QueryModel.call of <__main__.QueryModel object at 0x7fd54b3e7550>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method UserModel.call of <__main__.UserModel object at 0x7fd54b3cbd50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method UserModel.call of <__main__.UserModel object at 0x7fd54b3cbd50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Retrieval.call of <tensorflow_recommenders.tasks.retrieval.Retrieval object at 0x7fd54b3b7e90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Retrieval.call of <tensorflow_recommenders.tasks.retrieval.Retrieval object at 0x7fd54b3b7e90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "40/40 [==============================] - 3s 34ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 14936.3120 - regularization_loss: 0.0000e+00 - total_loss: 14936.3120\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 34ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 14446.7943 - regularization_loss: 0.0000e+00 - total_loss: 14446.7943\n",
      "Epoch 3/3\n",
      "40/40 [==============================] - 3s 34ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 13319.9614 - regularization_loss: 0.0000e+00 - total_loss: 13319.9614\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd57c02c5f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd57c02c5f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Streaming.call of <tensorflow_recommenders.layers.factorized_top_k.Streaming object at 0x7fd5b2caad10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Streaming.call of <tensorflow_recommenders.layers.factorized_top_k.Streaming object at 0x7fd5b2caad10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fd54b412830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fd54b412830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fd54b412950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fd54b412950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fd54b412680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fd54b412680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "40/40 [==============================] - 857s 22s/step - factorized_top_k/top_1_categorical_accuracy: 0.0020 - factorized_top_k/top_5_categorical_accuracy: 0.0023 - factorized_top_k/top_10_categorical_accuracy: 0.0028 - factorized_top_k/top_50_categorical_accuracy: 0.0069 - factorized_top_k/top_100_categorical_accuracy: 0.0120 - loss: 11646.5663 - regularization_loss: 0.0000e+00 - total_loss: 11646.5663\n",
      "5/5 [==============================] - 1466s 32s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 1.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 3.5000e-04 - loss: 35066.5163 - regularization_loss: 0.0000e+00 - total_loss: 35066.5163\n",
      "Top-100 accuracy (train): 0.01.\n",
      "Top-100 accuracy (test): 0.00.\n"
     ]
    }
   ],
   "source": [
    "model = FinalModel([64, 32])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, epochs=3)\n",
    "\n",
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "\n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")\n",
    "\n",
    "\n",
    "# two_layer_history = model.fit(\n",
    "#     cached_train,\n",
    "#     validation_data=cached_test,\n",
    "#     validation_freq=5,\n",
    "#     epochs=num_epochs,\n",
    "#     verbose=0)\n",
    "\n",
    "# accuracy = two_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "# print(f\"Top-100 accuracy: {accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHnzYfQrOj8I"
   },
   "source": [
    "The accuracy here is 0.29, quite a bit better than the shallow model.\n",
    "\n",
    "We can plot the validation accuracy curves to illustrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T11:36:47.056175Z",
     "iopub.status.busy": "2021-08-14T11:36:47.047659Z",
     "iopub.status.idle": "2021-08-14T11:36:47.284984Z",
     "shell.execute_reply": "2021-08-14T11:36:47.285367Z"
    },
    "id": "xzriiDRlHEvo"
   },
   "outputs": [],
   "source": [
    "# num_validation_runs = len(one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"])\n",
    "# epochs = [(x + 1)* 5 for x in range(num_validation_runs)]\n",
    "\n",
    "# plt.plot(epochs, one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"1 layer\")\n",
    "# plt.plot(epochs, two_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"2 layers\")\n",
    "# plt.title(\"Accuracy vs epoch\")\n",
    "# plt.xlabel(\"epoch\")\n",
    "# plt.ylabel(\"Top-100 accuracy\");\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ItwGCpXj9YF"
   },
   "source": [
    "Even early on in the training, the larger model has a clear and stable lead over the shallow model, suggesting that adding depth helps the model capture more nuanced relationships in the data.\n",
    "\n",
    "However, even deeper models are not necessarily better. The following model extends the depth to three layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T11:36:47.292771Z",
     "iopub.status.busy": "2021-08-14T11:36:47.292143Z",
     "iopub.status.idle": "2021-08-14T11:48:44.368987Z",
     "shell.execute_reply": "2021-08-14T11:48:44.369389Z"
    },
    "id": "es9k4o0ROt0l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fd54cd16830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fd54cd16830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fd5387e84d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fd5387e84d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd5388fb320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fd5388fb320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "40/40 [==============================] - 3s 35ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 16602.4394 - regularization_loss: 0.0000e+00 - total_loss: 16602.4394\n",
      "Epoch 2/3\n",
      "40/40 [==============================] - 3s 35ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 14672.8282 - regularization_loss: 0.0000e+00 - total_loss: 14672.8282\n",
      "Epoch 3/3\n",
      "40/40 [==============================] - 3s 36ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 13921.7193 - regularization_loss: 0.0000e+00 - total_loss: 13921.7193\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd538914f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fd538914f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fd53894c3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fd53894c3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fd57a6dab00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fd57a6dab00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fd57a6dab90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fd57a6dab90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "40/40 [==============================] - 1679s 43s/step - factorized_top_k/top_1_categorical_accuracy: 5.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 5.6250e-04 - factorized_top_k/top_10_categorical_accuracy: 6.6250e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0020 - factorized_top_k/top_100_categorical_accuracy: 0.0036 - loss: 12970.6776 - regularization_loss: 0.0000e+00 - total_loss: 12970.6776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 718s 171s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 1.5000e-04 - factorized_top_k/top_100_categorical_accuracy: 2.5000e-04 - loss: 33745.8945 - regularization_loss: 0.0000e+00 - total_loss: 33745.8945\n",
      "Top-100 accuracy (train): 0.00.\n",
      "Top-100 accuracy (test): 0.00.\n"
     ]
    }
   ],
   "source": [
    "model = FinalModel([128, 64, 32])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "model.fit(cached_train, epochs=3)\n",
    "\n",
    "train_accuracy = model.evaluate(\n",
    "    cached_train, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "test_accuracy = model.evaluate(\n",
    "    cached_test, return_dict=True)[\"factorized_top_k/top_100_categorical_accuracy\"]\n",
    "\n",
    "print(f\"Top-100 accuracy (train): {train_accuracy:.2f}.\")\n",
    "print(f\"Top-100 accuracy (test): {test_accuracy:.2f}.\")\n",
    "\n",
    "# three_layer_history = model.fit(\n",
    "#     cached_train,\n",
    "#     validation_data=cached_test,\n",
    "#     validation_freq=5,\n",
    "#     epochs=num_epochs,\n",
    "#     verbose=0)\n",
    "\n",
    "# accuracy = three_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]\n",
    "# print(f\"Top-100 accuracy: {accuracy:.2f}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLJV8jut40Ur"
   },
   "source": [
    "In fact, we don't see improvement over the shallow model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-14T11:48:44.387028Z",
     "iopub.status.busy": "2021-08-14T11:48:44.386335Z",
     "iopub.status.idle": "2021-08-14T11:48:44.549113Z",
     "shell.execute_reply": "2021-08-14T11:48:44.549484Z"
    },
    "id": "pIoVoMO1Kav6"
   },
   "outputs": [],
   "source": [
    "# plt.plot(epochs, one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"1 layer\")\n",
    "# plt.plot(epochs, two_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"2 layers\")\n",
    "# plt.plot(epochs, three_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"], label=\"3 layers\")\n",
    "# plt.title(\"Accuracy vs epoch\")\n",
    "# plt.xlabel(\"epoch\")\n",
    "# plt.ylabel(\"Top-100 accuracy\");\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wC95C1anA5Gx"
   },
   "source": [
    "This is a good illustration of the fact that deeper and larger models, while capable of superior performance, often require very careful tuning. For example, throughout this tutorial we used a single, fixed learning rate. Alternative choices may give very different results and are worth exploring. \n",
    "\n",
    "With appropriate tuning and sufficient data, the effort put into building larger and deeper models is in many cases well worth it: larger models can lead to substantial improvements in prediction accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dB09crfpgBx7"
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "In this tutorial we expanded our retrieval model with dense layers and activation functions. To see how to create a model that can perform not only retrieval tasks but also rating tasks, take a look at [the multitask tutorial](multitask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "deep_recommenders.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
