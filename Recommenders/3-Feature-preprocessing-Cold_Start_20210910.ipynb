{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c08264a",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/recommenders/examples/featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff71ba95",
   "metadata": {},
   "source": [
    "One of the great advantages of using a deep learning framework to build recommender models is the freedom to build rich, flexible feature representations.\n",
    "\n",
    "The first step in doing so is preparing the features, as raw features will usually not be immediately usable in a model.\n",
    "\n",
    "For example:\n",
    "\n",
    "- User and item ids may be strings (titles, usernames) or large, noncontiguous integers (database IDs).\n",
    "- Item descriptions could be raw text.\n",
    "- Interaction timestamps could be raw Unix timestamps.\n",
    "\n",
    "These need to be appropriately transformed in order to be useful in building models:\n",
    "\n",
    "- User and item ids have to be translated into embedding vectors: high-dimensional numerical representations that are adjusted during training to help the model predict its objective better.\n",
    "- Raw text needs to be tokenized (split into smaller parts such as individual words) and translated into embeddings.\n",
    "- Numerical features need to be normalized so that their values lie in a small interval around 0.\n",
    "\n",
    "Fortunately, by using TensorFlow we can make such preprocessing part of our model rather than a separate preprocessing step. This is not only convenient, but also ensures that our pre-processing is exactly the same during training and during serving. This makes it safe and easy to deploy models that include even very sophisticated pre-processing.\n",
    "\n",
    "In this tutorial, we are going to focus on recommenders and the preprocessing we need to do on the MovieLens dataset. If you're interested in a larger tutorial without a recommender system focus, have a look at the full Keras preprocessing guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51fef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pprint\n",
    "\n",
    "from typing import Dict, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62626833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06b3d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f076bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8510e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_file_cold(file, stats):\n",
    "    print('loading file:' + file)\n",
    "    training_df = pd.read_csv(\n",
    "        file,\n",
    "        skiprows=[0],\n",
    "        names=[\"viewer\",\"broadcaster\",\"viewer_age\",\"viewer_gender\",\"viewer_longitude\",\"viewer_latitude\",\"viewer_lang\",\"viewer_country\",\"broadcaster_age\",\"broadcaster_gender\",\"broadcaster_longitude\",\"broadcaster_latitude\",\"broadcaster_lang\",\"broadcaster_country\",\"duration\", \"viewer_network\", \"broadcaster_network\", \"count\"], dtype={\n",
    "            'viewer': np.unicode,\n",
    "            'broadcaster': np.unicode,\n",
    "            'viewer_age': np.single,\n",
    "            'viewer_gender': np.unicode,\n",
    "            'viewer_longitude': np.single,\n",
    "            'viewer_latitude': np.single,\n",
    "            'viewer_lang': np.unicode,\n",
    "            'viewer_country': np.unicode,\n",
    "            'broadcaster_age': np.single,\n",
    "            'broadcaster_longitude': np.single,\n",
    "            'broadcaster_latitude': np.single,\n",
    "            'broadcaster_lang': np.unicode,\n",
    "            'broadcaster_country': np.unicode,\n",
    "            'viewer_network': np.unicode,\n",
    "            'broadcaster_network': np.unicode,\n",
    "            'count': np.int\n",
    "        })\n",
    "\n",
    "    values = {\n",
    "        'viewer': 'unknown',\n",
    "        'broadcaster': 'unknown',\n",
    "        'viewer_age': 30,\n",
    "        'viewer_gender': 'unknown',\n",
    "        'viewer_longitude': 0,\n",
    "        'viewer_latitude': 0,\n",
    "        'viewer_lang': 'unknown',\n",
    "        'viewer_country': 'unknown',\n",
    "        'broadcaster_age': 30,\n",
    "        'broadcaster_longitude': 0,\n",
    "        'broadcaster_latitude': 0,\n",
    "        'broadcaster_lang': 'unknown',\n",
    "        'broadcaster_country': 'unknown',\n",
    "        'duration': 0,\n",
    "        'viewer_network': 'unknown',\n",
    "        'broadcaster_network': 'unknown',\n",
    "        'count': 0\n",
    "    }\n",
    "    training_df.fillna(value=values, inplace=True)\n",
    "#     print(training_df.head(10))\n",
    "#     print(training_df.iloc[-10:])\n",
    "#     stats.send_stats('data-size', len(training_df.index))\n",
    "\n",
    "    sampled_df = training_df.sample(frac=0.1)\n",
    "    print(sampled_df.head(10))\n",
    "    print(sampled_df.iloc[-10:])\n",
    "    return sampled_df\n",
    "\n",
    "def load_training_data_cold(file, stats):\n",
    "    ratings_df = load_data_file_cold(file, stats)\n",
    "    print('creating data set')\n",
    "    training_ds = (\n",
    "        tf.data.Dataset.from_tensor_slices(\n",
    "            ({\n",
    "                \"viewer\": tf.cast(\n",
    "                    ratings_df['viewer'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_gender\": tf.cast(\n",
    "                    ratings_df['viewer_gender'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_lang\": tf.cast(\n",
    "                    ratings_df['viewer_lang'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_country\": tf.cast(\n",
    "                    ratings_df['viewer_country'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_age\": tf.cast(\n",
    "                    ratings_df['viewer_age'].values,\n",
    "                    tf.int32),\n",
    "                \"viewer_longitude\": tf.cast(\n",
    "                    ratings_df['viewer_longitude'].values,\n",
    "                    tf.float16),\n",
    "                \"viewer_latitude\": tf.cast(\n",
    "                    ratings_df['viewer_latitude'].values,\n",
    "                    tf.float16),\n",
    "                \"broadcaster\": tf.cast(\n",
    "                    ratings_df['broadcaster'].values,\n",
    "                    tf.string),\n",
    "                \"viewer_network\": tf.cast(\n",
    "                    ratings_df['viewer_network'].values,\n",
    "                    tf.string),\n",
    "                \"broadcaster_network\": tf.cast(\n",
    "                    ratings_df['broadcaster_network'].values,\n",
    "                    tf.string),\n",
    "                \"duration\": tf.cast(\n",
    "                    ratings_df['duration'].values,\n",
    "                    tf.float16),\n",
    "                \"count\": tf.cast(\n",
    "                    ratings_df['count'].values,\n",
    "                    tf.int16),\n",
    "            })))\n",
    "\n",
    "    return training_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3dbdd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file:a3d86f3b-eb45-4641-b05d-30dff7423e6b.csv\n",
      "                   viewer       broadcaster  viewer_age viewer_gender  \\\n",
      "1858698  meetme:313644104     pof:298284045        29.0          male   \n",
      "2509002     pof:329096608  meetme:311343456        26.0          male   \n",
      "1931494  meetme:217635487  meetme:228586518        25.0          male   \n",
      "2476227     pof:291205266  meetme:276266098        28.0        female   \n",
      "2130883   skout:164234213  meetme:311655828        28.0          male   \n",
      "1357574     pof:172586161     pof:331106405        29.0          male   \n",
      "3818589  meetme:317318339  meetme:283611530        26.0          male   \n",
      "5300278     pof:325631121     pof:317685822        41.0          male   \n",
      "3082418  meetme:317976949    skout:62089611        26.0          male   \n",
      "249200   meetme:209570613  meetme:274948689        35.0          male   \n",
      "\n",
      "         viewer_longitude  viewer_latitude viewer_lang viewer_country  \\\n",
      "1858698       -117.166397        33.915401          en             US   \n",
      "2509002        -79.900002        40.299999          en             US   \n",
      "1931494          6.883200        49.283298          de             DE   \n",
      "2476227        -73.900002        40.599998          en             US   \n",
      "2130883         74.722000        19.122999          en             US   \n",
      "1357574        -74.599998        40.000000          en             US   \n",
      "3818589        -73.994499        40.752102          en             US   \n",
      "5300278       -158.000000        21.299999          en             US   \n",
      "3082418        121.003700        14.591300          en             US   \n",
      "249200         -80.316200        43.098598          en             US   \n",
      "\n",
      "         broadcaster_age broadcaster_gender  broadcaster_longitude  \\\n",
      "1858698             22.0             female            -118.500000   \n",
      "2509002             22.0             female             -73.994499   \n",
      "1931494             29.0             female             126.979301   \n",
      "2476227             38.0               male             -73.994499   \n",
      "2130883             23.0               male              79.431000   \n",
      "1357574             40.0               male            -112.099998   \n",
      "3818589             38.0             female             -80.205002   \n",
      "5300278             28.0             female            -158.000000   \n",
      "3082418             27.0             female             121.007004   \n",
      "249200              60.0             female             -80.549400   \n",
      "\n",
      "         broadcaster_latitude broadcaster_lang broadcaster_country  duration  \\\n",
      "1858698             34.200001               en                  US      2384   \n",
      "2509002             40.752102               en                  US       188   \n",
      "1931494             37.568001               en                  KR        83   \n",
      "2476227             40.752102               en                  US       464   \n",
      "2130883             13.624500               en                  IN      2698   \n",
      "1357574             33.599998               en                  US        76   \n",
      "3818589             26.680201               en                  US      6536   \n",
      "5300278             21.299999               en                  US        81   \n",
      "3082418             14.565000               en                  PH       423   \n",
      "249200              43.533901               en                  CA       624   \n",
      "\n",
      "        viewer_network broadcaster_network  count  \n",
      "1858698         meetme                 pof      3  \n",
      "2509002            pof              meetme      4  \n",
      "1931494         meetme              meetme      1  \n",
      "2476227            pof              meetme      1  \n",
      "2130883          skout              meetme      1  \n",
      "1357574            pof                 pof      1  \n",
      "3818589         meetme              meetme      2  \n",
      "5300278            pof                 pof      2  \n",
      "3082418         meetme               skout      2  \n",
      "249200          meetme              meetme      1  \n",
      "                   viewer       broadcaster  viewer_age viewer_gender  \\\n",
      "2184350     pof:261584442     pof:333307410        36.0          male   \n",
      "672773      pof:333619589     pof:233193467        24.0        female   \n",
      "875153   meetme:269788770  meetme:239854319        30.0        female   \n",
      "3607313   skout:158959165     pof:324825127        35.0          male   \n",
      "3963109   skout:125582711  meetme:282023464        29.0          male   \n",
      "4548647   skout:169009020  meetme:315565764        22.0          male   \n",
      "4983754     pof:216605920  meetme:271209183        31.0          male   \n",
      "3124923     pof:310828932   skout:150743909        35.0          male   \n",
      "3068637  meetme:284185150   skout:164637512        32.0          male   \n",
      "5182015   skout:181790586   skout:183200997        33.0          male   \n",
      "\n",
      "         viewer_longitude  viewer_latitude viewer_lang viewer_country  \\\n",
      "2184350        -78.699997        34.299999          en             US   \n",
      "672773         145.100006       -37.599998          en             US   \n",
      "875153        -103.078903        44.117699          en             US   \n",
      "3607313       -117.683998        34.014999          en             US   \n",
      "3963109        -73.911003        40.834000          en             US   \n",
      "4548647        -97.821999        37.750999          en             US   \n",
      "4983754        -94.500000        39.000000          en             US   \n",
      "3124923        -74.000000        40.799999          en             US   \n",
      "3068637        120.875504        14.249400          en             US   \n",
      "5182015        114.133003        22.350000          en             GB   \n",
      "\n",
      "         broadcaster_age broadcaster_gender  broadcaster_longitude  \\\n",
      "2184350             26.0             female             -79.199997   \n",
      "672773              34.0               male             138.600006   \n",
      "875153              34.0               male            -118.380096   \n",
      "3607313             34.0               male            -104.699997   \n",
      "3963109             38.0             female             -73.994499   \n",
      "4548647             22.0             female            -121.466003   \n",
      "4983754             26.0             female             -94.522697   \n",
      "3124923             30.0             female            -117.908997   \n",
      "3068637             28.0             female             121.059998   \n",
      "5182015             39.0             female             114.190002   \n",
      "\n",
      "         broadcaster_latitude broadcaster_lang broadcaster_country  duration  \\\n",
      "2184350             35.500000               en                  US       283   \n",
      "672773             -34.900002               en                  AU        97   \n",
      "875153              34.093899               en                  US     26875   \n",
      "3607313             38.299999               en                  US       274   \n",
      "3963109             40.752102               en                  US        99   \n",
      "4548647             38.575901               en                  US        71   \n",
      "4983754             38.880299               en                  US       125   \n",
      "3124923             33.625999               en                  US       165   \n",
      "3068637             14.534000               en                  PH       113   \n",
      "5182015             22.323999               en                  HK        67   \n",
      "\n",
      "        viewer_network broadcaster_network  count  \n",
      "2184350            pof                 pof      1  \n",
      "672773             pof                 pof      1  \n",
      "875153          meetme              meetme     19  \n",
      "3607313          skout                 pof      2  \n",
      "3963109          skout              meetme      1  \n",
      "4548647          skout              meetme      2  \n",
      "4983754            pof              meetme      1  \n",
      "3124923            pof               skout      1  \n",
      "3068637         meetme               skout      1  \n",
      "5182015          skout               skout      1  \n",
      "creating data set\n",
      "{'broadcaster': b'pof:298284045',\n",
      " 'broadcaster_network': b'pof',\n",
      " 'count': 3,\n",
      " 'duration': 2384.0,\n",
      " 'viewer': b'meetme:313644104',\n",
      " 'viewer_age': 29,\n",
      " 'viewer_country': b'US',\n",
      " 'viewer_gender': b'male',\n",
      " 'viewer_lang': b'en',\n",
      " 'viewer_latitude': 33.9,\n",
      " 'viewer_longitude': -117.2,\n",
      " 'viewer_network': b'meetme'}\n"
     ]
    }
   ],
   "source": [
    "ratings = load_training_data_cold(file=\"a3d86f3b-eb45-4641-b05d-30dff7423e6b.csv\", stats=\"\")\n",
    "\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc0540",
   "metadata": {},
   "source": [
    "### Defining the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83c7bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcaster_lookup = tf.keras.layers.experimental.preprocessing.StringLookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fef4c9ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0f31cdc20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0f31cdc20> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0f31cddd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0f31cddd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "broadcaster_lookup.adapt(ratings.map(lambda x: x[\"broadcaster\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28aeee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['[UNK]', 'meetme:277903808', 'meetme:50697624', 'meetme:219070323', 'pof:300442673', 'pof:322045884', 'pof:319663298', 'pof:315853960', 'pof:297373249', 'meetme:283611530', 'pof:79582086', 'skout:150743909', 'pof:299641758', 'meetme:309755964', 'meetme:197536011', 'meetme:294844287', 'meetme:308663123', 'skout:39313218', 'meetme:228586518', 'meetme:195325769']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulary: {broadcaster_lookup.get_vocabulary()[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "690ca2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69797"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcaster_lookup.vocabulary_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d83446fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([0, 1, 2])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcaster_lookup([\"[UNK]\", \"meetme:277903808\", \"meetme:50697624\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5f214",
   "metadata": {},
   "source": [
    "### Using feature hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81404e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set up a large number of bins to reduce the chance of hash collisions.\n",
    "num_hashing_bins = 200_000\n",
    "\n",
    "broadcaster_hashing = tf.keras.layers.experimental.preprocessing.Hashing(\n",
    "    num_bins=num_hashing_bins\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b928b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([ 18280, 193815, 180119])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcaster_hashing([\"[UNK]\", \"meetme:277903808\", \"meetme:50697624\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f7650f",
   "metadata": {},
   "source": [
    "### Defining the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d84a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcaster_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=broadcaster_lookup.vocabulary_size(),\n",
    "    output_dim=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31bd8334",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcaster_model = tf.keras.Sequential([broadcaster_lookup, broadcaster_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd48088e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['meetme:277903808']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[-0.00220549,  0.00318506, -0.04274105, -0.03318482,  0.01996905,\n",
       "        -0.00360984,  0.03728544,  0.04276649,  0.02944965, -0.01693236,\n",
       "        -0.03837664,  0.02658382, -0.01988866, -0.02986122,  0.02398682,\n",
       "        -0.00580009,  0.0463425 , -0.02724286,  0.03874153, -0.00180887,\n",
       "        -0.00071955, -0.02124978, -0.03418276,  0.03018219, -0.02725717,\n",
       "         0.03669694,  0.04854344,  0.0132411 ,  0.02092062,  0.04907768,\n",
       "        -0.04367078, -0.01637457]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcaster_model([\"meetme:277903808\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c592e0c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc17b19d170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc17b19d170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc17b19d9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc17b19d9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# user embedding\n",
    "user_id_lookup = tf.keras.layers.experimental.preprocessing.StringLookup()\n",
    "user_id_lookup.adapt(ratings.map(lambda x: x[\"viewer\"]))\n",
    "\n",
    "user_id_embedding = tf.keras.layers.Embedding(user_id_lookup.vocabulary_size(), 32)\n",
    "user_id_model = tf.keras.Sequential([user_id_lookup, user_id_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c81d6876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['meetme:277903808']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[ 0.01943531, -0.00493991, -0.00137669,  0.0355396 , -0.02645339,\n",
       "        -0.00294147,  0.03740872,  0.02480601, -0.04640242,  0.03370896,\n",
       "        -0.02711483,  0.00093615,  0.01668551,  0.03670264,  0.01320238,\n",
       "        -0.0214431 ,  0.04782381,  0.00272961,  0.04388637,  0.02362683,\n",
       "         0.02637327, -0.02401898, -0.03807665, -0.00941879,  0.0490785 ,\n",
       "        -0.04063647,  0.03368082, -0.01720614, -0.0470655 , -0.00019421,\n",
       "        -0.04578037,  0.04345498]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_model([\"meetme:277903808\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16727aa",
   "metadata": {},
   "source": [
    "### Normalizing continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50bdbb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viewer_age: 29.\n",
      "viewer_age: 26.\n",
      "viewer_age: 25.\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(3).as_numpy_iterator():\n",
    "    print(f\"viewer_age: {x['viewer_age']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b905c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0f15030e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0f15030e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0f1503440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0f1503440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Normalized viewer age: [-0.52391666].\n",
      "Normalized viewer age: [-0.83302295].\n",
      "Normalized viewer age: [-0.9360584].\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "viewer_age_normalization = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "    axis=None\n",
    ")\n",
    "viewer_age_normalization.adapt(ratings.map(lambda x: x['viewer_age']).batch(32))\n",
    "\n",
    "for x in ratings.take(3).as_numpy_iterator():\n",
    "    print(f\"Normalized viewer age: {viewer_age_normalization(x['viewer_age'])}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d66332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0f14e4320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0f14e4320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0f14e4830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0f14e4830> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Buckets: [ 18.          38.22222222  58.44444444  78.66666667  98.88888889\n",
      " 119.11111111 139.33333333 159.55555556 179.77777778 200.        ]\n"
     ]
    }
   ],
   "source": [
    "# Discretization\n",
    "max_viewer_age = ratings.map(lambda x: x[\"viewer_age\"]).reduce(\n",
    "    tf.cast(0, tf.int32), tf.maximum).numpy().max()\n",
    "min_viewer_age = ratings.map(lambda x: x[\"viewer_age\"]).reduce(\n",
    "    np.int32(100), tf.minimum).numpy().min()\n",
    "\n",
    "viewer_age_buckets = np.linspace(\n",
    "    min_viewer_age, max_viewer_age, num=10)\n",
    "\n",
    "print(f\"Buckets: {viewer_age_buckets[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "818bfca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc18c4469e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc18c4469e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Viewer_age embedding: [[-0.03302993  0.03110944  0.01416438 -0.01521438 -0.03592966 -0.02223239\n",
      "  -0.04625424 -0.00605955  0.00684149 -0.02312992 -0.01667572 -0.03321574\n",
      "  -0.02386065 -0.02983061  0.0152416   0.03268285  0.04790663  0.04542525\n",
      "  -0.02657044 -0.04043273 -0.03326219  0.04068789  0.04848525  0.02951981\n",
      "   0.04435328  0.02764675 -0.00330366 -0.03459014  0.00951219 -0.04073434\n",
      "   0.017962    0.01527431]].\n"
     ]
    }
   ],
   "source": [
    "# Given the bucket boundaries we can transform timestamps into embeddings:\n",
    "viewer_age_embedding_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Discretization(viewer_age_buckets.tolist()),\n",
    "  tf.keras.layers.Embedding(len(viewer_age_buckets) + 1, 32)\n",
    "])\n",
    "\n",
    "for viewer_age in ratings.take(1).map(lambda x: x[\"viewer_age\"]).batch(1).as_numpy_iterator():\n",
    "    print(f\"Viewer_age embedding: {viewer_age_embedding_model(viewer_age)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681eea49",
   "metadata": {},
   "source": [
    "### Processing text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d372997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_colons(text):\n",
    "    return tf.strings.split(text, sep=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a46d7977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0deadba70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0deadba70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0deaf3f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0deaf3f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "broadcaster_text = tf.keras.layers.experimental.preprocessing.TextVectorization(standardize= None, split=split_on_colons)\n",
    "broadcaster_text.adapt(ratings.map(lambda x: x[\"broadcaster\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63ac3797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc13bf7b560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc13bf7b560> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "tf.Tensor([[    3 13467]], shape=(1, 2), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for row in ratings.batch(1).map(lambda x: x[\"broadcaster\"]).take(1):\n",
    "  print(broadcaster_text(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa6cda09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'meetme',\n",
       " 'pof',\n",
       " 'skout',\n",
       " '277903808',\n",
       " '50697624',\n",
       " 'zoosk',\n",
       " '219070323',\n",
       " '300442673']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcaster_text.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5992dede",
   "metadata": {},
   "source": [
    "### User Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "094d845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.user_embedding = tf.keras.Sequential([\n",
    "\t\t\tuser_id_lookup,\n",
    "\t\t\ttf.keras.layers.Embedding(user_id_lookup.vocabulary_size(), 32),\n",
    "\t\t])\n",
    "        \n",
    "\t\tself.viewer_age_embedding = tf.keras.Sequential([\n",
    "\t\t\ttf.keras.layers.experimental.preprocessing.Discretization(viewer_age_buckets.tolist()),\n",
    "\t\t\ttf.keras.layers.Embedding(len(viewer_age_buckets) + 1, 32)\n",
    "\t\t])\n",
    "\t\tself.normalized_viewer_age = tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "\t\t\taxis = None\n",
    "\t\t)\n",
    "\n",
    "\tdef call(self, inputs):\n",
    "\t\t# Take the input dictionary, pass it through each input layer,\n",
    "\t\t# and concatenate the result.\n",
    "\t\treturn tf.concat([\n",
    "\t\t\tself.user_embedding(inputs[\"viewer\"]),\n",
    "\t\t\tself.viewer_age_embedding(inputs[\"viewer_age\"]),\n",
    "\t\t\ttf.reshape(self.normalized_viewer_age(inputs[\"viewer_age\"]), (-1, 1))\n",
    "\t\t], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43c1e345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0c9606050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0c9606050> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0deadbcb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0deadbcb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Computed representations: [-0.03831752 -0.03813299  0.0499326 ]\n"
     ]
    }
   ],
   "source": [
    "user_model = UserModel()\n",
    "\n",
    "user_model.normalized_viewer_age.adapt(\n",
    "    ratings.map(lambda x: x[\"viewer_age\"]).batch(128))\n",
    "\n",
    "for row in ratings.batch(1).take(1):\n",
    "    print(f\"Computed representations: {user_model(row)[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a45541",
   "metadata": {},
   "source": [
    "### Broadcaster model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b312323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0db1ad950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0db1ad950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "broadcaster_ids = ratings.batch(100_000).map(lambda x: x[\"broadcaster\"])\n",
    "unique_broadcaster_ids = np.unique(np.concatenate(list(broadcaster_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49390625",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BroadcasterModel(tf.keras.Model) :\n",
    "\n",
    "\tdef __init__(self) :\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tmax_tokens = 32\n",
    "\t\tself.broadcaster_embedding = tf.keras.Sequential([\n",
    "\t\t\ttf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "\t\t\t\tvocabulary = unique_broadcaster_ids, max_tokens=None),\n",
    "\t\t\ttf.keras.layers.Embedding(len(unique_broadcaster_ids) + 1, 32)\n",
    "\t\t])\n",
    "        \n",
    "\t\tself.broadcaster_text_embedding = tf.keras.Sequential([\n",
    "\t\t\ttf.keras.layers.experimental.preprocessing.TextVectorization(standardize= None, split=split_on_colons, max_tokens=32),\n",
    "\t\t\ttf.keras.layers.Embedding(max_tokens, 32, mask_zero = True),\n",
    "\t\t\t# We average the embedding of individual words to get one embedding vector\n",
    "\t\t\t# per title.\n",
    "\t\t\ttf.keras.layers.GlobalAveragePooling1D(),\n",
    "\t\t])\n",
    "\n",
    "\n",
    "\tdef call(self, inputs) :\n",
    "\t\treturn tf.concat([\n",
    "\t\t\tself.broadcaster_embedding(inputs[\"broadcaster\"]),\n",
    "\t\t\tself.broadcaster_text_embedding(inputs[\"broadcaster\"]),\n",
    "\t\t], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26da5b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0f1780f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0f1780f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0cddd5170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fc0cddd5170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Computed representations: [ 0.0276117  -0.04592123  0.02068477]\n"
     ]
    }
   ],
   "source": [
    "broadcaster_model = BroadcasterModel()\n",
    "\n",
    "broadcaster_model.broadcaster_text_embedding.layers[0].adapt(\n",
    "    ratings.map(lambda x: x[\"broadcaster\"]))\n",
    "\n",
    "for row in ratings.batch(1).take(1):\n",
    "    print(f\"Computed representations: {broadcaster_model(row)[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30469de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
