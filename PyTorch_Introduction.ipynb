{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "PyTorch_Introduction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zqyBFdobMTha",
        "jlzoXa6UMThg",
        "l08nQdE9MThp",
        "Tmg4eFQAMThr",
        "jifMOIcNMTh5",
        "aSO1McZLMTiT",
        "OCwLf9C2MTiY",
        "IrapEC2XMTiY",
        "NwsmNTYLMTig",
        "OyN-mHRoMTii"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linghduoduo/Deep-Learning/blob/master/PyTorch_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Lg2NXGMThA"
      },
      "source": [
        "# PyTorch Introduction\n",
        "\n",
        "##### This Tutorial is modified from [University of Washington CSE446](https://courses.cs.washington.edu/courses/cse446/19au/section9.html) and [PyTorch Official Tutorials](https://pytorch.org/tutorials/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi_QP1bmMThC"
      },
      "source": [
        "Today, we will be intoducing PyTorch, \"an open source deep learning platform that provides a seamless path from research prototyping to production deployment\".\n",
        "\n",
        "This notebook is by no means comprehensive. If you have any questions the **documentation** and **Google** are your friends.\n",
        "\n",
        "Goal takeaways:\n",
        "- Automatic differentiation is a powerful tool\n",
        "- PyTorch implements common functions used in deep learning\n",
        "- Data Processing with PyTorch DataSet\n",
        "- Mixed Presision Training in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQIPkkKdMThD"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(446)\n",
        "np.random.seed(446)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCQTBsnWMThH"
      },
      "source": [
        "## Tensors and relation to numpy\n",
        "\n",
        "By this point, we have worked with numpy quite a bit. PyTorch's basic building block, the `tensor` is similar to numpy's `ndarray`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXnFLFr1MThI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b3f240d-5b30-4487-df34-74521911a99e"
      },
      "source": [
        "# we create tensors in a similar way to numpy nd arrays\n",
        "x_numpy = np.array([0.1, 0.2, 0.3])\n",
        "x_torch = torch.tensor([0.1, 0.2, 0.3])\n",
        "print('x_numpy, x_torch')\n",
        "print(x_numpy, x_torch)\n",
        "print()\n",
        "\n",
        "# to and from numpy, pytorch\n",
        "print('to and from numpy and pytorch')\n",
        "print(torch.from_numpy(x_numpy), x_torch.numpy())\n",
        "print()\n",
        "\n",
        "# we can do basic operations like +-*/\n",
        "y_numpy = np.array([3,4,5.])\n",
        "y_torch = torch.tensor([3,4,5.])\n",
        "print(\"x+y\")\n",
        "print(x_numpy + y_numpy, x_torch + y_torch)\n",
        "print()\n",
        "\n",
        "# many functions that are in numpy are also in pytorch\n",
        "print(\"norm\")\n",
        "print(np.linalg.norm(x_numpy), torch.norm(x_torch))\n",
        "print()\n",
        "\n",
        "# to apply an operation along a dimension,\n",
        "# we use the dim keyword argument instead of axis\n",
        "print(\"mean along the 0th dimension\")\n",
        "x_numpy = np.array([[1,2],[3,4.]])\n",
        "x_torch = torch.tensor([[1,2],[3,4.]])\n",
        "print(np.mean(x_numpy, axis=0), torch.mean(x_torch, dim=0))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_numpy, x_torch\n",
            "[0.1 0.2 0.3] tensor([0.1000, 0.2000, 0.3000])\n",
            "\n",
            "to and from numpy and pytorch\n",
            "tensor([0.1000, 0.2000, 0.3000], dtype=torch.float64) [0.1 0.2 0.3]\n",
            "\n",
            "x+y\n",
            "[3.1 4.2 5.3] tensor([3.1000, 4.2000, 5.3000])\n",
            "\n",
            "norm\n",
            "0.37416573867739417 tensor(0.3742)\n",
            "\n",
            "mean along the 0th dimension\n",
            "[2. 3.] tensor([2., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtyttsoZMThL"
      },
      "source": [
        "### `Tensor.view`\n",
        "We can use the `Tensor.view()` function to reshape tensors similarly to `numpy.reshape()`\n",
        "\n",
        "It can also automatically calculate the correct dimension if a `-1` is passed in. This is useful if we are working with batches, but the batch size is unknown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABhZ5mKpMThM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f92f398b-d623-4557-9272-28316f4c27d7"
      },
      "source": [
        "# \"MNIST\"\n",
        "N, C, W, H = 10000, 3, 28, 28\n",
        "X = torch.randn((N, C, W, H))\n",
        "\n",
        "print(X.shape)\n",
        "print(X.view(N, C, 784).shape)\n",
        "print(X.view(-1, C, 784).shape) # automatically choose the 0th dimension"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 3, 28, 28])\n",
            "torch.Size([10000, 3, 784])\n",
            "torch.Size([10000, 3, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXgxfCTMOjIp"
      },
      "source": [
        "### `BROADCASTING SEMANTICS`\n",
        "Two tensors are “broadcastable” if the following rules hold:\n",
        "\n",
        "Each tensor has at least one dimension.\n",
        "\n",
        "When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ioj-DAhOjiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "319edbec-a488-43c5-db19-c1e6aaf5303b"
      },
      "source": [
        "# PyTorch operations support NumPy Broadcasting Semantics.\n",
        "x=torch.empty(5,1,4,1)\n",
        "y=torch.empty(  3,1,1)\n",
        "print((x+y).size())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 4, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3vQ3yD9MThP"
      },
      "source": [
        "## Computation graphs\n",
        "\n",
        "What's special about PyTorch's `tensor` object is that it implicitly creates a computation graph in the background. A computation graph is a a way of writing a mathematical expression as a graph. There is an algorithm to compute the gradients of all the variables of a computation graph in time on the same order it is to compute the function itself.\n",
        "\n",
        "Consider the expression $e=(a+b)*(b+1)$ with values $a=2, b=1$. We can draw the evaluated computation graph as\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "In PyTorch, we can write this as"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-HpojJ_MThQ"
      },
      "source": [
        "![tree-img](https://colah.github.io/posts/2015-08-Backprop/img/tree-eval.png)\n",
        "\n",
        "[source](https://colah.github.io/posts/2015-08-Backprop/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7NGX7CVMThR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "312eebc4-9d37-48b9-d479-bce4236eb925"
      },
      "source": [
        "a = torch.tensor(2.0, requires_grad=True) # we set requires_grad=True to let PyTorch know to keep the graph\n",
        "b = torch.tensor(1.0, requires_grad=True)\n",
        "c = a + b\n",
        "d = b + 1\n",
        "e = c * d\n",
        "print('c', c)\n",
        "print('d', d)\n",
        "print('e', e)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c tensor(3., grad_fn=<AddBackward0>)\n",
            "d tensor(2., grad_fn=<AddBackward0>)\n",
            "e tensor(6., grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orGtJTjkMThU"
      },
      "source": [
        "We can see that PyTorch kept track of the computation graph for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPZfJ1hy4uxj"
      },
      "source": [
        "## CUDA SEMANTICS\n",
        "It's easy cupy tensor from cpu to gpu or from gpu to cpu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYqe5vVv43tG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15efa5bc-46d1-4051-bf9e-591220e4d089"
      },
      "source": [
        "cpu = torch.device(\"cpu\")\n",
        "gpu = torch.device(\"cuda\")\n",
        "\n",
        "x = torch.rand(10)\n",
        "print(x)\n",
        "x = x.to(gpu)\n",
        "print(x)\n",
        "x = x.to(cpu)\n",
        "print(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.3959, 0.6177, 0.7256, 0.0971, 0.9186, 0.8277, 0.4409, 0.9344, 0.8967,\n",
            "        0.1897])\n",
            "tensor([0.3959, 0.6177, 0.7256, 0.0971, 0.9186, 0.8277, 0.4409, 0.9344, 0.8967,\n",
            "        0.1897], device='cuda:0')\n",
            "tensor([0.3959, 0.6177, 0.7256, 0.0971, 0.9186, 0.8277, 0.4409, 0.9344, 0.8967,\n",
            "        0.1897])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7Wy2mEOMThU"
      },
      "source": [
        "## PyTorch as an auto grad framework\n",
        "\n",
        "Now that we have seen that PyTorch keeps the graph around for us, let's use it to compute some gradients for us.\n",
        "\n",
        "Consider the function $f(x) = (x-2)^2$.\n",
        "\n",
        "Q: Compute $\\frac{d}{dx} f(x)$ and then compute $f'(1)$.\n",
        "\n",
        "We make a `backward()` call on the leaf variable (`y`) in the computation, computing all the gradients of `y` at once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvN0jSOKMThV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "badea327-2c2c-4e97-8160-234ea8384b85"
      },
      "source": [
        "def f(x):\n",
        "    return (x-2)**2\n",
        "\n",
        "def fp(x):\n",
        "    return 2*(x-2)\n",
        "\n",
        "x = torch.tensor([1.0], requires_grad=True)\n",
        "\n",
        "y = f(x)\n",
        "y.backward()\n",
        "\n",
        "print('Analytical f\\'(x):', fp(x))\n",
        "print('PyTorch\\'s f\\'(x):', x.grad)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analytical f'(x): tensor([-2.], grad_fn=<MulBackward0>)\n",
            "PyTorch's f'(x): tensor([-2.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvJR6H7KMThX"
      },
      "source": [
        "It can also find gradients of functions.\n",
        "\n",
        "Let $w = [w_1, w_2]^T$\n",
        "\n",
        "Consider $g(w) = 2w_1w_2 + w_2\\cos(w_1)$\n",
        "\n",
        "Q: Compute $\\nabla_w g(w)$ and verify $\\nabla_w g([\\pi,1]) = [2, \\pi - 1]^T$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WCp53C1MThY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d91f7f-491a-4eba-c3b5-11b1e4a2cf0e"
      },
      "source": [
        "def g(w):\n",
        "    return 2*w[0]*w[1] + w[1]*torch.cos(w[0])\n",
        "\n",
        "def grad_g(w):\n",
        "    return torch.tensor([2*w[1] - w[1]*torch.sin(w[0]), 2*w[0] + torch.cos(w[0])])\n",
        "\n",
        "w = torch.tensor([np.pi, 1], requires_grad=True)\n",
        "\n",
        "z = g(w)\n",
        "z.backward()\n",
        "\n",
        "print('Analytical grad g(w)', grad_g(w))\n",
        "print('PyTorch\\'s grad g(w)', w.grad)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analytical grad g(w) tensor([2.0000, 5.2832])\n",
            "PyTorch's grad g(w) tensor([2.0000, 5.2832])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqyBFdobMTha"
      },
      "source": [
        "## Using the gradients\n",
        "Now that we have gradients, we can use our favorite optimization algorithm: gradient descent!\n",
        "\n",
        "Let $f$ the same function we defined above.\n",
        "\n",
        "Q: What is the value of $x$ that minimizes $f$?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4-8fhqAMThb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c50b864a-1619-4acc-f9b0-8868f2346617"
      },
      "source": [
        "x = torch.tensor([5.0], requires_grad=True)\n",
        "step_size = 0.25\n",
        "\n",
        "print('iter,\\tx, \\tf(x),\\tf\\'(x), pytorch\\tf\\'(x)')\n",
        "for i in range(15):\n",
        "    y = f(x)\n",
        "    y.backward() # compute the gradient\n",
        "    \n",
        "    print('{},\\t{:.3f},\\t{:.3f},\\t{:.3f},\\t{:.3f}'.format(i, x.item(), f(x).item(), fp(x).item(), x.grad.item()))\n",
        "    \n",
        "    x.data = x.data - step_size * x.grad # perform a GD update step\n",
        "    \n",
        "    # We need to zero the grad variable since the backward()\n",
        "    # call accumulates the gradients in .grad instead of overwriting.\n",
        "    # The detach_() is for efficiency. You do not need to worry too much about it.\n",
        "    x.grad.detach_()\n",
        "    x.grad.zero_()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter,\tx, \tf(x),\tf'(x), pytorch\tf'(x)\n",
            "0,\t5.000,\t9.000,\t6.000,\t6.000\n",
            "1,\t3.500,\t2.250,\t3.000,\t3.000\n",
            "2,\t2.750,\t0.562,\t1.500,\t1.500\n",
            "3,\t2.375,\t0.141,\t0.750,\t0.750\n",
            "4,\t2.188,\t0.035,\t0.375,\t0.375\n",
            "5,\t2.094,\t0.009,\t0.188,\t0.188\n",
            "6,\t2.047,\t0.002,\t0.094,\t0.094\n",
            "7,\t2.023,\t0.001,\t0.047,\t0.047\n",
            "8,\t2.012,\t0.000,\t0.023,\t0.023\n",
            "9,\t2.006,\t0.000,\t0.012,\t0.012\n",
            "10,\t2.003,\t0.000,\t0.006,\t0.006\n",
            "11,\t2.001,\t0.000,\t0.003,\t0.003\n",
            "12,\t2.001,\t0.000,\t0.001,\t0.001\n",
            "13,\t2.000,\t0.000,\t0.001,\t0.001\n",
            "14,\t2.000,\t0.000,\t0.000,\t0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TPWiwARMThd"
      },
      "source": [
        "# Linear Regression\n",
        "\n",
        "Now, instead of minimizing a made-up function, lets minimize a loss function on some made-up data.\n",
        "\n",
        "We will implement Gradient Descent in order to solve the task of linear regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3el-4esEMThe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6aff816-d407-4b73-f193-f21cbe96b365"
      },
      "source": [
        "# make a simple linear dataset with some noise\n",
        "\n",
        "d = 2\n",
        "n = 50\n",
        "X = torch.randn(n, d)\n",
        "true_w = torch.tensor([[-1.0], [2.0]])\n",
        "y = X @ true_w + torch.randn(n, 1) * 0.1\n",
        "print('X shape', X.shape)\n",
        "print('y shape', y.shape)\n",
        "print('w shape', true_w.shape)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape torch.Size([50, 2])\n",
            "y shape torch.Size([50, 1])\n",
            "w shape torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlzoXa6UMThg"
      },
      "source": [
        "### Note: dimensions\n",
        "PyTorch does a lot of operations on batches of data. The convention is to have your data be of size $(N, d)$ where $N$ is the size of the batch of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l08nQdE9MThp"
      },
      "source": [
        "### Sanity check\n",
        "To verify PyTorch is computing the gradients correctly, let's recall the gradient for the RSS objective:\n",
        "\n",
        "$$\\nabla_w \\mathcal{L}_{RSS}(w; X) = \\nabla_w\\frac{1}{n} ||y - Xw||_2^2 = -\\frac{2}{n}X^T(y-Xw)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5HfA5YcMThp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "603fc953-f0cf-44f7-c1a6-4c7d5e18846e"
      },
      "source": [
        "# define a linear model with no bias\n",
        "def model(X, w):\n",
        "    return X @ w\n",
        "\n",
        "# the residual sum of squares loss function\n",
        "def rss(y, y_hat):\n",
        "    return torch.norm(y - y_hat)**2 / n\n",
        "\n",
        "# analytical expression for the gradient\n",
        "def grad_rss(X, y, w):\n",
        "    return -2*X.t() @ (y - X @ w) / n\n",
        "\n",
        "w = torch.tensor([[1.], [0]], requires_grad=True)\n",
        "y_hat = model(X, w)\n",
        "\n",
        "loss = rss(y, y_hat)\n",
        "loss.backward()\n",
        "\n",
        "print('Analytical gradient', grad_rss(X, y, w).detach().view(2).numpy())\n",
        "print('PyTorch\\'s gradient', w.grad.view(2).numpy())\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analytical gradient [ 4.342543  -3.5023162]\n",
            "PyTorch's gradient [ 4.342543 -3.502316]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tmg4eFQAMThr"
      },
      "source": [
        "Now that we've seen PyTorch is doing the right think, let's use the gradients!\n",
        "\n",
        "## Linear regression using GD with automatically computed derivatives\n",
        "\n",
        "We will now use the gradients to run the gradient descent algorithm.\n",
        "\n",
        "Note: This example is an illustration to connect ideas we have seen before to PyTorch's way of doing things. We will see how to do this in the \"PyTorchic\" way in the next example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gea4LETnMThs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b7abad-1665-404c-a280-41e37e741a7d"
      },
      "source": [
        "step_size = 0.1\n",
        "\n",
        "print('iter,\\tloss,\\tw')\n",
        "for i in range(20):\n",
        "    y_hat = model(X, w)\n",
        "    loss = rss(y, y_hat)\n",
        "    \n",
        "    loss.backward() # compute the gradient of the loss\n",
        "    \n",
        "    w.data = w.data - step_size * w.grad # do a gradient descent step\n",
        "    \n",
        "    print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), w.view(2).detach().numpy()))\n",
        "    \n",
        "    # We need to zero the grad variable since the backward()\n",
        "    # call accumulates the gradients in .grad instead of overwriting.\n",
        "    # The detach_() is for efficiency. You do not need to worry too much about it.\n",
        "    w.grad.detach()\n",
        "    w.grad.zero_()\n",
        "\n",
        "print('\\ntrue w\\t\\t', true_w.view(2).numpy())\n",
        "print('estimated w\\t', w.view(2).detach().numpy())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter,\tloss,\tw\n",
            "0,\t7.82,\t[0.13149136 0.70046324]\n",
            "1,\t2.84,\t[-0.11822014  0.9229876 ]\n",
            "2,\t1.84,\t[-0.31444427  1.1054724 ]\n",
            "3,\t1.19,\t[-0.4684834  1.2552956]\n",
            "4,\t0.77,\t[-0.58927345  1.3784461 ]\n",
            "5,\t0.50,\t[-0.68387645  1.4797904 ]\n",
            "6,\t0.33,\t[-0.75787055  1.563287  ]\n",
            "7,\t0.22,\t[-0.8156596  1.632159 ]\n",
            "8,\t0.15,\t[-0.86071837  1.6890337 ]\n",
            "9,\t0.10,\t[-0.89578694  1.736055  ]\n",
            "10,\t0.07,\t[-0.9230244  1.7749742]\n",
            "11,\t0.05,\t[-0.94413096  1.8072236 ]\n",
            "12,\t0.03,\t[-0.9604442  1.8339758]\n",
            "13,\t0.02,\t[-0.9730157  1.8561921]\n",
            "14,\t0.02,\t[-0.9826713  1.8746614]\n",
            "15,\t0.01,\t[-0.99005884  1.8900318 ]\n",
            "16,\t0.01,\t[-0.99568594  1.9028363 ]\n",
            "17,\t0.01,\t[-0.99994993  1.913514  ]\n",
            "18,\t0.01,\t[-1.0031612  1.9224268]\n",
            "19,\t0.01,\t[-1.0055621  1.9298735]\n",
            "\n",
            "true w\t\t [-1.  2.]\n",
            "estimated w\t [-1.0055621  1.9298735]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AexdjJtcMThu"
      },
      "source": [
        "## torch.nn.Module\n",
        "\n",
        "`Module` is PyTorch's way of performing operations on tensors. Modules are implemented as subclasses of the `torch.nn.Module` class. All modules are callable and can be composed together to create complex functions.\n",
        "\n",
        "[`torch.nn` docs](https://pytorch.org/docs/stable/nn.html)\n",
        "\n",
        "Note: most of the functionality implemented for modules can be accessed in a functional form via `torch.nn.functional`, but these require you to create and manage the weight tensors yourself.\n",
        "\n",
        "[`torch.nn.functional` docs](https://pytorch.org/docs/stable/nn.html#torch-nn-functional)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuigjBAiMThv"
      },
      "source": [
        "### Linear Module\n",
        "The bread and butter of modules is the Linear module which does a linear transformation with a bias. It takes the input and output dimensions as parameters, and creates the weights in the object.\n",
        "\n",
        "Unlike how we initialized our $w$ manually, the Linear module automatically initializes the weights randomly. For minimizing non convex loss functions (e.g. training neural networks), initialization is important and can affect results. If training isn't working as well as expected, one thing to try is manually initializing the weights to something different from the default. PyTorch implements some common initializations in `torch.nn.init`.\n",
        "\n",
        "[`torch.nn.init` docs](https://pytorch.org/docs/stable/nn.html#torch-nn-init)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi4lhPVCMThv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1f9e8a-95fe-46f6-d5b1-280c2891147b"
      },
      "source": [
        "d_in = 3\n",
        "d_out = 4\n",
        "linear_module = nn.Linear(d_in, d_out)\n",
        "\n",
        "example_tensor = torch.tensor([[1.,2,3], [4,5,6]])\n",
        "# applys a linear transformation to the data\n",
        "transformed = linear_module(example_tensor)\n",
        "print('example_tensor', example_tensor.shape)\n",
        "print('transormed', transformed.shape)\n",
        "print()\n",
        "print('We can see that the weights exist in the background\\n')\n",
        "print('W:', linear_module.weight)\n",
        "print('b:', linear_module.bias)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example_tensor torch.Size([2, 3])\n",
            "transormed torch.Size([2, 4])\n",
            "\n",
            "We can see that the weights exist in the background\n",
            "\n",
            "W: Parameter containing:\n",
            "tensor([[ 0.5260,  0.4925, -0.0887],\n",
            "        [ 0.3944,  0.4080,  0.2182],\n",
            "        [-0.1409,  0.0518,  0.3034],\n",
            "        [ 0.0913,  0.2452, -0.2616]], requires_grad=True)\n",
            "b: Parameter containing:\n",
            "tensor([0.5021, 0.0118, 0.1383, 0.4757], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLNmKz9BMThx"
      },
      "source": [
        "### Activation functions\n",
        "PyTorch implements a number of activation functions including but not limited to `ReLU`, `Tanh`, and `Sigmoid`. Since they are modules, they need to be instantiated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toOsF9qXMThy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2caaf778-a972-464b-8943-84e265e92e38"
      },
      "source": [
        "activation_fn = nn.ReLU() # we instantiate an instance of the ReLU module\n",
        "example_tensor = torch.tensor([-1.0, 1.0, 0.0])\n",
        "activated = activation_fn(example_tensor)\n",
        "print('example_tensor', example_tensor)\n",
        "print('activated', activated)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example_tensor tensor([-1.,  1.,  0.])\n",
            "activated tensor([0., 1., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPdu_KS_MTh0"
      },
      "source": [
        "### Sequential\n",
        "\n",
        "Many times, we want to compose Modules together. `torch.nn.Sequential` provides a good interface for composing simple modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn-jaKd3MTh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02148d68-41fd-4ccf-836b-4fde4b078c1b"
      },
      "source": [
        "d_in = 3\n",
        "d_hidden = 4\n",
        "d_out = 1\n",
        "model = torch.nn.Sequential(\n",
        "                            nn.Linear(d_in, d_hidden),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(d_hidden, d_out),\n",
        "                            nn.Sigmoid()\n",
        "                           )\n",
        "\n",
        "example_tensor = torch.tensor([[1.,2,3],[4,5,6]])\n",
        "transformed = model(example_tensor)\n",
        "print('transformed', transformed.shape)\n",
        "\n",
        "linear = nn.Linear(d_in, d_out)\n",
        "# tanhn = nn.Tanh()\n",
        "# linear2 = nn.Linear(d_hidden, d_out)\n",
        "# sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "# x = linear(x)\n",
        "# x = nn.Tanh(x)\n",
        "# x = linear2(x)\n",
        "# x = sigmoid(x)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "transformed torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5GkJ1UTMTh2"
      },
      "source": [
        "Note: we can access *all* of the parameters (of any `nn.Module`) with the `parameters()` method. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTTsMkxoMTh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c8e51c-ac17-431b-bd30-8e084cca960a"
      },
      "source": [
        "params = model.parameters()\n",
        "\n",
        "for param in params:\n",
        "    print(param)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3128,  0.2707, -0.3952],\n",
            "        [ 0.1285,  0.1777, -0.4675],\n",
            "        [ 0.0452, -0.5630, -0.1999],\n",
            "        [ 0.5431,  0.0524,  0.1126]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.2683, -0.2361,  0.2769, -0.1380], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.4902, -0.0928, -0.2907,  0.0734]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0394], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifMOIcNMTh5"
      },
      "source": [
        "### Loss functions\n",
        "PyTorch implements many common loss functions including `MSELoss` and `CrossEntropyLoss`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8NXNEhlMTh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5053a6a2-7fd9-4fb1-a66b-5eefc00c4c1f"
      },
      "source": [
        "mse_loss_fn = nn.MSELoss()\n",
        "\n",
        "input = torch.tensor([[0., 0, 0]])\n",
        "target = torch.tensor([[1., 0, -1]])\n",
        "\n",
        "loss = mse_loss_fn(input, target)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6667)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh0YZh1QMTh7"
      },
      "source": [
        "## torch.optim\n",
        "PyTorch implements a number of gradient-based optimization methods in `torch.optim`, including Gradient Descent. At the minimum, it takes in the model parameters and a learning rate.\n",
        "\n",
        "Optimizers do not compute the gradients for you, so you must call `backward()` yourself. You also must call the `optim.zero_grad()` function before calling `backward()` since by default PyTorch does and inplace add to the `.grad` member variable rather than overwriting it.\n",
        "\n",
        "This does both the `detach_()` and `zero_()` calls on all tensor's `grad` variables.\n",
        "\n",
        "[`torch.optim` docs](https://pytorch.org/docs/stable/optim.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CldNJzMHMTh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc7399e-98b1-4c39-b3ef-32530a1364d0"
      },
      "source": [
        "# create a simple model\n",
        "model = nn.Linear(1, 1)\n",
        "\n",
        "# create a simple dataset\n",
        "X_simple = torch.tensor([[1.]])\n",
        "y_simple = torch.tensor([[2.]])\n",
        "\n",
        "# create our optimizer\n",
        "optim = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "mse_loss_fn = nn.MSELoss()\n",
        "\n",
        "y_hat = model(X_simple)\n",
        "print('model params before:', model.weight)\n",
        "loss = mse_loss_fn(y_hat, y_simple)\n",
        "optim.zero_grad()\n",
        "loss.backward()\n",
        "optim.step()\n",
        "print('model params after:', model.weight)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model params before: Parameter containing:\n",
            "tensor([[-0.2824]], requires_grad=True)\n",
            "model params after: Parameter containing:\n",
            "tensor([[-0.2544]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxv9VHTOMTh-"
      },
      "source": [
        "As we can see, the parameter was updated in the correct direction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjiD9FATMTh_"
      },
      "source": [
        "## Linear regression using GD with automatically computed derivatives and PyTorch's Modules\n",
        "\n",
        "Now let's combine what we've learned to solve linear regression in a \"PyTorchic\" way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGz8gPweMTh_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204815c8-6424-46cc-98e4-e359d180d742"
      },
      "source": [
        "step_size = 0.1\n",
        "\n",
        "linear_module = nn.Linear(d, 1, bias=False)\n",
        "\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "optim = torch.optim.SGD(linear_module.parameters(), lr=step_size)\n",
        "\n",
        "print('iter,\\tloss,\\tw')\n",
        "\n",
        "for i in range(20):\n",
        "    y_hat = linear_module(X)\n",
        "    loss = loss_func(y_hat, y)\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    \n",
        "    print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), linear_module.weight.view(2).detach().numpy()))\n",
        "\n",
        "print('\\ntrue w\\t\\t', true_w.view(2).numpy())\n",
        "print('estimated w\\t', linear_module.weight.view(2).detach().numpy())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter,\tloss,\tw\n",
            "0,\t4.91,\t[0.2344979  0.68060493]\n",
            "1,\t3.16,\t[-0.03581982  0.90833795]\n",
            "2,\t2.03,\t[-0.24850288  1.0947952 ]\n",
            "3,\t1.31,\t[-0.41569215  1.2476329 ]\n",
            "4,\t0.85,\t[-0.54699206  1.3730575 ]\n",
            "5,\t0.55,\t[-0.6499974  1.4761056]\n",
            "6,\t0.36,\t[-0.7307112  1.5608679]\n",
            "7,\t0.24,\t[-0.79387635  1.6306704 ]\n",
            "8,\t0.16,\t[-0.8432379  1.6882205]\n",
            "9,\t0.11,\t[-0.8817516  1.7357237]\n",
            "10,\t0.07,\t[-0.9117487  1.7749794]\n",
            "11,\t0.05,\t[-0.93506676  1.8074564 ]\n",
            "12,\t0.03,\t[-0.95315313  1.8343556 ]\n",
            "13,\t0.03,\t[-0.96714705  1.8566599 ]\n",
            "14,\t0.02,\t[-0.97794425  1.8751745 ]\n",
            "15,\t0.01,\t[-0.98624855  1.8905599 ]\n",
            "16,\t0.01,\t[-0.9926123  1.9033586]\n",
            "17,\t0.01,\t[-0.99746853  1.9140164 ]\n",
            "18,\t0.01,\t[-1.0011563  1.9229004]\n",
            "19,\t0.01,\t[-1.0039408  1.9303132]\n",
            "\n",
            "true w\t\t [-1.  2.]\n",
            "estimated w\t [-1.0039408  1.9303132]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j9hUvjQMTiD"
      },
      "source": [
        "## Linear regression using SGD \n",
        "In the previous examples, we computed the average gradient over the entire dataset (Gradient Descent). We can implement Stochastic Gradient Descent with a simple modification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3EUcFMbMTiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4bea1a-21da-4c10-a656-a866aec982ee"
      },
      "source": [
        "step_size = 0.01\n",
        "\n",
        "linear_module = nn.Linear(d, 1)\n",
        "loss_func = nn.MSELoss()\n",
        "optim = torch.optim.SGD(linear_module.parameters(), lr=step_size)\n",
        "print('iter,\\tloss,\\tw')\n",
        "for i in range(200):\n",
        "    rand_idx = np.random.choice(n) # take a random point from the dataset\n",
        "    x = X[rand_idx] \n",
        "    y_hat = linear_module(x)\n",
        "    loss = loss_func(y_hat, y[rand_idx]) # only compute the loss on the single point\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    \n",
        "    if i % 20 == 0:\n",
        "        print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), linear_module.weight.view(2).detach().numpy()))\n",
        "\n",
        "print('\\ntrue w\\t\\t', true_w.view(2).numpy())\n",
        "print('estimated w\\t', linear_module.weight.view(2).detach().numpy())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter,\tloss,\tw\n",
            "0,\t8.10,\t[-0.59799653 -0.30969334]\n",
            "20,\t1.85,\t[-0.6271329   0.05489432]\n",
            "40,\t0.10,\t[-0.70736873  0.56732166]\n",
            "60,\t0.52,\t[-0.7628798  1.1769345]\n",
            "80,\t0.41,\t[-0.85972327  1.3698369 ]\n",
            "100,\t0.86,\t[-0.9004862  1.5761231]\n",
            "120,\t0.07,\t[-0.9448357  1.7208863]\n",
            "140,\t0.00,\t[-0.97799194  1.819061  ]\n",
            "160,\t0.00,\t[-0.9869582  1.8632383]\n",
            "180,\t0.00,\t[-0.9946795  1.8824043]\n",
            "\n",
            "true w\t\t [-1.  2.]\n",
            "estimated w\t [-0.9934893  1.9184126]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Re8u8STMTiI"
      },
      "source": [
        "# Neural Network Basics in PyTorch\n",
        "We will try and fit a simple neural network to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "401On5ckMTiJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "8a5e4e00-d038-4907-b743-7cd3d4228694"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "d = 1\n",
        "n = 200\n",
        "X = torch.rand(n,d)\n",
        "y = 4 * torch.sin(np.pi * X) * torch.cos(6*np.pi*X**2)\n",
        "\n",
        "plt.scatter(X.numpy(), y.numpy())\n",
        "plt.title('plot of $f(x)$')\n",
        "plt.xlabel('$x$')\n",
        "plt.ylabel('$y$')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQl2A_XDMTiL"
      },
      "source": [
        "Here we define a simple two hidden layer neural network with Tanh activations. There are a few hyper parameters to play with to get a feel for how they change the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C72y6DtpMTiM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6f3d705-6af4-43d2-b24c-04b105775685"
      },
      "source": [
        "# feel free to play with these parameters\n",
        "\n",
        "step_size = 0.05\n",
        "n_epochs = 6000\n",
        "n_hidden_1 = 32\n",
        "n_hidden_2 = 32\n",
        "d_out = 1\n",
        "\n",
        "neural_network = nn.Sequential(\n",
        "                            nn.Linear(d, n_hidden_1), \n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(n_hidden_1, n_hidden_2),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(n_hidden_2, d_out)\n",
        "                            )\n",
        "\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "optim = torch.optim.SGD(neural_network.parameters(), lr=step_size)\n",
        "print('iter,\\tloss')\n",
        "for i in range(n_epochs):\n",
        "    y_hat = neural_network(X)\n",
        "    loss = loss_func(y_hat, y)\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    \n",
        "    if i % (n_epochs // 10) == 0:\n",
        "        print('{},\\t{:.2f}'.format(i, loss.item()))\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter,\tloss\n",
            "0,\t4.00\n",
            "600,\t3.90\n",
            "1200,\t3.19\n",
            "1800,\t1.20\n",
            "2400,\t0.92\n",
            "3000,\t0.62\n",
            "3600,\t0.18\n",
            "4200,\t0.22\n",
            "4800,\t0.08\n",
            "5400,\t0.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQBkFt9LMTiO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "056bc0d3-66f3-4381-eac9-f1af6713d925"
      },
      "source": [
        "X_grid = torch.from_numpy(np.linspace(0,1,50)).float().view(-1, d)\n",
        "y_hat = neural_network(X_grid)\n",
        "plt.scatter(X.numpy(), y.numpy())\n",
        "plt.plot(X_grid.detach().numpy(), y_hat.detach().numpy(), 'r')\n",
        "plt.title('plot of $f(x)$ and $\\hat{f}(x)$')\n",
        "plt.xlabel('$x$')\n",
        "plt.ylabel('$y$')\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8mPkng3MTiQ"
      },
      "source": [
        "# Things that might help on the homework\n",
        "\n",
        "## Brief Sidenote: Momentum\n",
        "\n",
        "There are other optimization algorithms besides stochastic gradient descent. One is a modification of SGD called momentum. We won't get into it here, but if you would like to read more [here](https://distill.pub/2017/momentum/) is a good place to start.\n",
        "\n",
        "We only change the step size and add the momentum keyword argument to the optimizer. Notice how it reduces the training loss in fewer iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhGP8gZDMTiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc9dd3c4-4dc9-4e57-ad54-6333f53b9af6"
      },
      "source": [
        "# feel free to play with these parameters\n",
        "\n",
        "step_size = 0.05\n",
        "momentum = 0.9\n",
        "n_epochs = 1500\n",
        "n_hidden_1 = 32\n",
        "n_hidden_2 = 32\n",
        "d_out = 1\n",
        "\n",
        "neural_network = nn.Sequential(\n",
        "                            nn.Linear(d, n_hidden_1), \n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(n_hidden_1, n_hidden_2),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(n_hidden_2, d_out)\n",
        "                            )\n",
        "\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "optim = torch.optim.SGD(neural_network.parameters(), lr=step_size, momentum=momentum)\n",
        "print('iter,\\tloss')\n",
        "for i in range(n_epochs):\n",
        "    y_hat = neural_network(X)\n",
        "    loss = loss_func(y_hat, y)\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    \n",
        "    if i % (n_epochs // 10) == 0:\n",
        "        print('{},\\t{:.2f}'.format(i, loss.item()))\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter,\tloss\n",
            "0,\t3.97\n",
            "150,\t3.22\n",
            "300,\t0.86\n",
            "450,\t0.11\n",
            "600,\t0.04\n",
            "750,\t0.03\n",
            "900,\t0.01\n",
            "1050,\t0.00\n",
            "1200,\t0.00\n",
            "1350,\t0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGZL4mkbMTiS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "00bb88f1-89d8-4ec9-b440-6368de8673f2"
      },
      "source": [
        "X_grid = torch.from_numpy(np.linspace(0,1,50)).float().view(-1, d)\n",
        "y_hat = neural_network(X_grid)\n",
        "plt.scatter(X.numpy(), y.numpy())\n",
        "plt.plot(X_grid.detach().numpy(), y_hat.detach().numpy(), 'r')\n",
        "plt.title('plot of $f(x)$ and $\\hat{f}(x)$')\n",
        "plt.xlabel('$x$')\n",
        "plt.ylabel('$y$')\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSO1McZLMTiT"
      },
      "source": [
        "## CrossEntropyLoss\n",
        "So far, we have been considering regression tasks and have used the [MSELoss](https://pytorch.org/docs/stable/nn.html#torch.nn.MSELoss) module. For the homework, we will be performing a classification task and will use the cross entropy loss.\n",
        "\n",
        "PyTorch implements a version of the cross entropy loss in one module called [CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss). Its usage is slightly different than MSE, so we will break it down here. \n",
        "\n",
        "- input: The first parameter to CrossEntropyLoss is the output of our network. It expects a *real valued* tensor of dimensions $(N,C)$ where $N$ is the minibatch size and $C$ is the number of classes. In our case $N=3$ and $C=2$. The values along the second dimension correspond to raw unnormalized scores for each class. The CrossEntropyLoss module does the softmax calculation for us, so we do not need to apply our own softmax to the output of our neural network.\n",
        "- output: The second parameter to CrossEntropyLoss is the true label. It expects an *integer valued* tensor of dimension $(N)$. The integer at each element corresponds to the correct class. In our case, the \"correct\" class labels are class 0, class 1, and class 1.\n",
        "\n",
        "Try out the loss function on three toy predictions. The true class labels are $y=[1,1,0]$. The first two examples correspond to predictions that are \"correct\" in that they have higher raw scores for the correct class. The second example is \"more confident\" in the prediction, leading to a smaller loss. The last two examples are incorrect predictions with lower and higher confidence respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALoGYsu1MTiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61996c0c-9bad-4662-979b-90fd1764190b"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "input = torch.tensor([[-1., 1],[-1, 1],[1, -1]]) # raw scores correspond to the correct class\n",
        "# input = torch.tensor([[-3., 3],[-3, 3],[3, -3]]) # raw scores correspond to the correct class with higher confidence\n",
        "# input = torch.tensor([[1., -1],[1, -1],[-1, 1]]) # raw scores correspond to the incorrect class\n",
        "# input = torch.tensor([[3., -3],[3, -3],[-3, 3]]) # raw scores correspond to the incorrect class with incorrectly placed confidence\n",
        "\n",
        "target = torch.tensor([1, 1, 0])\n",
        "output = loss(input, target)\n",
        "print(output)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1269)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCwLf9C2MTiY"
      },
      "source": [
        "## Learning rate schedulers\n",
        "\n",
        "Often we do not want to use a fixed learning rate throughout all training. PyTorch offers learning rate schedulers to change the learning rate over time. Common strategies include multiplying the lr by a constant every epoch (e.g. 0.9) and halving the learning rate when the training loss flattens out.\n",
        "\n",
        "See the [learning rate scheduler docs](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate) for usage and examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrapEC2XMTiY"
      },
      "source": [
        "## Convolutions\n",
        "When working with images, we often want to use convolutions to extract features using convolutions. PyTorch implments this for us in the `torch.nn.Conv2d` module. It expects the input to have a specific dimension $(N, C_{in}, H_{in}, W_{in})$ where $N$ is batch size, $C_{in}$ is the number of channels the image has, and $H_{in}, W_{in}$ are the image height and width respectively.\n",
        "\n",
        "We can modify the convolution to have different properties with the parameters:\n",
        "- kernel_size\n",
        "- stride\n",
        "- padding\n",
        "\n",
        "They can change the output dimension so be careful.\n",
        "\n",
        "See the [`torch.nn.Conv2d` docs](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d) for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gKSeJYuMTiZ"
      },
      "source": [
        "To illustrate what the `Conv2d` module is doing, let's set the conv weights manually to a Gaussian blur kernel.\n",
        "\n",
        "We can see that it applies the kernel to the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJjlv1lOMTiZ"
      },
      "source": [
        "# an entire mnist digit\n",
        "image = np.array([0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.3803922 , 0.37647063, 0.3019608 ,0.46274513, 0.2392157 , 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.3529412 , 0.5411765 , 0.9215687 ,0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 ,0.9843138 , 0.9843138 , 0.9725491 , 0.9960785 , 0.9607844 ,0.9215687 , 0.74509805, 0.08235294, 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.54901963,0.9843138 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,0.7411765 , 0.09019608, 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.8862746 , 0.9960785 , 0.81568635,0.7803922 , 0.7803922 , 0.7803922 , 0.7803922 , 0.54509807,0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 ,0.5019608 , 0.8705883 , 0.9960785 , 0.9960785 , 0.7411765 ,0.08235294, 0., 0., 0., 0.,0., 0., 0., 0., 0.,0.14901961, 0.32156864, 0.0509804 , 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.13333334,0.8352942 , 0.9960785 , 0.9960785 , 0.45098042, 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0.32941177, 0.9960785 ,0.9960785 , 0.9176471 , 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0.32941177, 0.9960785 , 0.9960785 , 0.9176471 ,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0.4156863 , 0.6156863 ,0.9960785 , 0.9960785 , 0.95294124, 0.20000002, 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0.09803922, 0.45882356, 0.8941177 , 0.8941177 ,0.8941177 , 0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 ,0.9960785 , 0.94117653, 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.26666668, 0.4666667 , 0.86274517,0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.5568628 ,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0.14509805, 0.73333335,0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 , 0.8745099 ,0.8078432 , 0.8078432 , 0.29411766, 0.26666668, 0.8431373 ,0.9960785 , 0.9960785 , 0.45882356, 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0.4431373 , 0.8588236 , 0.9960785 , 0.9490197 , 0.89019614,0.45098042, 0.34901962, 0.12156864, 0., 0.,0., 0., 0.7843138 , 0.9960785 , 0.9450981 ,0.16078432, 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0.6627451 , 0.9960785 ,0.6901961 , 0.24313727, 0., 0., 0.,0., 0., 0., 0., 0.18823531,0.9058824 , 0.9960785 , 0.9176471 , 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0.07058824, 0.48627454, 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.32941177, 0.9960785 , 0.9960785 ,0.6509804 , 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0.54509807, 0.9960785 , 0.9333334 , 0.22352943, 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.8235295 , 0.9803922 , 0.9960785 ,0.65882355, 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0.9490197 , 0.9960785 , 0.93725497, 0.22352943, 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.34901962, 0.9843138 , 0.9450981 ,0.3372549 , 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.01960784,0.8078432 , 0.96470594, 0.6156863 , 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.01568628, 0.45882356, 0.27058825,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0.], dtype=np.float32)\n",
        "image_torch = torch.from_numpy(image).view(1, 1, 28, 28)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28-oVco6MTib",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "95dd7e55-c6e8-460f-995e-51ce3f1aeff8"
      },
      "source": [
        "# a gaussian blur kernel\n",
        "gaussian_kernel = torch.tensor([[1., 2, 1],[2, 4, 2],[1, 2, 1]]) / 16.0\n",
        "\n",
        "conv = nn.Conv2d(1, 1, 3)\n",
        "# manually set the conv weight\n",
        "conv.weight.data[:] = gaussian_kernel\n",
        "\n",
        "convolved = conv(image_torch)\n",
        "\n",
        "plt.title('original image')\n",
        "plt.imshow(image_torch.view(28,28).detach().numpy())\n",
        "plt.show()\n",
        "\n",
        "plt.title('blurred image')\n",
        "plt.imshow(convolved.view(26,26).detach().numpy())\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhf848TRMTid"
      },
      "source": [
        "As we can see, the image is blurred as expected. \n",
        "\n",
        "In practice, we learn many kernels at a time. In this example, we take in an RGB image (3 channels) and output a 16 channel image. After an activation function, that could be used as input to another `Conv2d` module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noG9FyJ0MTie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0205c46f-9e8b-42b5-e943-55cd0916a9ef"
      },
      "source": [
        "im_channels = 3 # if we are working with RGB images, there are 3 input channels, with black and white, 1\n",
        "out_channels = 16 # this is a hyperparameter we can tune\n",
        "kernel_size = 3 # this is another hyperparameter we can tune\n",
        "batch_size = 4\n",
        "image_width = 32\n",
        "image_height = 32\n",
        "\n",
        "im = torch.randn(batch_size, im_channels, image_width, image_height)\n",
        "\n",
        "m = nn.Conv2d(im_channels, out_channels, kernel_size)\n",
        "convolved = m(im) # it is a module so we can call it\n",
        "\n",
        "print('im shape', im.shape)\n",
        "print('convolved im shape', convolved.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "im shape torch.Size([4, 3, 32, 32])\n",
            "convolved im shape torch.Size([4, 16, 30, 30])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwsmNTYLMTig"
      },
      "source": [
        "## Useful links:\n",
        "- [60 minute PyTorch Tutorial](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
        "- [PyTorch Docs](https://pytorch.org/docs/stable/index.html)\n",
        "- [Lecture notes on Auto-Diff](https://courses.cs.washington.edu/courses/cse446/19wi/notes/auto-diff.pdf)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d77LgKaMTih"
      },
      "source": [
        "\n",
        "Custom Datasets, DataLoaders\n",
        "===================================================\n",
        "This is modified from pytorch official tutorial.\n",
        "**Author**: `Sasank Chilamkurthy <https://chsasank.github.io>`_\n",
        "\n",
        "A lot of effort in solving any machine learning problem goes in to\n",
        "preparing the data. PyTorch provides many tools to make data loading\n",
        "easy and hopefully, to make your code more readable. In this tutorial,\n",
        "we will see how to load and preprocess/augment data from a non trivial\n",
        "dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyN-mHRoMTii"
      },
      "source": [
        "Dataset class\n",
        "-------------\n",
        "\n",
        "``torch.utils.data.Dataset`` is an abstract class representing a\n",
        "dataset.\n",
        "Your custom dataset should inherit ``Dataset`` and override the following\n",
        "methods:\n",
        "\n",
        "-  ``__len__`` so that ``len(dataset)`` returns the size of the dataset.\n",
        "-  ``__getitem__`` to support the indexing such that ``dataset[i]`` can\n",
        "   be used to get $i$\\ th sample\n",
        "\n",
        "Let's create a dataset class for our face landmarks dataset. We will\n",
        "read the csv in ``__init__`` but leave the reading of images to\n",
        "``__getitem__``. This is memory efficient because all the images are not\n",
        "stored in the memory at once but read as required.\n",
        "\n",
        "Sample of our dataset will be a dict\n",
        "``{'image': image, 'landmarks': landmarks}``. Our dataset will take an\n",
        "optional argument ``transform`` so that any required processing can be\n",
        "applied on the sample. We will see the usefulness of ``transform`` in the\n",
        "next section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I302HaeiMTij"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class FakeDataset(Dataset):\n",
        "\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOgpiQcIMTik"
      },
      "source": [
        "However, we are losing a lot of features by using a simple ``for`` loop to\n",
        "iterate over the data. In particular, we are missing out on:\n",
        "\n",
        "-  Batching the data\n",
        "-  Shuffling the data\n",
        "-  Load the data in parallel using ``multiprocessing`` workers.\n",
        "\n",
        "``torch.utils.data.DataLoader`` is an iterator which provides all these\n",
        "features. Parameters used below should be clear. One parameter of\n",
        "interest is ``collate_fn``. You can specify how exactly the samples need\n",
        "to be batched using ``collate_fn``. However, default collate should work\n",
        "fine for most use cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMHL8d06MTik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbb90abd-babf-4535-eeb1-c7551d7b0fa2"
      },
      "source": [
        "x = np.random.rand(100, 10)\n",
        "y = np.random.rand(100)\n",
        "\n",
        "dataset = FakeDataset(x, y)\n",
        "dataloader = DataLoader(dataset, batch_size=4,\n",
        "                        shuffle=True, num_workers=4)\n",
        "\n",
        "for i_batch, sample_batched in enumerate(dataloader):\n",
        "    print(i_batch, sample_batched)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [tensor([[0.5355, 0.7904, 0.9605, 0.7997, 0.1974, 0.2357, 0.5871, 0.5880, 0.8157,\n",
            "         0.7967],\n",
            "        [0.0431, 0.4885, 0.0495, 0.2853, 0.8376, 0.3061, 0.0888, 0.8225, 0.8141,\n",
            "         0.8305],\n",
            "        [0.4420, 0.6948, 0.1094, 0.5931, 0.7619, 0.4407, 0.4690, 0.3976, 0.9607,\n",
            "         0.3494],\n",
            "        [0.9241, 0.5794, 0.1106, 0.4831, 0.1394, 0.8072, 0.4977, 0.0555, 0.7470,\n",
            "         0.6890]], dtype=torch.float64), tensor([0.3752, 0.9373, 0.1883, 0.0983], dtype=torch.float64)]\n",
            "1 [tensor([[0.3276, 0.4199, 0.6992, 0.4885, 0.0958, 0.6588, 0.2741, 0.4439, 0.1695,\n",
            "         0.8619],\n",
            "        [0.5713, 0.6165, 0.7750, 0.5141, 0.1918, 0.8182, 0.5630, 0.2650, 0.9904,\n",
            "         0.0493],\n",
            "        [0.7059, 0.0629, 0.4574, 0.6665, 0.9461, 0.6405, 0.6298, 0.0565, 0.9597,\n",
            "         0.4506],\n",
            "        [0.5660, 0.5365, 0.7909, 0.4810, 0.2659, 0.1149, 0.3142, 0.5249, 0.2611,\n",
            "         0.9927]], dtype=torch.float64), tensor([0.3145, 0.8794, 0.9747, 0.2815], dtype=torch.float64)]\n",
            "2 [tensor([[0.6574, 0.5226, 0.4919, 0.2658, 0.3278, 0.4690, 0.0562, 0.9769, 0.1475,\n",
            "         0.5129],\n",
            "        [0.2575, 0.8604, 0.1631, 0.3485, 0.5333, 0.5776, 0.7931, 0.6992, 0.4117,\n",
            "         0.0477],\n",
            "        [0.4232, 0.2060, 0.8339, 0.6456, 0.2742, 0.0868, 0.9288, 0.2806, 0.1588,\n",
            "         0.8433],\n",
            "        [0.6122, 0.3149, 0.4599, 0.4874, 0.5861, 0.7513, 0.2208, 0.0972, 0.9090,\n",
            "         0.7897]], dtype=torch.float64), tensor([0.3191, 0.3106, 0.4983, 0.0727], dtype=torch.float64)]\n",
            "3 [tensor([[0.2729, 0.1071, 0.9125, 0.4087, 0.2112, 0.2144, 0.4645, 0.4689, 0.5563,\n",
            "         0.3527],\n",
            "        [0.3348, 0.1017, 0.6351, 0.7048, 0.8362, 0.4930, 0.7561, 0.2674, 0.9701,\n",
            "         0.8510],\n",
            "        [0.2766, 0.8681, 0.0590, 0.0525, 0.6620, 0.5223, 0.9452, 0.1036, 0.2693,\n",
            "         0.3226],\n",
            "        [0.0157, 0.9246, 0.2020, 0.1813, 0.5590, 0.1894, 0.8663, 0.3976, 0.6099,\n",
            "         0.7796]], dtype=torch.float64), tensor([0.2831, 0.3492, 0.4770, 0.1214], dtype=torch.float64)]\n",
            "4 [tensor([[0.3428, 0.9303, 0.4622, 0.7690, 0.5182, 0.2178, 0.8088, 0.3814, 0.2451,\n",
            "         0.0097],\n",
            "        [0.3330, 0.9045, 0.2981, 0.6869, 0.8339, 0.6206, 0.7687, 0.8025, 0.1287,\n",
            "         0.2582],\n",
            "        [0.2407, 0.3158, 0.8096, 0.1740, 0.9177, 0.7346, 0.3027, 0.5294, 0.2325,\n",
            "         0.8409],\n",
            "        [0.4609, 0.6859, 0.3709, 0.9270, 0.6991, 0.5749, 0.8408, 0.4865, 0.5438,\n",
            "         0.6000]], dtype=torch.float64), tensor([0.3401, 0.4160, 0.3310, 0.8094], dtype=torch.float64)]\n",
            "5 [tensor([[0.6713, 0.4263, 0.9188, 0.9392, 0.6510, 0.8450, 0.1234, 0.0928, 0.8625,\n",
            "         0.0309],\n",
            "        [0.7630, 0.1256, 0.6109, 0.5586, 0.9137, 0.5597, 0.6269, 0.3198, 0.3077,\n",
            "         0.3593],\n",
            "        [0.9806, 0.3530, 0.0961, 0.5138, 0.8475, 0.7146, 0.5949, 0.2177, 0.5165,\n",
            "         0.7706],\n",
            "        [0.2514, 0.5027, 0.7723, 0.5894, 0.3749, 0.9916, 0.5685, 0.2184, 0.4930,\n",
            "         0.4290]], dtype=torch.float64), tensor([0.0337, 0.4832, 0.8239, 0.3861], dtype=torch.float64)]\n",
            "6 [tensor([[0.1370, 0.7772, 0.2095, 0.0615, 0.9563, 0.1148, 0.7654, 0.8568, 0.8793,\n",
            "         0.3518],\n",
            "        [0.1630, 0.2736, 0.0070, 0.1457, 0.0807, 0.6849, 0.8761, 0.0502, 0.7291,\n",
            "         0.2466],\n",
            "        [0.4305, 0.7886, 0.6214, 0.4531, 0.4469, 0.7205, 0.1592, 0.1842, 0.5187,\n",
            "         0.6969],\n",
            "        [0.6150, 0.6825, 0.1255, 0.7408, 0.5374, 0.0448, 0.4369, 0.7070, 0.6105,\n",
            "         0.2682]], dtype=torch.float64), tensor([0.0032, 0.6671, 0.2027, 0.2601], dtype=torch.float64)]\n",
            "7 [tensor([[0.3773, 0.7661, 0.9189, 0.0614, 0.9269, 0.1185, 0.6387, 0.1429, 0.6989,\n",
            "         0.3441],\n",
            "        [0.6278, 0.0859, 0.0657, 0.6674, 0.6366, 0.9306, 0.8121, 0.6326, 0.5322,\n",
            "         0.7793],\n",
            "        [0.0633, 0.2424, 0.2661, 0.7229, 0.8196, 0.0043, 0.3061, 0.9725, 0.4043,\n",
            "         0.5097],\n",
            "        [0.1366, 0.9362, 0.8221, 0.4098, 0.0233, 0.8347, 0.3028, 0.7414, 0.2492,\n",
            "         0.3986]], dtype=torch.float64), tensor([0.0164, 0.9702, 0.4057, 0.1860], dtype=torch.float64)]\n",
            "8 [tensor([[0.1415, 0.0567, 0.5027, 0.6150, 0.1651, 0.4861, 0.4452, 0.6551, 0.6557,\n",
            "         0.7662],\n",
            "        [0.5806, 0.0531, 0.8747, 0.0568, 0.1727, 0.7886, 0.5517, 0.1274, 0.0775,\n",
            "         0.2411],\n",
            "        [0.8126, 0.4741, 0.5860, 0.3143, 0.0428, 0.0722, 0.0376, 0.9781, 0.0124,\n",
            "         0.2722],\n",
            "        [0.7026, 0.0047, 0.9629, 0.5305, 0.8144, 0.2466, 0.7914, 0.4742, 0.6611,\n",
            "         0.9934]], dtype=torch.float64), tensor([0.1673, 0.1575, 0.4335, 0.1524], dtype=torch.float64)]\n",
            "9 [tensor([[0.1443, 0.5263, 0.4120, 0.3804, 0.8041, 0.9519, 0.1409, 0.5286, 0.9267,\n",
            "         0.2848],\n",
            "        [0.3985, 0.6418, 0.9978, 0.6291, 0.6545, 0.5499, 0.6170, 0.3744, 0.1309,\n",
            "         0.0333],\n",
            "        [0.7485, 0.2783, 0.3977, 0.0927, 0.1109, 0.4401, 0.9317, 0.4913, 0.9146,\n",
            "         0.5833],\n",
            "        [0.3544, 0.1138, 0.4130, 0.6864, 0.0309, 0.2801, 0.9899, 0.4980, 0.8004,\n",
            "         0.2637]], dtype=torch.float64), tensor([0.4732, 0.9767, 0.5321, 0.3185], dtype=torch.float64)]\n",
            "10 [tensor([[0.7997, 0.7779, 0.2931, 0.6034, 0.3622, 0.1584, 0.6144, 0.7697, 0.3829,\n",
            "         0.0093],\n",
            "        [0.5625, 0.4209, 0.3199, 0.5329, 0.4318, 0.4624, 0.7504, 0.0850, 0.8262,\n",
            "         0.8674],\n",
            "        [0.5961, 0.1317, 0.5008, 0.0683, 0.5264, 0.8927, 0.2962, 0.2142, 0.7640,\n",
            "         0.8714],\n",
            "        [0.8435, 0.2153, 0.4496, 0.2253, 0.4997, 0.3479, 0.4391, 0.0605, 0.4542,\n",
            "         0.0157]], dtype=torch.float64), tensor([0.2867, 0.6624, 0.8594, 0.6350], dtype=torch.float64)]\n",
            "11 [tensor([[0.8425, 0.0163, 0.0450, 0.9658, 0.1704, 0.7332, 0.5599, 0.3465, 0.5721,\n",
            "         0.3130],\n",
            "        [0.6240, 0.6081, 0.1885, 0.8287, 0.0992, 0.9690, 0.7310, 0.4237, 0.0929,\n",
            "         0.3810],\n",
            "        [0.2460, 0.8893, 0.5499, 0.0054, 0.8566, 0.2870, 0.2730, 0.5990, 0.5467,\n",
            "         0.3042],\n",
            "        [0.1333, 0.8867, 0.5232, 0.9336, 0.1000, 0.0323, 0.3984, 0.9970, 0.4848,\n",
            "         0.4662]], dtype=torch.float64), tensor([0.3623, 0.2295, 0.3607, 0.6319], dtype=torch.float64)]\n",
            "12 [tensor([[0.1269, 0.5661, 0.6663, 0.0428, 0.6780, 0.2926, 0.7766, 0.1815, 0.7354,\n",
            "         0.6291],\n",
            "        [0.4832, 0.9956, 0.4878, 0.2249, 0.9667, 0.6957, 0.0909, 0.6688, 0.8366,\n",
            "         0.0182],\n",
            "        [0.1711, 0.7196, 0.2643, 0.3807, 0.5423, 0.7101, 0.6998, 0.4714, 0.5880,\n",
            "         0.9182],\n",
            "        [0.5020, 0.6228, 0.7321, 0.8117, 0.8293, 0.7492, 0.4505, 0.8574, 0.3756,\n",
            "         0.7858]], dtype=torch.float64), tensor([0.6234, 0.3888, 0.5712, 0.8451], dtype=torch.float64)]\n",
            "13 [tensor([[0.9117, 0.1700, 0.2482, 0.3003, 0.1531, 0.6073, 0.5338, 0.5332, 0.2620,\n",
            "         0.0839],\n",
            "        [0.1089, 0.5596, 0.5591, 0.7019, 0.5667, 0.2379, 0.3286, 0.0240, 0.3211,\n",
            "         0.1834],\n",
            "        [0.5321, 0.4342, 0.0405, 0.1812, 0.6136, 0.7870, 0.0483, 0.9592, 0.4478,\n",
            "         0.5764],\n",
            "        [0.2195, 0.3428, 0.2049, 0.9051, 0.9741, 0.3217, 0.1570, 0.6321, 0.9287,\n",
            "         0.0520]], dtype=torch.float64), tensor([0.0576, 0.3808, 0.8922, 0.1052], dtype=torch.float64)]\n",
            "14 [tensor([[0.2442, 0.1764, 0.6082, 0.0751, 0.6153, 0.5185, 0.6593, 0.6469, 0.2874,\n",
            "         0.4393],\n",
            "        [0.6947, 0.4833, 0.4664, 0.0637, 0.6154, 0.3276, 0.2890, 0.9505, 0.2479,\n",
            "         0.4722],\n",
            "        [0.4771, 0.3198, 0.2225, 0.2465, 0.5702, 0.4464, 0.7550, 0.1298, 0.1753,\n",
            "         0.1040],\n",
            "        [0.0705, 0.8939, 0.1630, 0.9421, 0.4714, 0.8645, 0.1503, 0.4629, 0.6484,\n",
            "         0.6583]], dtype=torch.float64), tensor([0.0552, 0.1866, 0.5800, 0.7861], dtype=torch.float64)]\n",
            "15 [tensor([[0.3332, 0.0981, 0.7359, 0.7838, 0.3023, 0.2381, 0.5067, 0.4706, 0.2707,\n",
            "         0.3132],\n",
            "        [0.5042, 0.4699, 0.3214, 0.7640, 0.5101, 0.6616, 0.3617, 0.4770, 0.0069,\n",
            "         0.1894],\n",
            "        [0.4786, 0.1964, 0.8945, 0.9900, 0.8276, 0.1961, 0.2638, 0.0117, 0.1773,\n",
            "         0.6262],\n",
            "        [0.5439, 0.1739, 0.6939, 0.3658, 0.5159, 0.9156, 0.0107, 0.5253, 0.1156,\n",
            "         0.4393]], dtype=torch.float64), tensor([0.4883, 0.4412, 0.0566, 0.1617], dtype=torch.float64)]\n",
            "16 [tensor([[0.6515, 0.9134, 0.5027, 0.7137, 0.3813, 0.0376, 0.6971, 0.9692, 0.9135,\n",
            "         0.2692],\n",
            "        [0.6050, 0.2824, 0.6153, 0.2513, 0.0531, 0.0236, 0.7016, 0.6394, 0.9860,\n",
            "         0.4539],\n",
            "        [0.7834, 0.7959, 0.4286, 0.5653, 0.3529, 0.3601, 0.0417, 0.5342, 0.4847,\n",
            "         0.0560],\n",
            "        [0.0165, 0.3028, 0.3071, 0.0787, 0.2653, 0.3550, 0.3574, 0.0368, 0.0728,\n",
            "         0.8916]], dtype=torch.float64), tensor([0.6051, 0.9452, 0.0361, 0.1207], dtype=torch.float64)]\n",
            "17 [tensor([[0.0274, 0.2815, 0.4425, 0.2692, 0.4284, 0.3600, 0.6660, 0.2705, 0.7473,\n",
            "         0.2071],\n",
            "        [0.5691, 0.1234, 0.0489, 0.6661, 0.6113, 0.6277, 0.0384, 0.6170, 0.2797,\n",
            "         0.8429],\n",
            "        [0.1754, 0.2864, 0.7618, 0.0244, 0.3647, 0.9209, 0.0891, 0.1538, 0.1855,\n",
            "         0.7084],\n",
            "        [0.5955, 0.0951, 0.6246, 0.7979, 0.9589, 0.3035, 0.9799, 0.8582, 0.6784,\n",
            "         0.7507]], dtype=torch.float64), tensor([0.9358, 0.3899, 0.8977, 0.3991], dtype=torch.float64)]\n",
            "18 [tensor([[0.3322, 0.7527, 0.8107, 0.2407, 0.2330, 0.0650, 0.1372, 0.2534, 0.4211,\n",
            "         0.1260],\n",
            "        [0.1096, 0.4694, 0.7044, 0.3765, 0.8890, 0.9266, 0.2414, 0.1361, 0.3555,\n",
            "         0.6641],\n",
            "        [0.0994, 0.4514, 0.3857, 0.9796, 0.9205, 0.1876, 0.3074, 0.2653, 0.4389,\n",
            "         0.1293],\n",
            "        [0.9852, 0.7606, 0.0070, 0.6510, 0.2410, 0.3949, 0.1414, 0.7690, 0.8134,\n",
            "         0.7123]], dtype=torch.float64), tensor([0.7878, 0.2701, 0.2245, 0.8446], dtype=torch.float64)]\n",
            "19 [tensor([[0.3676, 0.1686, 0.0707, 0.4301, 0.8522, 0.6364, 0.6080, 0.8737, 0.3691,\n",
            "         0.1897],\n",
            "        [0.1505, 0.9721, 0.3268, 0.8636, 0.4060, 0.1426, 0.2754, 0.0926, 0.8451,\n",
            "         0.1824],\n",
            "        [0.1328, 0.4722, 0.4579, 0.2818, 0.5141, 0.8366, 0.0479, 0.0689, 0.7267,\n",
            "         0.3794],\n",
            "        [0.3471, 0.9848, 0.1266, 0.3642, 0.3110, 0.2262, 0.7783, 0.4433, 0.5535,\n",
            "         0.4736]], dtype=torch.float64), tensor([0.2156, 0.7661, 0.3083, 0.0902], dtype=torch.float64)]\n",
            "20 [tensor([[0.7553, 0.7957, 0.3804, 0.9051, 0.6033, 0.3121, 0.1475, 0.6260, 0.8481,\n",
            "         0.0456],\n",
            "        [0.7332, 0.8916, 0.8853, 0.7412, 0.7929, 0.9534, 0.1238, 0.0607, 0.1257,\n",
            "         0.0268],\n",
            "        [0.3525, 0.3487, 0.2770, 0.5047, 0.1117, 0.9636, 0.4308, 0.3456, 0.0113,\n",
            "         0.2805],\n",
            "        [0.6934, 0.8673, 0.6935, 0.4884, 0.7295, 0.3680, 0.1332, 0.1841, 0.8962,\n",
            "         0.7861]], dtype=torch.float64), tensor([0.2310, 0.9971, 0.4506, 0.0302], dtype=torch.float64)]\n",
            "21 [tensor([[0.1478, 0.4510, 0.5293, 0.0144, 0.6534, 0.0011, 0.7619, 0.8707, 0.0184,\n",
            "         0.0679],\n",
            "        [0.1796, 0.2674, 0.7746, 0.9959, 0.3893, 0.6051, 0.6899, 0.3247, 0.2102,\n",
            "         0.8673],\n",
            "        [0.7651, 0.3097, 0.8265, 0.7565, 0.3180, 0.9248, 0.9444, 0.4895, 0.4972,\n",
            "         0.6315],\n",
            "        [0.3225, 0.1331, 0.9460, 0.9248, 0.6805, 0.3465, 0.6849, 0.1555, 0.6478,\n",
            "         0.7804]], dtype=torch.float64), tensor([0.9799, 0.3140, 0.8146, 0.0759], dtype=torch.float64)]\n",
            "22 [tensor([[0.8506, 0.4169, 0.4541, 0.9331, 0.0052, 0.1280, 0.9007, 0.1913, 0.8718,\n",
            "         0.0106],\n",
            "        [0.3914, 0.0533, 0.7894, 0.8275, 0.7835, 0.2978, 0.4156, 0.8235, 0.9098,\n",
            "         0.8376],\n",
            "        [0.2921, 0.9617, 0.9515, 0.3262, 0.4368, 0.5069, 0.7174, 0.9699, 0.8135,\n",
            "         0.2042],\n",
            "        [0.3389, 0.7122, 0.8899, 0.6695, 0.9767, 0.1120, 0.2055, 0.7342, 0.6544,\n",
            "         0.9195]], dtype=torch.float64), tensor([0.6756, 0.8951, 0.8708, 0.1774], dtype=torch.float64)]\n",
            "23 [tensor([[0.0795, 0.8094, 0.9198, 0.5961, 0.0574, 0.6314, 0.6500, 0.2977, 0.3418,\n",
            "         0.7521],\n",
            "        [0.3207, 0.4271, 0.3206, 0.9046, 0.7617, 0.8463, 0.6925, 0.1443, 0.0974,\n",
            "         0.5341],\n",
            "        [0.9347, 0.8148, 0.4499, 0.0176, 0.4606, 0.1236, 0.1444, 0.2298, 0.5406,\n",
            "         0.6820],\n",
            "        [0.2653, 0.5330, 0.0414, 0.4293, 0.3036, 0.1316, 0.0314, 0.6894, 0.7553,\n",
            "         0.2532]], dtype=torch.float64), tensor([0.6891, 0.8877, 0.6488, 0.0190], dtype=torch.float64)]\n",
            "24 [tensor([[0.9219, 0.4175, 0.7378, 0.7466, 0.6516, 0.3478, 0.3196, 0.4792, 0.0107,\n",
            "         0.0097],\n",
            "        [0.1141, 0.1068, 0.5190, 0.8968, 0.4951, 0.1997, 0.6193, 0.2545, 0.8648,\n",
            "         0.8976],\n",
            "        [0.0472, 0.2678, 0.7080, 0.2435, 0.6636, 0.8487, 0.3345, 0.3422, 0.7687,\n",
            "         0.3709],\n",
            "        [0.3854, 0.9316, 0.0298, 0.9188, 0.8910, 0.3670, 0.8487, 0.1697, 0.0127,\n",
            "         0.0498]], dtype=torch.float64), tensor([0.3341, 0.8928, 0.0040, 0.0839], dtype=torch.float64)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-m-ml0NoMTim"
      },
      "source": [
        "Mixed Presision Training\n",
        "===================================================\n",
        "**Author**: `Chi-Liang Liu <https://liangtaiwan.github.io>`\n",
        "**Ref**: https://github.com/NVIDIA/apex\n",
        "Using mixed precision to train your networks can be:\n",
        "- 2-4x faster\n",
        "- memory-efficient\n",
        "in only 3 lines of Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a94qxAC_MTin"
      },
      "source": [
        "# Apex \n",
        "\n",
        "NVIDIA-maintained utilities to streamline mixed precision and distributed training in Pytorch. Some of the code here will be included in upstream Pytorch eventually. The intention of Apex is to make up-to-date utilities available to users as quickly as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw6ociH0MTin"
      },
      "source": [
        "## apex.amp\n",
        "\n",
        "Amp allows users to easily experiment with different pure and mixed precision modes.\n",
        "Commonly-used default modes are chosen by\n",
        "selecting an \"optimization level\" or ``opt_level``; each ``opt_level`` establishes a set of\n",
        "properties that govern Amp's implementation of pure or mixed precision training.\n",
        "Finer-grained control of how a given ``opt_level`` behaves can be achieved by passing values for\n",
        "particular properties directly to ``amp.initialize``.  These manually specified values\n",
        "override the defaults established by the ``opt_level``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxP-tvHcMTio",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "0642ae52-0146-4d20-d2d2-22207c726fde"
      },
      "source": [
        "from apex import amp\n",
        "\n",
        "# Declare model and optimizer as usual, with default (FP32) precision\n",
        "model = torch.nn.Linear(10, 100).cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Allow Amp to perform casts as required by the opt_level\n",
        "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n",
        "...\n",
        "# loss.backward() becomes:\n",
        "with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "    scaled_loss.backward()\n",
        "..."
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-f5e8b68ab591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mapex\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Declare model and optimizer as usual, with default (FP32) precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'apex'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}